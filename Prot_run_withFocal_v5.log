
name:  shared.weight param num:  131072
name:  encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight param num:  8192
name:  encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight param num:  32768
name:  encoder.block.23.layer.0.SelfAttention.k.lora_A.default.weight param num:  8192
name:  encoder.block.23.layer.0.SelfAttention.k.lora_B.default.weight param num:  32768
name:  encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight param num:  8192
name:  encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight param num:  32768
name:  encoder.block.23.layer.1.DenseReluDense.wi.lora_A.default.weight param num:  8192
name:  encoder.block.23.layer.1.DenseReluDense.wi.lora_B.default.weight param num:  131072
name:  encoder.block.23.layer.1.DenseReluDense.wo.lora_A.default.weight param num:  131072
name:  encoder.block.23.layer.1.DenseReluDense.wo.lora_B.default.weight param num:  8192
name:  layer_classifier.local_layers.0.0.weight param num:  4096
name:  layer_classifier.local_layers.0.0.bias param num:  64
name:  layer_classifier.local_layers.0.2.weight param num:  64
name:  layer_classifier.local_layers.0.2.bias param num:  64
name:  layer_classifier.local_layers.0.3.weight param num:  2816
name:  layer_classifier.local_layers.0.3.bias param num:  44
name:  layer_classifier.local_layers.1.0.weight param num:  8192
name:  layer_classifier.local_layers.1.0.bias param num:  128
name:  layer_classifier.local_layers.1.2.weight param num:  128
name:  layer_classifier.local_layers.1.2.bias param num:  128
name:  layer_classifier.local_layers.1.3.weight param num:  5376
name:  layer_classifier.local_layers.1.3.bias param num:  42
name:  layer_classifier.local_layers.2.0.weight param num:  16384
name:  layer_classifier.local_layers.2.0.bias param num:  128
name:  layer_classifier.local_layers.2.2.weight param num:  128
name:  layer_classifier.local_layers.2.2.bias param num:  128
name:  layer_classifier.local_layers.2.3.weight param num:  5632
name:  layer_classifier.local_layers.2.3.bias param num:  44
name:  layer_classifier.global_layers.0.0.weight param num:  65536
name:  layer_classifier.global_layers.0.0.bias param num:  64
name:  layer_classifier.global_layers.0.2.weight param num:  64
name:  layer_classifier.global_layers.0.2.bias param num:  64
name:  layer_classifier.global_layers.1.0.weight param num:  69632
name:  layer_classifier.global_layers.1.0.bias param num:  64
name:  layer_classifier.global_layers.1.2.weight param num:  64
name:  layer_classifier.global_layers.1.2.bias param num:  64
name:  layer_classifier.global_layers.2.0.weight param num:  139264
name:  layer_classifier.global_layers.2.0.bias param num:  128
name:  layer_classifier.global_layers.2.2.weight param num:  128
name:  layer_classifier.global_layers.2.2.bias param num:  128
name:  layer_classifier.linear.weight param num:  16640
name:  layer_classifier.linear.bias param num:  130
name:  node_classifier.layer_score.weight param num:  66560
name:  node_classifier.layer_score.bias param num:  512
name:  node_classifier.node_score.weight param num:  524288
name:  node_classifier.node_score.bias param num:  512
name:  node_classifier.v.weight param num:  524288
name:  node_classifier.v.bias param num:  512
name:  node_classifier.batch_norm1.weight param num:  512
name:  node_classifier.batch_norm1.bias param num:  512
name:  node_classifier.out_proj.weight param num:  796672
name:  node_classifier.out_proj.bias param num:  1556
trainable paras number: 2783960
ep: 0, global_step: 10, layer accuracy: 0.0, total loss: 2.5003232955932617, layer loss: 1.4004613161087036, node loss: 1.0998618602752686
ep: 0, global_step: 20, layer accuracy: 0.0, total loss: 2.5261974334716797, layer loss: 1.2404155731201172, node loss: 1.2857818603515625
ep: 0, global_step: 30, layer accuracy: 0.196875, total loss: 2.2135019302368164, layer loss: 1.0307292938232422, node loss: 1.1827725172042847
ep: 0, global_step: 40, layer accuracy: 0.30625, total loss: 1.6439170837402344, layer loss: 0.7983662486076355, node loss: 0.8455508947372437
ep: 0, global_step: 50, layer accuracy: 0.346875, total loss: 1.3132903575897217, layer loss: 0.5573631525039673, node loss: 0.7559272050857544
ep: 0, global_step: 60, layer accuracy: 0.296875, total loss: 1.1613097190856934, layer loss: 0.38933438062667847, node loss: 0.7719753980636597
ep: 0, global_step: 70, layer accuracy: 0.315625, total loss: 0.924387514591217, layer loss: 0.27377551794052124, node loss: 0.6506119966506958
ep: 0, global_step: 80, layer accuracy: 0.309375, total loss: 0.9850437045097351, layer loss: 0.21717612445354462, node loss: 0.7678675651550293
ep: 0, global_step: 90, layer accuracy: 0.35, total loss: 0.8203436136245728, layer loss: 0.17431680858135223, node loss: 0.6460268497467041
ep: 0, global_step: 100, layer accuracy: 0.365625, total loss: 0.7685911655426025, layer loss: 0.15005208551883698, node loss: 0.6185390949249268
ep: 0, global_step: 110, layer accuracy: 0.26875, total loss: 0.7184092402458191, layer loss: 0.14147979021072388, node loss: 0.5769294500350952
ep: 0, global_step: 120, layer accuracy: 0.34375, total loss: 0.6596903800964355, layer loss: 0.13447898626327515, node loss: 0.5252113342285156
ep: 0, global_step: 130, layer accuracy: 0.3, total loss: 0.5933423042297363, layer loss: 0.1354658156633377, node loss: 0.4578765034675598
ep: 0, global_step: 140, layer accuracy: 0.309375, total loss: 0.5957267880439758, layer loss: 0.12976858019828796, node loss: 0.4659581780433655
ep: 0, global_step: 150, layer accuracy: 0.328125, total loss: 0.6395339965820312, layer loss: 0.12369472533464432, node loss: 0.5158393383026123
ep: 0, global_step: 160, layer accuracy: 0.325, total loss: 0.5166522264480591, layer loss: 0.11313779652118683, node loss: 0.40351444482803345
ep: 0, global_step: 170, layer accuracy: 0.371875, total loss: 0.6491364240646362, layer loss: 0.116785928606987, node loss: 0.5323505401611328
ep: 0, global_step: 180, layer accuracy: 0.371875, total loss: 0.536807656288147, layer loss: 0.1150922030210495, node loss: 0.4217154383659363
ep: 0, global_step: 190, layer accuracy: 0.4, total loss: 0.5820816159248352, layer loss: 0.10879494994878769, node loss: 0.4732866883277893
ep: 0, global_step: 200, layer accuracy: 0.340625, total loss: 0.5979205369949341, layer loss: 0.1073065847158432, node loss: 0.49061399698257446
save checkpoint -> step_200
[2024-10-30 15:28:43,799] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-10-30 15:28:44,820] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts3/step_200/pytorch_model/mp_rank_00_model_states.pt
[2024-10-30 15:28:44,821] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts3/step_200/pytorch_model/mp_rank_00_model_states.pt...
[2024-10-30 15:28:48,925] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts3/step_200/pytorch_model/mp_rank_00_model_states.pt.
[2024-10-30 15:28:49,005] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts3/step_200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-10-30 15:28:49,005] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts3/step_200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-10-30 15:28:49,021] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts3/step_200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-10-30 15:28:49,021] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts3/step_200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-10-30 15:28:49,021] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-10-30 15:28:49,021] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts3/step_200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-10-30 15:28:49,021] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts3/step_200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-10-30 15:28:49,021] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_200 saved!
ep: 0, global_step: 210, layer accuracy: 0.353125, total loss: 0.6023999452590942, layer loss: 0.10956867039203644, node loss: 0.492831289768219
ep: 0, global_step: 220, layer accuracy: 0.390625, total loss: 0.5696378946304321, layer loss: 0.10123248398303986, node loss: 0.46840542554855347
