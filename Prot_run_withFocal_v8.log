ep: 0, global_step: 10, layer accuracy: 0.0, layer loss: 4.806251525878906, 
ep: 0, global_step: 20, layer accuracy: 0.0, layer loss: 4.641204357147217, 
ep: 0, global_step: 30, layer accuracy: 0.0, layer loss: 4.484798431396484, 
ep: 0, global_step: 40, layer accuracy: 0.0, layer loss: 4.3915629386901855, 
ep: 0, global_step: 50, layer accuracy: 0.0, layer loss: 4.273779392242432, 
ep: 0, global_step: 60, layer accuracy: 0.0, layer loss: 4.120880603790283, 
ep: 0, global_step: 70, layer accuracy: 0.0, layer loss: 4.014394283294678, 
ep: 0, global_step: 80, layer accuracy: 0.0, layer loss: 4.016874313354492, 
ep: 0, global_step: 90, layer accuracy: 0.0, layer loss: 3.8066658973693848, 
ep: 0, global_step: 100, layer accuracy: 0.0, layer loss: 3.6300535202026367, 
ep: 0, global_step: 110, layer accuracy: 0.0, layer loss: 3.596989631652832, 
ep: 0, global_step: 120, layer accuracy: 0.0, layer loss: 3.4611592292785645, 
ep: 0, global_step: 130, layer accuracy: 0.0, layer loss: 3.386512041091919, 
ep: 0, global_step: 140, layer accuracy: 0.0, layer loss: 3.3421974182128906, 
ep: 0, global_step: 150, layer accuracy: 0.0, layer loss: 3.175016403198242, 
ep: 0, global_step: 160, layer accuracy: 0.0, layer loss: 3.211514472961426, 
ep: 0, global_step: 170, layer accuracy: 0.0, layer loss: 3.0628132820129395, 
ep: 0, global_step: 180, layer accuracy: 0.0, layer loss: 3.0772831439971924, 
ep: 0, global_step: 190, layer accuracy: 0.0, layer loss: 3.0006680488586426, 
ep: 0, global_step: 200, layer accuracy: 0.0, layer loss: 2.911306381225586, 
ep: 0, global_step: 210, layer accuracy: 0.0, layer loss: 2.912041664123535, 
ep: 0, global_step: 220, layer accuracy: 0.0, layer loss: 2.8360137939453125, 
ep: 0, global_step: 230, layer accuracy: 0.0, layer loss: 2.8459692001342773, 
ep: 0, global_step: 240, layer accuracy: 0.0, layer loss: 2.843876361846924, 
ep: 0, global_step: 250, layer accuracy: 0.0, layer loss: 2.761082172393799, 
ep: 0, global_step: 260, layer accuracy: 0.0, layer loss: 2.7401175498962402, 
ep: 0, global_step: 270, layer accuracy: 0.0, layer loss: 2.6817214488983154, 
ep: 0, global_step: 280, layer accuracy: 0.0, layer loss: 2.648850917816162, 
ep: 0, global_step: 290, layer accuracy: 0.0, layer loss: 2.658540725708008, 
ep: 0, global_step: 300, layer accuracy: 0.0, layer loss: 2.7022976875305176, 
ep: 0, global_step: 310, layer accuracy: 0.0, layer loss: 2.5977869033813477, 
ep: 0, global_step: 320, layer accuracy: 0.0, layer loss: 2.557025909423828, 
ep: 0, global_step: 330, layer accuracy: 0.0, layer loss: 2.526646852493286, 
ep: 0, global_step: 340, layer accuracy: 0.0, layer loss: 2.454568386077881, 
ep: 0, global_step: 350, layer accuracy: 0.0, layer loss: 2.469029664993286, 
ep: 0, global_step: 360, layer accuracy: 0.0, layer loss: 2.494333028793335, 
ep: 0, global_step: 370, layer accuracy: 0.0, layer loss: 2.3491101264953613, 
ep: 0, global_step: 380, layer accuracy: 0.01171875, layer loss: 2.3728342056274414, 
ep: 0, global_step: 390, layer accuracy: 0.02734375, layer loss: 2.3484935760498047, 
ep: 0, global_step: 400, layer accuracy: 0.0078125, layer loss: 2.3512372970581055, 
save checkpoint -> step_400
[2024-11-26 20:37:17,696] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-26 20:37:18,683] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_400/pytorch_model/mp_rank_00_model_states.pt
[2024-11-26 20:37:18,683] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_400/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-26 20:37:22,807] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_400/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-26 20:37:22,861] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-26 20:37:22,861] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-26 20:37:22,869] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-26 20:37:22,869] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-26 20:37:22,869] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-26 20:37:22,869] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-26 20:37:22,869] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-26 20:37:22,869] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_400 saved!
ep: 0, global_step: 410, layer accuracy: 0.0234375, layer loss: 2.2844226360321045, 
ep: 0, global_step: 420, layer accuracy: 0.0625, layer loss: 2.2415335178375244, 
ep: 0, global_step: 430, layer accuracy: 0.06640625, layer loss: 2.2081146240234375, 
ep: 0, global_step: 440, layer accuracy: 0.15234375, layer loss: 2.2272510528564453, 
ep: 0, global_step: 450, layer accuracy: 0.14453125, layer loss: 2.2019619941711426, 
ep: 0, global_step: 460, layer accuracy: 0.16015625, layer loss: 2.1938323974609375, 
ep: 0, global_step: 470, layer accuracy: 0.2578125, layer loss: 2.1766738891601562, 
ep: 0, global_step: 480, layer accuracy: 0.24609375, layer loss: 2.089841842651367, 
ep: 0, global_step: 490, layer accuracy: 0.22265625, layer loss: 2.0506038665771484, 
ep: 0, global_step: 500, layer accuracy: 0.19921875, layer loss: 2.0832629203796387, 
ep: 0, global_step: 510, layer accuracy: 0.26171875, layer loss: 2.071765422821045, 
valid layer_batch_acc: 0.4416527272413734
ep: 0, time: 11857.980554580688
训练集的acc: 0.0
验证集的acc: 0.0
ep: 1, global_step: 520, layer accuracy: 0.2890625, layer loss: 1.9967057704925537, 
ep: 1, global_step: 530, layer accuracy: 0.28125, layer loss: 2.0158982276916504, 
ep: 1, global_step: 540, layer accuracy: 0.22265625, layer loss: 1.9644676446914673, 
ep: 1, global_step: 550, layer accuracy: 0.27734375, layer loss: 1.9228579998016357, 
ep: 1, global_step: 560, layer accuracy: 0.16796875, layer loss: 1.8692599534988403, 
ep: 1, global_step: 570, layer accuracy: 0.25, layer loss: 1.9194483757019043, 
ep: 1, global_step: 580, layer accuracy: 0.23828125, layer loss: 1.7987436056137085, 
ep: 1, global_step: 590, layer accuracy: 0.22265625, layer loss: 1.8410284519195557, 
ep: 1, global_step: 600, layer accuracy: 0.3046875, layer loss: 1.7735437154769897, 
ep: 1, global_step: 610, layer accuracy: 0.27734375, layer loss: 1.7468907833099365, 
ep: 1, global_step: 620, layer accuracy: 0.2734375, layer loss: 1.7413873672485352, 
ep: 1, global_step: 630, layer accuracy: 0.3203125, layer loss: 1.7964245080947876, 
ep: 1, global_step: 640, layer accuracy: 0.30078125, layer loss: 1.722226619720459, 
ep: 1, global_step: 650, layer accuracy: 0.3046875, layer loss: 1.6724615097045898, 
ep: 1, global_step: 660, layer accuracy: 0.27734375, layer loss: 1.64492666721344, 
ep: 1, global_step: 670, layer accuracy: 0.296875, layer loss: 1.644130825996399, 
ep: 1, global_step: 680, layer accuracy: 0.3203125, layer loss: 1.5640065670013428, 
ep: 1, global_step: 690, layer accuracy: 0.30859375, layer loss: 1.5910422801971436, 
ep: 1, global_step: 700, layer accuracy: 0.29296875, layer loss: 1.562255620956421, 
ep: 1, global_step: 710, layer accuracy: 0.27734375, layer loss: 1.486173152923584, 
ep: 1, global_step: 720, layer accuracy: 0.32421875, layer loss: 1.5586928129196167, 
ep: 1, global_step: 730, layer accuracy: 0.31640625, layer loss: 1.5616323947906494, 
ep: 1, global_step: 740, layer accuracy: 0.33203125, layer loss: 1.41787588596344, 
ep: 1, global_step: 750, layer accuracy: 0.30859375, layer loss: 1.4380743503570557, 
ep: 1, global_step: 760, layer accuracy: 0.37109375, layer loss: 1.4069445133209229, 
ep: 1, global_step: 770, layer accuracy: 0.33203125, layer loss: 1.4435184001922607, 
ep: 1, global_step: 780, layer accuracy: 0.35546875, layer loss: 1.381103754043579, 
ep: 1, global_step: 790, layer accuracy: 0.37109375, layer loss: 1.3563952445983887, 
ep: 1, global_step: 800, layer accuracy: 0.3125, layer loss: 1.4376857280731201, 
save checkpoint -> step_800
[2024-11-26 23:22:44,777] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-26 23:22:45,787] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_800/pytorch_model/mp_rank_00_model_states.pt
[2024-11-26 23:22:45,787] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_800/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-26 23:22:49,917] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_800/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-26 23:22:50,003] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-26 23:22:50,003] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_800/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-26 23:22:50,012] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_800/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-26 23:22:50,012] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_800/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-26 23:22:50,012] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-26 23:22:50,012] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-26 23:22:50,012] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-26 23:22:50,012] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_800 saved!
ep: 1, global_step: 810, layer accuracy: 0.359375, layer loss: 1.2732701301574707, 
ep: 1, global_step: 820, layer accuracy: 0.33203125, layer loss: 1.2765443325042725, 
ep: 1, global_step: 830, layer accuracy: 0.37109375, layer loss: 1.3059823513031006, 
ep: 1, global_step: 840, layer accuracy: 0.328125, layer loss: 1.204845905303955, 
ep: 1, global_step: 850, layer accuracy: 0.37109375, layer loss: 1.2492183446884155, 
ep: 1, global_step: 860, layer accuracy: 0.33984375, layer loss: 1.2155652046203613, 
ep: 1, global_step: 870, layer accuracy: 0.38671875, layer loss: 1.1744587421417236, 
ep: 1, global_step: 880, layer accuracy: 0.375, layer loss: 1.1753394603729248, 
ep: 1, global_step: 890, layer accuracy: 0.328125, layer loss: 1.180814504623413, 
ep: 1, global_step: 900, layer accuracy: 0.33203125, layer loss: 1.0972782373428345, 
ep: 1, global_step: 910, layer accuracy: 0.36328125, layer loss: 1.1097593307495117, 
ep: 1, global_step: 920, layer accuracy: 0.3828125, layer loss: 1.065047025680542, 
ep: 1, global_step: 930, layer accuracy: 0.3046875, layer loss: 1.0775752067565918, 
ep: 1, global_step: 940, layer accuracy: 0.35546875, layer loss: 1.051481008529663, 
ep: 1, global_step: 950, layer accuracy: 0.3828125, layer loss: 1.0107409954071045, 
ep: 1, global_step: 960, layer accuracy: 0.3671875, layer loss: 1.0305769443511963, 
ep: 1, global_step: 970, layer accuracy: 0.30859375, layer loss: 1.272011637687683, 
ep: 1, global_step: 980, layer accuracy: 0.375, layer loss: 0.9842230081558228, 
ep: 1, global_step: 990, layer accuracy: 0.33203125, layer loss: 0.970862627029419, 
ep: 1, global_step: 1000, layer accuracy: 0.34765625, layer loss: 0.9865196943283081, 
ep: 1, global_step: 1010, layer accuracy: 0.359375, layer loss: 0.9967103004455566, 
ep: 1, global_step: 1020, layer accuracy: 0.40234375, layer loss: 0.9386183023452759, 
ep: 1, global_step: 1030, layer accuracy: 0.33984375, layer loss: 1.0002782344818115, 
valid layer_batch_acc: 0.5827743192674473
ep: 1, time: 23710.19570016861
训练集的acc: 0.0
验证集的acc: 0.0
ep: 2, global_step: 1040, layer accuracy: 0.37109375, layer loss: 0.9300057291984558, 
ep: 2, global_step: 1050, layer accuracy: 0.39453125, layer loss: 0.9166592359542847, 
ep: 2, global_step: 1060, layer accuracy: 0.40625, layer loss: 0.8986786603927612, 
ep: 2, global_step: 1070, layer accuracy: 0.453125, layer loss: 0.843623161315918, 
ep: 2, global_step: 1080, layer accuracy: 0.41796875, layer loss: 0.9166789054870605, 
ep: 2, global_step: 1090, layer accuracy: 0.375, layer loss: 0.9952178001403809, 
ep: 2, global_step: 1100, layer accuracy: 0.3984375, layer loss: 0.8516008257865906, 
ep: 2, global_step: 1110, layer accuracy: 0.40625, layer loss: 0.8818749189376831, 
ep: 2, global_step: 1120, layer accuracy: 0.390625, layer loss: 0.8105928897857666, 
ep: 2, global_step: 1130, layer accuracy: 0.34375, layer loss: 0.9869606494903564, 
ep: 2, global_step: 1140, layer accuracy: 0.3984375, layer loss: 0.8402700424194336, 
ep: 2, global_step: 1150, layer accuracy: 0.4296875, layer loss: 0.8666269779205322, 
ep: 2, global_step: 1160, layer accuracy: 0.390625, layer loss: 0.8411955833435059, 
ep: 2, global_step: 1170, layer accuracy: 0.3515625, layer loss: 0.7772480249404907, 
ep: 2, global_step: 1180, layer accuracy: 0.3359375, layer loss: 0.8241156339645386, 
ep: 2, global_step: 1190, layer accuracy: 0.40625, layer loss: 0.806878387928009, 
ep: 2, global_step: 1200, layer accuracy: 0.34375, layer loss: 0.8912702798843384, 
save checkpoint -> step_1200
[2024-11-27 02:08:11,212] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-27 02:08:12,214] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_1200/pytorch_model/mp_rank_00_model_states.pt
[2024-11-27 02:08:12,215] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_1200/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-27 02:08:16,623] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_1200/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-27 02:08:16,686] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_1200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-27 02:08:16,686] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_1200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-27 02:08:16,694] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_1200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-27 02:08:16,694] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_1200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-27 02:08:16,694] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-27 02:08:16,694] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_1200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-27 02:08:16,694] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_1200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-27 02:08:16,694] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_1200 saved!
ep: 2, global_step: 1210, layer accuracy: 0.359375, layer loss: 0.7587029933929443, 
ep: 2, global_step: 1220, layer accuracy: 0.359375, layer loss: 0.741966187953949, 
ep: 2, global_step: 1230, layer accuracy: 0.35546875, layer loss: 0.7965226173400879, 
ep: 2, global_step: 1240, layer accuracy: 0.3515625, layer loss: 0.7584064602851868, 
ep: 2, global_step: 1250, layer accuracy: 0.34375, layer loss: 0.7774596214294434, 
ep: 2, global_step: 1260, layer accuracy: 0.3515625, layer loss: 0.8193050622940063, 
ep: 2, global_step: 1270, layer accuracy: 0.35546875, layer loss: 0.8476884365081787, 
ep: 2, global_step: 1280, layer accuracy: 0.3828125, layer loss: 0.7328882217407227, 
ep: 2, global_step: 1290, layer accuracy: 0.421875, layer loss: 0.7115042805671692, 
ep: 2, global_step: 1300, layer accuracy: 0.46875, layer loss: 0.623836874961853, 
ep: 2, global_step: 1310, layer accuracy: 0.37109375, layer loss: 0.6996440887451172, 
ep: 2, global_step: 1320, layer accuracy: 0.328125, layer loss: 0.7595749497413635, 
ep: 2, global_step: 1330, layer accuracy: 0.41015625, layer loss: 0.6407426595687866, 
ep: 2, global_step: 1340, layer accuracy: 0.3359375, layer loss: 0.7329390048980713, 
ep: 2, global_step: 1350, layer accuracy: 0.42578125, layer loss: 0.6719945669174194, 
ep: 2, global_step: 1360, layer accuracy: 0.4453125, layer loss: 0.6729235649108887, 
ep: 2, global_step: 1370, layer accuracy: 0.4453125, layer loss: 0.6364266872406006, 
ep: 2, global_step: 1380, layer accuracy: 0.375, layer loss: 0.6910547018051147, 
ep: 2, global_step: 1390, layer accuracy: 0.3828125, layer loss: 0.6782480478286743, 
ep: 2, global_step: 1400, layer accuracy: 0.46484375, layer loss: 0.6209304332733154, 
ep: 2, global_step: 1410, layer accuracy: 0.40625, layer loss: 0.6688219308853149, 
ep: 2, global_step: 1420, layer accuracy: 0.375, layer loss: 0.6492939591407776, 
ep: 2, global_step: 1430, layer accuracy: 0.39453125, layer loss: 0.6818886399269104, 
ep: 2, global_step: 1440, layer accuracy: 0.41796875, layer loss: 0.6262185573577881, 
ep: 2, global_step: 1450, layer accuracy: 0.41015625, layer loss: 0.6737587451934814, 
ep: 2, global_step: 1460, layer accuracy: 0.4609375, layer loss: 0.652838945388794, 
ep: 2, global_step: 1470, layer accuracy: 0.390625, layer loss: 0.597834050655365, 
ep: 2, global_step: 1480, layer accuracy: 0.4140625, layer loss: 0.5695333480834961, 
ep: 2, global_step: 1490, layer accuracy: 0.41015625, layer loss: 0.6480038166046143, 
ep: 2, global_step: 1500, layer accuracy: 0.37890625, layer loss: 0.656427800655365, 
ep: 2, global_step: 1510, layer accuracy: 0.42578125, layer loss: 0.6358035802841187, 
ep: 2, global_step: 1520, layer accuracy: 0.4375, layer loss: 0.5876879096031189, 
ep: 2, global_step: 1530, layer accuracy: 0.41796875, layer loss: 0.6878719329833984, 
ep: 2, global_step: 1540, layer accuracy: 0.375, layer loss: 0.6000033617019653, 
ep: 2, global_step: 1550, layer accuracy: 0.41015625, layer loss: 0.6304284930229187, 
valid layer_batch_acc: 0.6154011967786994
ep: 2, time: 35555.96142554283
训练集的acc: 0.0
验证集的acc: 0.0
ep: 3, global_step: 1560, layer accuracy: 0.34375, layer loss: 0.7010795474052429, 
ep: 3, global_step: 1570, layer accuracy: 0.38671875, layer loss: 0.6639436483383179, 
ep: 3, global_step: 1580, layer accuracy: 0.4453125, layer loss: 0.6092151403427124, 
ep: 3, global_step: 1590, layer accuracy: 0.40234375, layer loss: 0.6100680828094482, 
ep: 3, global_step: 1600, layer accuracy: 0.46484375, layer loss: 0.5607506632804871, 
save checkpoint -> step_1600
[2024-11-27 04:53:29,926] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-27 04:53:30,927] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_1600/pytorch_model/mp_rank_00_model_states.pt
[2024-11-27 04:53:30,927] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_1600/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-27 04:53:35,026] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_1600/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-27 04:53:35,089] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_1600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-27 04:53:35,089] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_1600/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-27 04:53:35,097] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_1600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-27 04:53:35,098] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_1600/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-27 04:53:35,098] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_1600/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-27 04:53:35,098] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_1600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-27 04:53:35,098] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-27 04:53:35,098] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_1600 saved!
ep: 3, global_step: 1610, layer accuracy: 0.375, layer loss: 0.6664020419120789, 
ep: 3, global_step: 1620, layer accuracy: 0.40234375, layer loss: 0.5970282554626465, 
ep: 3, global_step: 1630, layer accuracy: 0.4140625, layer loss: 0.5870274901390076, 
ep: 3, global_step: 1640, layer accuracy: 0.484375, layer loss: 0.5576705932617188, 
ep: 3, global_step: 1650, layer accuracy: 0.43359375, layer loss: 0.5279091596603394, 
ep: 3, global_step: 1660, layer accuracy: 0.4609375, layer loss: 0.5903552174568176, 
ep: 3, global_step: 1670, layer accuracy: 0.41796875, layer loss: 0.5664204359054565, 
ep: 3, global_step: 1680, layer accuracy: 0.41015625, layer loss: 0.6007213592529297, 
ep: 3, global_step: 1690, layer accuracy: 0.4296875, layer loss: 0.5967982411384583, 
ep: 3, global_step: 1700, layer accuracy: 0.46875, layer loss: 0.5487698912620544, 
ep: 3, global_step: 1710, layer accuracy: 0.44921875, layer loss: 0.5731977224349976, 
ep: 3, global_step: 1720, layer accuracy: 0.4140625, layer loss: 0.5659859776496887, 
ep: 3, global_step: 1730, layer accuracy: 0.43359375, layer loss: 0.555391788482666, 
ep: 3, global_step: 1740, layer accuracy: 0.5, layer loss: 0.48377668857574463, 
ep: 3, global_step: 1750, layer accuracy: 0.42578125, layer loss: 0.538673460483551, 
ep: 3, global_step: 1760, layer accuracy: 0.47265625, layer loss: 0.5323821902275085, 
ep: 3, global_step: 1770, layer accuracy: 0.46484375, layer loss: 0.5457664132118225, 
ep: 3, global_step: 1780, layer accuracy: 0.49609375, layer loss: 0.549443244934082, 
ep: 3, global_step: 1790, layer accuracy: 0.41015625, layer loss: 0.5841389894485474, 
ep: 3, global_step: 1800, layer accuracy: 0.453125, layer loss: 0.5372876524925232, 
ep: 3, global_step: 1810, layer accuracy: 0.4296875, layer loss: 0.6471818089485168, 
ep: 3, global_step: 1820, layer accuracy: 0.4375, layer loss: 0.6011838912963867, 
ep: 3, global_step: 1830, layer accuracy: 0.3984375, layer loss: 0.537177562713623, 
ep: 3, global_step: 1840, layer accuracy: 0.4453125, layer loss: 0.5517385601997375, 
ep: 3, global_step: 1850, layer accuracy: 0.44140625, layer loss: 0.542411208152771, 
ep: 3, global_step: 1860, layer accuracy: 0.44921875, layer loss: 0.5496790409088135, 
ep: 3, global_step: 1870, layer accuracy: 0.43359375, layer loss: 0.6320338249206543, 
ep: 3, global_step: 1880, layer accuracy: 0.46875, layer loss: 0.5249913930892944, 
ep: 3, global_step: 1890, layer accuracy: 0.42578125, layer loss: 0.5582171678543091, 
ep: 3, global_step: 1900, layer accuracy: 0.47265625, layer loss: 0.5123633146286011, 
ep: 3, global_step: 1910, layer accuracy: 0.42578125, layer loss: 0.5049149990081787, 
ep: 3, global_step: 1920, layer accuracy: 0.4296875, layer loss: 0.5563681125640869, 
ep: 3, global_step: 1930, layer accuracy: 0.4609375, layer loss: 0.526646614074707, 
ep: 3, global_step: 1940, layer accuracy: 0.484375, layer loss: 0.5214183330535889, 
ep: 3, global_step: 1950, layer accuracy: 0.43359375, layer loss: 0.5541971325874329, 
ep: 3, global_step: 1960, layer accuracy: 0.46484375, layer loss: 0.4733797311782837, 
ep: 3, global_step: 1970, layer accuracy: 0.44921875, layer loss: 0.5370441675186157, 
ep: 3, global_step: 1980, layer accuracy: 0.48828125, layer loss: 0.47392207384109497, 
ep: 3, global_step: 1990, layer accuracy: 0.44921875, layer loss: 0.5121896862983704, 
ep: 3, global_step: 2000, layer accuracy: 0.46484375, layer loss: 0.5275595188140869, 
save checkpoint -> step_2000
[2024-11-27 06:42:25,266] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-27 06:42:26,283] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_2000/pytorch_model/mp_rank_00_model_states.pt
[2024-11-27 06:42:26,283] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_2000/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-27 06:42:30,533] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_2000/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-27 06:42:30,598] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_2000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-27 06:42:30,598] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_2000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-27 06:42:30,607] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_2000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-27 06:42:30,607] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_2000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-27 06:42:30,607] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-27 06:42:30,607] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_2000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-27 06:42:30,607] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_2000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-27 06:42:30,607] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_2000 saved!
ep: 3, global_step: 2010, layer accuracy: 0.484375, layer loss: 0.5138190984725952, 
ep: 3, global_step: 2020, layer accuracy: 0.48828125, layer loss: 0.4409518241882324, 
ep: 3, global_step: 2030, layer accuracy: 0.453125, layer loss: 0.4870957136154175, 
ep: 3, global_step: 2040, layer accuracy: 0.48046875, layer loss: 0.5122100114822388, 
ep: 3, global_step: 2050, layer accuracy: 0.4921875, layer loss: 0.5354526042938232, 
ep: 3, global_step: 2060, layer accuracy: 0.46484375, layer loss: 0.48081791400909424, 
ep: 3, global_step: 2070, layer accuracy: 0.45703125, layer loss: 0.5165928602218628, 
valid layer_batch_acc: 0.6547103761058132
ep: 3, time: 47409.90709090233
训练集的acc: 0.0
验证集的acc: 0.0
ep: 4, global_step: 2080, layer accuracy: 0.4453125, layer loss: 0.5070263147354126, 
ep: 4, global_step: 2090, layer accuracy: 0.47265625, layer loss: 0.5208728313446045, 
ep: 4, global_step: 2100, layer accuracy: 0.36328125, layer loss: 0.45365625619888306, 
ep: 4, global_step: 2110, layer accuracy: 0.5, layer loss: 0.45751088857650757, 
ep: 4, global_step: 2120, layer accuracy: 0.4921875, layer loss: 0.4953613579273224, 
ep: 4, global_step: 2130, layer accuracy: 0.46484375, layer loss: 0.5286191701889038, 
ep: 4, global_step: 2140, layer accuracy: 0.44921875, layer loss: 0.499164342880249, 
ep: 4, global_step: 2150, layer accuracy: 0.46875, layer loss: 0.5191296935081482, 
ep: 4, global_step: 2160, layer accuracy: 0.4375, layer loss: 0.47584831714630127, 
ep: 4, global_step: 2170, layer accuracy: 0.47265625, layer loss: 0.519853949546814, 
ep: 4, global_step: 2180, layer accuracy: 0.46875, layer loss: 0.5456217527389526, 
ep: 4, global_step: 2190, layer accuracy: 0.48046875, layer loss: 0.45450708270072937, 
ep: 4, global_step: 2200, layer accuracy: 0.48828125, layer loss: 0.46823054552078247, 
ep: 4, global_step: 2210, layer accuracy: 0.51171875, layer loss: 0.42635786533355713, 
ep: 4, global_step: 2220, layer accuracy: 0.46484375, layer loss: 0.4760299026966095, 
ep: 4, global_step: 2230, layer accuracy: 0.48828125, layer loss: 0.46916306018829346, 
ep: 4, global_step: 2240, layer accuracy: 0.44140625, layer loss: 0.5214153528213501, 
ep: 4, global_step: 2250, layer accuracy: 0.4140625, layer loss: 0.49449244141578674, 
ep: 4, global_step: 2260, layer accuracy: 0.4453125, layer loss: 0.4846384525299072, 
ep: 4, global_step: 2270, layer accuracy: 0.5234375, layer loss: 0.4528580605983734, 
ep: 4, global_step: 2280, layer accuracy: 0.49609375, layer loss: 0.4132593274116516, 
ep: 4, global_step: 2290, layer accuracy: 0.48046875, layer loss: 0.4613173007965088, 
ep: 4, global_step: 2300, layer accuracy: 0.51953125, layer loss: 0.47697317600250244, 
ep: 4, global_step: 2310, layer accuracy: 0.484375, layer loss: 0.45973217487335205, 
ep: 4, global_step: 2320, layer accuracy: 0.48046875, layer loss: 0.4524000287055969, 
ep: 4, global_step: 2330, layer accuracy: 0.43359375, layer loss: 0.5231066942214966, 
ep: 4, global_step: 2340, layer accuracy: 0.5, layer loss: 0.5053339004516602, 
ep: 4, global_step: 2350, layer accuracy: 0.4296875, layer loss: 0.4905659258365631, 
ep: 4, global_step: 2360, layer accuracy: 0.49609375, layer loss: 0.44222110509872437, 
ep: 4, global_step: 2370, layer accuracy: 0.515625, layer loss: 0.4286125898361206, 
ep: 4, global_step: 2380, layer accuracy: 0.44921875, layer loss: 0.5123240351676941, 
ep: 4, global_step: 2390, layer accuracy: 0.51171875, layer loss: 0.477791428565979, 
ep: 4, global_step: 2400, layer accuracy: 0.43359375, layer loss: 0.501327395439148, 
save checkpoint -> step_2400
[2024-11-27 09:27:49,258] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-27 09:27:50,273] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_2400/pytorch_model/mp_rank_00_model_states.pt
[2024-11-27 09:27:50,273] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_2400/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-27 09:27:54,581] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_2400/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-27 09:27:54,652] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_2400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-27 09:27:54,652] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_2400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-27 09:27:54,661] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_2400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-27 09:27:54,661] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_2400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-27 09:27:54,661] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-27 09:27:54,661] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_2400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-27 09:27:54,661] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_2400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-27 09:27:54,661] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_2400 saved!
ep: 4, global_step: 2410, layer accuracy: 0.5078125, layer loss: 0.46797752380371094, 
ep: 4, global_step: 2420, layer accuracy: 0.484375, layer loss: 0.5456051826477051, 
ep: 4, global_step: 2430, layer accuracy: 0.5390625, layer loss: 0.4150736331939697, 
ep: 4, global_step: 2440, layer accuracy: 0.484375, layer loss: 0.4361022710800171, 
ep: 4, global_step: 2450, layer accuracy: 0.5, layer loss: 0.5122964382171631, 
ep: 4, global_step: 2460, layer accuracy: 0.5078125, layer loss: 0.42244988679885864, 
ep: 4, global_step: 2470, layer accuracy: 0.44921875, layer loss: 0.4678838849067688, 
ep: 4, global_step: 2480, layer accuracy: 0.54296875, layer loss: 0.439263254404068, 
ep: 4, global_step: 2490, layer accuracy: 0.5390625, layer loss: 0.4657873213291168, 
ep: 4, global_step: 2500, layer accuracy: 0.4921875, layer loss: 0.4058566689491272, 
ep: 4, global_step: 2510, layer accuracy: 0.46875, layer loss: 0.41963210701942444, 
ep: 4, global_step: 2520, layer accuracy: 0.4453125, layer loss: 0.49847841262817383, 
ep: 4, global_step: 2530, layer accuracy: 0.484375, layer loss: 0.49387845396995544, 
ep: 4, global_step: 2540, layer accuracy: 0.49609375, layer loss: 0.4862389862537384, 
ep: 4, global_step: 2550, layer accuracy: 0.48828125, layer loss: 0.49490809440612793, 
ep: 4, global_step: 2560, layer accuracy: 0.4921875, layer loss: 0.4503491520881653, 
ep: 4, global_step: 2570, layer accuracy: 0.484375, layer loss: 0.4389978051185608, 
ep: 4, global_step: 2580, layer accuracy: 0.546875, layer loss: 0.40866076946258545, 
ep: 4, global_step: 2590, layer accuracy: 0.5061728395061729, layer loss: 0.4157469868659973, 
valid layer_batch_acc: 0.6831899153287693
ep: 4, time: 59261.01961994171
训练集的acc: 0.0
验证集的acc: 0.0
ep: 5, global_step: 2600, layer accuracy: 0.5625, layer loss: 0.4056219458580017, 
ep: 5, global_step: 2610, layer accuracy: 0.46875, layer loss: 0.4910134971141815, 
ep: 5, global_step: 2620, layer accuracy: 0.47265625, layer loss: 0.5051132440567017, 
ep: 5, global_step: 2630, layer accuracy: 0.48046875, layer loss: 0.42827561497688293, 
ep: 5, global_step: 2640, layer accuracy: 0.48828125, layer loss: 0.4704733192920685, 
ep: 5, global_step: 2650, layer accuracy: 0.5078125, layer loss: 0.47672703862190247, 
ep: 5, global_step: 2660, layer accuracy: 0.5078125, layer loss: 0.41048330068588257, 
ep: 5, global_step: 2670, layer accuracy: 0.51953125, layer loss: 0.4537220299243927, 
ep: 5, global_step: 2680, layer accuracy: 0.5, layer loss: 0.45918625593185425, 
ep: 5, global_step: 2690, layer accuracy: 0.515625, layer loss: 0.3798842132091522, 
ep: 5, global_step: 2700, layer accuracy: 0.3984375, layer loss: 0.44140079617500305, 
ep: 5, global_step: 2710, layer accuracy: 0.53125, layer loss: 0.3969287574291229, 
ep: 5, global_step: 2720, layer accuracy: 0.52734375, layer loss: 0.38895025849342346, 
ep: 5, global_step: 2730, layer accuracy: 0.55859375, layer loss: 0.37767601013183594, 
ep: 5, global_step: 2740, layer accuracy: 0.48828125, layer loss: 0.43344441056251526, 
ep: 5, global_step: 2750, layer accuracy: 0.4921875, layer loss: 0.4422456920146942, 
ep: 5, global_step: 2760, layer accuracy: 0.4609375, layer loss: 0.47413370013237, 
ep: 5, global_step: 2770, layer accuracy: 0.50390625, layer loss: 0.4208892583847046, 
ep: 5, global_step: 2780, layer accuracy: 0.48046875, layer loss: 0.48549193143844604, 
ep: 5, global_step: 2790, layer accuracy: 0.47265625, layer loss: 0.45795580744743347, 
ep: 5, global_step: 2800, layer accuracy: 0.578125, layer loss: 0.3741050362586975, 
save checkpoint -> step_2800
[2024-11-27 12:13:12,324] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-27 12:13:13,358] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_2800/pytorch_model/mp_rank_00_model_states.pt
[2024-11-27 12:13:13,358] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_2800/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-27 12:13:17,697] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_2800/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-27 12:13:17,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_2800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-27 12:13:17,773] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_2800/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-27 12:13:17,781] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_2800/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-27 12:13:17,781] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_2800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-27 12:13:17,781] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_2800/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-27 12:13:17,781] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-27 12:13:17,781] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_2800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-27 12:13:17,782] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_2800 saved!
ep: 5, global_step: 2810, layer accuracy: 0.4921875, layer loss: 0.39823365211486816, 
ep: 5, global_step: 2820, layer accuracy: 0.53515625, layer loss: 0.36815786361694336, 
ep: 5, global_step: 2830, layer accuracy: 0.54296875, layer loss: 0.39483052492141724, 
ep: 5, global_step: 2840, layer accuracy: 0.484375, layer loss: 0.4281863570213318, 
ep: 5, global_step: 2850, layer accuracy: 0.578125, layer loss: 0.32585886120796204, 
ep: 5, global_step: 2860, layer accuracy: 0.50390625, layer loss: 0.4150486886501312, 
ep: 5, global_step: 2870, layer accuracy: 0.52734375, layer loss: 0.410696804523468, 
ep: 5, global_step: 2880, layer accuracy: 0.49609375, layer loss: 0.42984360456466675, 
ep: 5, global_step: 2890, layer accuracy: 0.5625, layer loss: 0.40656566619873047, 
ep: 5, global_step: 2900, layer accuracy: 0.55078125, layer loss: 0.3805723190307617, 
ep: 5, global_step: 2910, layer accuracy: 0.55078125, layer loss: 0.45140546560287476, 
ep: 5, global_step: 2920, layer accuracy: 0.5078125, layer loss: 0.41292160749435425, 
ep: 5, global_step: 2930, layer accuracy: 0.5078125, layer loss: 0.45806246995925903, 
ep: 5, global_step: 2940, layer accuracy: 0.49609375, layer loss: 0.4872548580169678, 
ep: 5, global_step: 2950, layer accuracy: 0.4765625, layer loss: 0.4197254776954651, 
ep: 5, global_step: 2960, layer accuracy: 0.4296875, layer loss: 0.4650473892688751, 
ep: 5, global_step: 2970, layer accuracy: 0.51953125, layer loss: 0.42614656686782837, 
ep: 5, global_step: 2980, layer accuracy: 0.51171875, layer loss: 0.38180169463157654, 
ep: 5, global_step: 2990, layer accuracy: 0.5390625, layer loss: 0.4209437966346741, 
ep: 5, global_step: 3000, layer accuracy: 0.50390625, layer loss: 0.4487420320510864, 
ep: 5, global_step: 3010, layer accuracy: 0.5390625, layer loss: 0.396104097366333, 
ep: 5, global_step: 3020, layer accuracy: 0.578125, layer loss: 0.3705793619155884, 
ep: 5, global_step: 3030, layer accuracy: 0.5546875, layer loss: 0.4106424152851105, 
ep: 5, global_step: 3040, layer accuracy: 0.57421875, layer loss: 0.39682984352111816, 
ep: 5, global_step: 3050, layer accuracy: 0.546875, layer loss: 0.33480411767959595, 
ep: 5, global_step: 3060, layer accuracy: 0.5, layer loss: 0.4090101718902588, 
ep: 5, global_step: 3070, layer accuracy: 0.50390625, layer loss: 0.36573001742362976, 
ep: 5, global_step: 3080, layer accuracy: 0.52734375, layer loss: 0.4235444664955139, 
ep: 5, global_step: 3090, layer accuracy: 0.46875, layer loss: 0.4863113760948181, 
ep: 5, global_step: 3100, layer accuracy: 0.52734375, layer loss: 0.3636149764060974, 
valid layer_batch_acc: 0.7112124713307696
ep: 5, time: 71103.73967313766
训练集的acc: 0.0
验证集的acc: 0.0
ep: 6, global_step: 3110, layer accuracy: 0.50390625, layer loss: 0.40235286951065063, 
ep: 6, global_step: 3120, layer accuracy: 0.4453125, layer loss: 0.4586367905139923, 
ep: 6, global_step: 3130, layer accuracy: 0.4375, layer loss: 0.4325936436653137, 
ep: 6, global_step: 3140, layer accuracy: 0.5234375, layer loss: 0.39332401752471924, 
ep: 6, global_step: 3150, layer accuracy: 0.49609375, layer loss: 0.37010616064071655, 
ep: 6, global_step: 3160, layer accuracy: 0.53515625, layer loss: 0.42461487650871277, 
ep: 6, global_step: 3170, layer accuracy: 0.53125, layer loss: 0.3729640245437622, 
ep: 6, global_step: 3180, layer accuracy: 0.515625, layer loss: 0.43466195464134216, 
ep: 6, global_step: 3190, layer accuracy: 0.5390625, layer loss: 0.3736379146575928, 
ep: 6, global_step: 3200, layer accuracy: 0.5546875, layer loss: 0.40745505690574646, 
save checkpoint -> step_3200
[2024-11-27 14:58:26,928] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-27 14:58:27,959] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_3200/pytorch_model/mp_rank_00_model_states.pt
[2024-11-27 14:58:27,959] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_3200/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-27 14:58:32,167] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_3200/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-27 14:58:32,243] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_3200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-27 14:58:32,243] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_3200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-27 14:58:32,252] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_3200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-27 14:58:32,252] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_3200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-27 14:58:32,252] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-27 14:58:32,252] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_3200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-27 14:58:32,252] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_3200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-27 14:58:32,252] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_3200 saved!
ep: 6, global_step: 3210, layer accuracy: 0.4921875, layer loss: 0.4021676182746887, 
ep: 6, global_step: 3220, layer accuracy: 0.5078125, layer loss: 0.38965514302253723, 
ep: 6, global_step: 3230, layer accuracy: 0.6015625, layer loss: 0.3502161502838135, 
ep: 6, global_step: 3240, layer accuracy: 0.50390625, layer loss: 0.41203171014785767, 
ep: 6, global_step: 3250, layer accuracy: 0.50390625, layer loss: 0.431829035282135, 
ep: 6, global_step: 3260, layer accuracy: 0.51171875, layer loss: 0.3693050146102905, 
ep: 6, global_step: 3270, layer accuracy: 0.52734375, layer loss: 0.4160771071910858, 
ep: 6, global_step: 3280, layer accuracy: 0.51171875, layer loss: 0.42839306592941284, 
ep: 6, global_step: 3290, layer accuracy: 0.5625, layer loss: 0.3975791931152344, 
ep: 6, global_step: 3300, layer accuracy: 0.5703125, layer loss: 0.35140806436538696, 
ep: 6, global_step: 3310, layer accuracy: 0.51953125, layer loss: 0.36906254291534424, 
ep: 6, global_step: 3320, layer accuracy: 0.55078125, layer loss: 0.32595622539520264, 
ep: 6, global_step: 3330, layer accuracy: 0.55078125, layer loss: 0.41143131256103516, 
ep: 6, global_step: 3340, layer accuracy: 0.53515625, layer loss: 0.42037469148635864, 
ep: 6, global_step: 3350, layer accuracy: 0.5078125, layer loss: 0.46369898319244385, 
ep: 6, global_step: 3360, layer accuracy: 0.53515625, layer loss: 0.42232269048690796, 
ep: 6, global_step: 3370, layer accuracy: 0.546875, layer loss: 0.37338823080062866, 
ep: 6, global_step: 3380, layer accuracy: 0.52734375, layer loss: 0.3806219696998596, 
ep: 6, global_step: 3390, layer accuracy: 0.55078125, layer loss: 0.3479808270931244, 
ep: 6, global_step: 3400, layer accuracy: 0.484375, layer loss: 0.4300428330898285, 
ep: 6, global_step: 3410, layer accuracy: 0.50390625, layer loss: 0.3638923168182373, 
ep: 6, global_step: 3420, layer accuracy: 0.55859375, layer loss: 0.42721128463745117, 
ep: 6, global_step: 3430, layer accuracy: 0.5, layer loss: 0.42995408177375793, 
ep: 6, global_step: 3440, layer accuracy: 0.51171875, layer loss: 0.3755037188529968, 
ep: 6, global_step: 3450, layer accuracy: 0.4609375, layer loss: 0.42497730255126953, 
ep: 6, global_step: 3460, layer accuracy: 0.53125, layer loss: 0.4216282367706299, 
ep: 6, global_step: 3470, layer accuracy: 0.5234375, layer loss: 0.3456299304962158, 
ep: 6, global_step: 3480, layer accuracy: 0.53515625, layer loss: 0.4013715088367462, 
ep: 6, global_step: 3490, layer accuracy: 0.53125, layer loss: 0.3739456832408905, 
ep: 6, global_step: 3500, layer accuracy: 0.5, layer loss: 0.41699981689453125, 
ep: 6, global_step: 3510, layer accuracy: 0.515625, layer loss: 0.4154711365699768, 
ep: 6, global_step: 3520, layer accuracy: 0.47265625, layer loss: 0.43787989020347595, 
ep: 6, global_step: 3530, layer accuracy: 0.52734375, layer loss: 0.3499453663825989, 
ep: 6, global_step: 3540, layer accuracy: 0.55859375, layer loss: 0.35835570096969604, 
ep: 6, global_step: 3550, layer accuracy: 0.59375, layer loss: 0.28656405210494995, 
ep: 6, global_step: 3560, layer accuracy: 0.52734375, layer loss: 0.4380289912223816, 
ep: 6, global_step: 3570, layer accuracy: 0.546875, layer loss: 0.3757721781730652, 
ep: 6, global_step: 3580, layer accuracy: 0.5859375, layer loss: 0.33543306589126587, 
ep: 6, global_step: 3590, layer accuracy: 0.53515625, layer loss: 0.4454389214515686, 
ep: 6, global_step: 3600, layer accuracy: 0.56640625, layer loss: 0.37211835384368896, 
save checkpoint -> step_3600
[2024-11-27 16:47:21,392] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-27 16:47:22,442] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_3600/pytorch_model/mp_rank_00_model_states.pt
[2024-11-27 16:47:22,442] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_3600/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-27 16:47:26,751] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_3600/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-27 16:47:26,863] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_3600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-27 16:47:26,864] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_3600/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-27 16:47:26,872] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_3600/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-27 16:47:26,872] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_3600/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-27 16:47:26,872] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-27 16:47:26,872] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_3600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-27 16:47:26,873] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_3600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-27 16:47:26,873] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_3600 saved!
ep: 6, global_step: 3610, layer accuracy: 0.515625, layer loss: 0.33137246966362, 
ep: 6, global_step: 3620, layer accuracy: 0.53125, layer loss: 0.40581026673316956, 
valid layer_batch_acc: 0.7214989049647347
ep: 6, time: 82957.18030023575
训练集的acc: 0.0
验证集的acc: 0.0
ep: 7, global_step: 3630, layer accuracy: 0.50390625, layer loss: 0.36401158571243286, 
ep: 7, global_step: 3640, layer accuracy: 0.54296875, layer loss: 0.3938029706478119, 
ep: 7, global_step: 3650, layer accuracy: 0.484375, layer loss: 0.4053901433944702, 
ep: 7, global_step: 3660, layer accuracy: 0.5546875, layer loss: 0.3560260832309723, 
ep: 7, global_step: 3670, layer accuracy: 0.5390625, layer loss: 0.43522098660469055, 
ep: 7, global_step: 3680, layer accuracy: 0.59765625, layer loss: 0.32483822107315063, 
ep: 7, global_step: 3690, layer accuracy: 0.54296875, layer loss: 0.4038201868534088, 
ep: 7, global_step: 3700, layer accuracy: 0.5859375, layer loss: 0.37918606400489807, 
ep: 7, global_step: 3710, layer accuracy: 0.5703125, layer loss: 0.3043123483657837, 
ep: 7, global_step: 3720, layer accuracy: 0.51171875, layer loss: 0.44920241832733154, 
ep: 7, global_step: 3730, layer accuracy: 0.51953125, layer loss: 0.38000696897506714, 
ep: 7, global_step: 3740, layer accuracy: 0.5390625, layer loss: 0.3953825831413269, 
ep: 7, global_step: 3750, layer accuracy: 0.49609375, layer loss: 0.3456716239452362, 
ep: 7, global_step: 3760, layer accuracy: 0.51171875, layer loss: 0.36427420377731323, 
ep: 7, global_step: 3770, layer accuracy: 0.54296875, layer loss: 0.3520581126213074, 
ep: 7, global_step: 3780, layer accuracy: 0.484375, layer loss: 0.402511328458786, 
ep: 7, global_step: 3790, layer accuracy: 0.5234375, layer loss: 0.3794182538986206, 
ep: 7, global_step: 3800, layer accuracy: 0.515625, layer loss: 0.3631919324398041, 
ep: 7, global_step: 3810, layer accuracy: 0.56640625, layer loss: 0.3642643392086029, 
ep: 7, global_step: 3820, layer accuracy: 0.5546875, layer loss: 0.3625805974006653, 
ep: 7, global_step: 3830, layer accuracy: 0.515625, layer loss: 0.36901146173477173, 
ep: 7, global_step: 3840, layer accuracy: 0.56640625, layer loss: 0.3737541139125824, 
ep: 7, global_step: 3850, layer accuracy: 0.6171875, layer loss: 0.3342071771621704, 
ep: 7, global_step: 3860, layer accuracy: 0.5390625, layer loss: 0.3936336040496826, 
ep: 7, global_step: 3870, layer accuracy: 0.54296875, layer loss: 0.46956494450569153, 
ep: 7, global_step: 3880, layer accuracy: 0.4921875, layer loss: 0.33814793825149536, 
ep: 7, global_step: 3890, layer accuracy: 0.53125, layer loss: 0.32074180245399475, 
ep: 7, global_step: 3900, layer accuracy: 0.5, layer loss: 0.4256642758846283, 
ep: 7, global_step: 3910, layer accuracy: 0.55078125, layer loss: 0.34836819767951965, 
ep: 7, global_step: 3920, layer accuracy: 0.56640625, layer loss: 0.3594260811805725, 
ep: 7, global_step: 3930, layer accuracy: 0.54296875, layer loss: 0.3784187138080597, 
ep: 7, global_step: 3940, layer accuracy: 0.5078125, layer loss: 0.3646436631679535, 
ep: 7, global_step: 3950, layer accuracy: 0.5234375, layer loss: 0.39424198865890503, 
ep: 7, global_step: 3960, layer accuracy: 0.54296875, layer loss: 0.3394010066986084, 
ep: 7, global_step: 3970, layer accuracy: 0.5546875, layer loss: 0.3567239046096802, 
ep: 7, global_step: 3980, layer accuracy: 0.60546875, layer loss: 0.3210092782974243, 
ep: 7, global_step: 3990, layer accuracy: 0.56640625, layer loss: 0.33086690306663513, 
ep: 7, global_step: 4000, layer accuracy: 0.5546875, layer loss: 0.34213072061538696, 
save checkpoint -> step_4000
[2024-11-27 19:32:42,803] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-27 19:32:43,842] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_4000/pytorch_model/mp_rank_00_model_states.pt
[2024-11-27 19:32:43,842] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_4000/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-27 19:32:48,075] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_4000/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-27 19:32:48,178] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_4000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-27 19:32:48,178] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_4000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-27 19:32:48,187] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_4000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-27 19:32:48,187] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_4000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-27 19:32:48,187] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-27 19:32:48,187] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_4000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-27 19:32:48,187] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_4000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-27 19:32:48,187] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_4000 saved!
ep: 7, global_step: 4010, layer accuracy: 0.56640625, layer loss: 0.3522738218307495, 
ep: 7, global_step: 4020, layer accuracy: 0.50390625, layer loss: 0.4116367995738983, 
ep: 7, global_step: 4030, layer accuracy: 0.5546875, layer loss: 0.345558762550354, 
ep: 7, global_step: 4040, layer accuracy: 0.546875, layer loss: 0.30534353852272034, 
ep: 7, global_step: 4050, layer accuracy: 0.515625, layer loss: 0.3829001784324646, 
ep: 7, global_step: 4060, layer accuracy: 0.5546875, layer loss: 0.3381127119064331, 
ep: 7, global_step: 4070, layer accuracy: 0.54296875, layer loss: 0.35334861278533936, 
ep: 7, global_step: 4080, layer accuracy: 0.5546875, layer loss: 0.3888711929321289, 
ep: 7, global_step: 4090, layer accuracy: 0.5390625, layer loss: 0.3453161120414734, 
ep: 7, global_step: 4100, layer accuracy: 0.578125, layer loss: 0.31432217359542847, 
ep: 7, global_step: 4110, layer accuracy: 0.51953125, layer loss: 0.3851510286331177, 
ep: 7, global_step: 4120, layer accuracy: 0.49609375, layer loss: 0.3647710084915161, 
ep: 7, global_step: 4130, layer accuracy: 0.5546875, layer loss: 0.33152464032173157, 
ep: 7, global_step: 4140, layer accuracy: 0.53515625, layer loss: 0.3587731122970581, 
valid layer_batch_acc: 0.733406335684354
ep: 7, time: 94800.74711871147
训练集的acc: 0.0
验证集的acc: 0.0
ep: 8, global_step: 4150, layer accuracy: 0.5859375, layer loss: 0.34920594096183777, 
ep: 8, global_step: 4160, layer accuracy: 0.55859375, layer loss: 0.3453502058982849, 
ep: 8, global_step: 4170, layer accuracy: 0.546875, layer loss: 0.37681835889816284, 
ep: 8, global_step: 4180, layer accuracy: 0.609375, layer loss: 0.38490089774131775, 
ep: 8, global_step: 4190, layer accuracy: 0.56640625, layer loss: 0.33663779497146606, 
ep: 8, global_step: 4200, layer accuracy: 0.5546875, layer loss: 0.37998926639556885, 
ep: 8, global_step: 4210, layer accuracy: 0.55859375, layer loss: 0.40639060735702515, 
ep: 8, global_step: 4220, layer accuracy: 0.58984375, layer loss: 0.30918794870376587, 
ep: 8, global_step: 4230, layer accuracy: 0.55078125, layer loss: 0.30903321504592896, 
ep: 8, global_step: 4240, layer accuracy: 0.5546875, layer loss: 0.39470377564430237, 
ep: 8, global_step: 4250, layer accuracy: 0.5390625, layer loss: 0.36894723773002625, 
ep: 8, global_step: 4260, layer accuracy: 0.5625, layer loss: 0.36346524953842163, 
ep: 8, global_step: 4270, layer accuracy: 0.56640625, layer loss: 0.34735649824142456, 
ep: 8, global_step: 4280, layer accuracy: 0.5703125, layer loss: 0.33781513571739197, 
ep: 8, global_step: 4290, layer accuracy: 0.53515625, layer loss: 0.3825773596763611, 
ep: 8, global_step: 4300, layer accuracy: 0.515625, layer loss: 0.393122136592865, 
ep: 8, global_step: 4310, layer accuracy: 0.5703125, layer loss: 0.33522772789001465, 
ep: 8, global_step: 4320, layer accuracy: 0.5390625, layer loss: 0.393990695476532, 
ep: 8, global_step: 4330, layer accuracy: 0.55078125, layer loss: 0.3887906074523926, 
ep: 8, global_step: 4340, layer accuracy: 0.55078125, layer loss: 0.3759005069732666, 
ep: 8, global_step: 4350, layer accuracy: 0.5859375, layer loss: 0.36461785435676575, 
ep: 8, global_step: 4360, layer accuracy: 0.50390625, layer loss: 0.3313009738922119, 
ep: 8, global_step: 4370, layer accuracy: 0.6015625, layer loss: 0.2987751066684723, 
ep: 8, global_step: 4380, layer accuracy: 0.58984375, layer loss: 0.30834585428237915, 
ep: 8, global_step: 4390, layer accuracy: 0.578125, layer loss: 0.3006083369255066, 
ep: 8, global_step: 4400, layer accuracy: 0.59375, layer loss: 0.3438418507575989, 
save checkpoint -> step_4400
[2024-11-27 22:18:01,634] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-27 22:18:02,698] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_4400/pytorch_model/mp_rank_00_model_states.pt
[2024-11-27 22:18:02,698] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_4400/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-27 22:18:07,033] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_4400/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-27 22:18:07,117] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_4400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-27 22:18:07,117] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_4400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-27 22:18:07,126] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_4400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-27 22:18:07,126] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_4400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-27 22:18:07,126] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-27 22:18:07,126] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_4400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-27 22:18:07,127] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_4400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-27 22:18:07,127] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_4400 saved!
ep: 8, global_step: 4410, layer accuracy: 0.49609375, layer loss: 0.41006389260292053, 
ep: 8, global_step: 4420, layer accuracy: 0.55078125, layer loss: 0.34134039282798767, 
ep: 8, global_step: 4430, layer accuracy: 0.6015625, layer loss: 0.31782570481300354, 
ep: 8, global_step: 4440, layer accuracy: 0.64453125, layer loss: 0.26556164026260376, 
ep: 8, global_step: 4450, layer accuracy: 0.53515625, layer loss: 0.3652874529361725, 
ep: 8, global_step: 4460, layer accuracy: 0.57421875, layer loss: 0.3996385931968689, 
ep: 8, global_step: 4470, layer accuracy: 0.60546875, layer loss: 0.36727374792099, 
ep: 8, global_step: 4480, layer accuracy: 0.61328125, layer loss: 0.31712058186531067, 
ep: 8, global_step: 4490, layer accuracy: 0.53125, layer loss: 0.3570701479911804, 
ep: 8, global_step: 4500, layer accuracy: 0.54296875, layer loss: 0.352769672870636, 
ep: 8, global_step: 4510, layer accuracy: 0.57421875, layer loss: 0.30379340052604675, 
ep: 8, global_step: 4520, layer accuracy: 0.5390625, layer loss: 0.3550660014152527, 
ep: 8, global_step: 4530, layer accuracy: 0.61328125, layer loss: 0.3195897936820984, 
ep: 8, global_step: 4540, layer accuracy: 0.5625, layer loss: 0.34358689188957214, 
ep: 8, global_step: 4550, layer accuracy: 0.5625, layer loss: 0.36510175466537476, 
ep: 8, global_step: 4560, layer accuracy: 0.578125, layer loss: 0.3406520485877991, 
ep: 8, global_step: 4570, layer accuracy: 0.60546875, layer loss: 0.3055086135864258, 
ep: 8, global_step: 4580, layer accuracy: 0.5625, layer loss: 0.2823622226715088, 
ep: 8, global_step: 4590, layer accuracy: 0.6015625, layer loss: 0.2959485650062561, 
ep: 8, global_step: 4600, layer accuracy: 0.56640625, layer loss: 0.30668705701828003, 
ep: 8, global_step: 4610, layer accuracy: 0.55078125, layer loss: 0.3466634452342987, 
ep: 8, global_step: 4620, layer accuracy: 0.5390625, layer loss: 0.3947470784187317, 
ep: 8, global_step: 4630, layer accuracy: 0.59375, layer loss: 0.37439674139022827, 
ep: 8, global_step: 4640, layer accuracy: 0.5859375, layer loss: 0.35609209537506104, 
ep: 8, global_step: 4650, layer accuracy: 0.55859375, layer loss: 0.3287980258464813, 
ep: 8, global_step: 4660, layer accuracy: 0.56640625, layer loss: 0.37863999605178833, 
valid layer_batch_acc: 0.7425460001034679
ep: 8, time: 106643.10912370682
训练集的acc: 0.0
验证集的acc: 0.0
ep: 9, global_step: 4670, layer accuracy: 0.59375, layer loss: 0.3279605209827423, 
ep: 9, global_step: 4680, layer accuracy: 0.58984375, layer loss: 0.3419809341430664, 
ep: 9, global_step: 4690, layer accuracy: 0.5078125, layer loss: 0.3303561508655548, 
ep: 9, global_step: 4700, layer accuracy: 0.58203125, layer loss: 0.37164294719696045, 
ep: 9, global_step: 4710, layer accuracy: 0.62890625, layer loss: 0.24161149561405182, 
ep: 9, global_step: 4720, layer accuracy: 0.546875, layer loss: 0.40240544080734253, 
ep: 9, global_step: 4730, layer accuracy: 0.59375, layer loss: 0.35725775361061096, 
ep: 9, global_step: 4740, layer accuracy: 0.55859375, layer loss: 0.3385375738143921, 
ep: 9, global_step: 4750, layer accuracy: 0.55078125, layer loss: 0.36337870359420776, 
ep: 9, global_step: 4760, layer accuracy: 0.54296875, layer loss: 0.4034140706062317, 
ep: 9, global_step: 4770, layer accuracy: 0.5625, layer loss: 0.3525853753089905, 
ep: 9, global_step: 4780, layer accuracy: 0.58984375, layer loss: 0.273426353931427, 
ep: 9, global_step: 4790, layer accuracy: 0.5703125, layer loss: 0.29854661226272583, 
ep: 9, global_step: 4800, layer accuracy: 0.60546875, layer loss: 0.2633736729621887, 
save checkpoint -> step_4800
[2024-11-28 01:03:17,136] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-28 01:03:18,161] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_4800/pytorch_model/mp_rank_00_model_states.pt
[2024-11-28 01:03:18,161] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_4800/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-28 01:03:22,353] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_4800/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-28 01:03:22,418] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_4800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-28 01:03:22,418] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_4800/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-28 01:03:22,427] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_4800/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-28 01:03:22,427] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_4800/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-28 01:03:22,427] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-28 01:03:22,427] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_4800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-28 01:03:22,427] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_4800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-28 01:03:22,427] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_4800 saved!
ep: 9, global_step: 4810, layer accuracy: 0.58203125, layer loss: 0.30287373065948486, 
ep: 9, global_step: 4820, layer accuracy: 0.6171875, layer loss: 0.28706392645835876, 
ep: 9, global_step: 4830, layer accuracy: 0.56640625, layer loss: 0.34942156076431274, 
ep: 9, global_step: 4840, layer accuracy: 0.60546875, layer loss: 0.30358827114105225, 
ep: 9, global_step: 4850, layer accuracy: 0.578125, layer loss: 0.3119039237499237, 
ep: 9, global_step: 4860, layer accuracy: 0.60546875, layer loss: 0.2515440583229065, 
ep: 9, global_step: 4870, layer accuracy: 0.57421875, layer loss: 0.33012184500694275, 
ep: 9, global_step: 4880, layer accuracy: 0.55859375, layer loss: 0.3547179698944092, 
ep: 9, global_step: 4890, layer accuracy: 0.53515625, layer loss: 0.3883068561553955, 
ep: 9, global_step: 4900, layer accuracy: 0.59375, layer loss: 0.3099045753479004, 
ep: 9, global_step: 4910, layer accuracy: 0.6015625, layer loss: 0.30849868059158325, 
ep: 9, global_step: 4920, layer accuracy: 0.56640625, layer loss: 0.36035144329071045, 
ep: 9, global_step: 4930, layer accuracy: 0.5625, layer loss: 0.32793956995010376, 
ep: 9, global_step: 4940, layer accuracy: 0.55859375, layer loss: 0.3469531536102295, 
ep: 9, global_step: 4950, layer accuracy: 0.53125, layer loss: 0.30795708298683167, 
ep: 9, global_step: 4960, layer accuracy: 0.5, layer loss: 0.4011818766593933, 
ep: 9, global_step: 4970, layer accuracy: 0.5625, layer loss: 0.3362010419368744, 
ep: 9, global_step: 4980, layer accuracy: 0.578125, layer loss: 0.408153772354126, 
ep: 9, global_step: 4990, layer accuracy: 0.58984375, layer loss: 0.3571571707725525, 
ep: 9, global_step: 5000, layer accuracy: 0.62109375, layer loss: 0.2659168243408203, 
ep: 9, global_step: 5010, layer accuracy: 0.64453125, layer loss: 0.2721638083457947, 
ep: 9, global_step: 5020, layer accuracy: 0.5546875, layer loss: 0.3445706069469452, 
ep: 9, global_step: 5030, layer accuracy: 0.58203125, layer loss: 0.3960093855857849, 
ep: 9, global_step: 5040, layer accuracy: 0.55859375, layer loss: 0.33042827248573303, 
ep: 9, global_step: 5050, layer accuracy: 0.5625, layer loss: 0.40416064858436584, 
ep: 9, global_step: 5060, layer accuracy: 0.55859375, layer loss: 0.3467503786087036, 
ep: 9, global_step: 5070, layer accuracy: 0.609375, layer loss: 0.3127329647541046, 
ep: 9, global_step: 5080, layer accuracy: 0.5546875, layer loss: 0.33147427439689636, 
ep: 9, global_step: 5090, layer accuracy: 0.55859375, layer loss: 0.376739501953125, 
ep: 9, global_step: 5100, layer accuracy: 0.546875, layer loss: 0.284260094165802, 
ep: 9, global_step: 5110, layer accuracy: 0.578125, layer loss: 0.3458256125450134, 
ep: 9, global_step: 5120, layer accuracy: 0.56640625, layer loss: 0.3753860890865326, 
ep: 9, global_step: 5130, layer accuracy: 0.58984375, layer loss: 0.37941551208496094, 
ep: 9, global_step: 5140, layer accuracy: 0.61328125, layer loss: 0.2826559543609619, 
ep: 9, global_step: 5150, layer accuracy: 0.5859375, layer loss: 0.3511386215686798, 
ep: 9, global_step: 5160, layer accuracy: 0.53515625, layer loss: 0.37417542934417725, 
ep: 9, global_step: 5170, layer accuracy: 0.57421875, layer loss: 0.32441583275794983, 
ep: 9, global_step: 5180, layer accuracy: 0.5432098765432098, layer loss: 0.32688120007514954, 
valid layer_batch_acc: 0.7545051647726293
ep: 9, time: 118490.55688595772
训练集的acc: 0.0
验证集的acc: 0.0
ep: 10, global_step: 5190, layer accuracy: 0.61328125, layer loss: 0.32523542642593384, 
ep: 10, global_step: 5200, layer accuracy: 0.578125, layer loss: 0.3002610206604004, 
save checkpoint -> step_5200
[2024-11-28 03:48:39,667] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-28 03:48:40,657] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_5200/pytorch_model/mp_rank_00_model_states.pt
[2024-11-28 03:48:40,657] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_5200/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-28 03:48:44,779] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_5200/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-28 03:48:44,855] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_5200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-28 03:48:44,855] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_5200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-28 03:48:44,863] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_5200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-28 03:48:44,863] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_5200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-28 03:48:44,863] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_5200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-28 03:48:44,863] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-28 03:48:44,863] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_5200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-28 03:48:44,863] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_5200 saved!
ep: 10, global_step: 5210, layer accuracy: 0.5859375, layer loss: 0.3345603346824646, 
ep: 10, global_step: 5220, layer accuracy: 0.5546875, layer loss: 0.339950829744339, 
ep: 10, global_step: 5230, layer accuracy: 0.5625, layer loss: 0.39448559284210205, 
ep: 10, global_step: 5240, layer accuracy: 0.60546875, layer loss: 0.3458901047706604, 
ep: 10, global_step: 5250, layer accuracy: 0.578125, layer loss: 0.2868798077106476, 
ep: 10, global_step: 5260, layer accuracy: 0.52734375, layer loss: 0.4120185971260071, 
ep: 10, global_step: 5270, layer accuracy: 0.578125, layer loss: 0.33678650856018066, 
ep: 10, global_step: 5280, layer accuracy: 0.50390625, layer loss: 0.36157506704330444, 
ep: 10, global_step: 5290, layer accuracy: 0.60546875, layer loss: 0.30775174498558044, 
ep: 10, global_step: 5300, layer accuracy: 0.61328125, layer loss: 0.28709179162979126, 
ep: 10, global_step: 5310, layer accuracy: 0.62109375, layer loss: 0.3145046830177307, 
ep: 10, global_step: 5320, layer accuracy: 0.62109375, layer loss: 0.3009462058544159, 
ep: 10, global_step: 5330, layer accuracy: 0.5625, layer loss: 0.3645114302635193, 
ep: 10, global_step: 5340, layer accuracy: 0.60546875, layer loss: 0.33539965748786926, 
ep: 10, global_step: 5350, layer accuracy: 0.52734375, layer loss: 0.4076230525970459, 
ep: 10, global_step: 5360, layer accuracy: 0.59375, layer loss: 0.30932122468948364, 
ep: 10, global_step: 5370, layer accuracy: 0.61328125, layer loss: 0.32727980613708496, 
ep: 10, global_step: 5380, layer accuracy: 0.56640625, layer loss: 0.30696365237236023, 
ep: 10, global_step: 5390, layer accuracy: 0.609375, layer loss: 0.35401374101638794, 
ep: 10, global_step: 5400, layer accuracy: 0.5625, layer loss: 0.3188168406486511, 
ep: 10, global_step: 5410, layer accuracy: 0.6171875, layer loss: 0.28815221786499023, 
ep: 10, global_step: 5420, layer accuracy: 0.62890625, layer loss: 0.28125518560409546, 
ep: 10, global_step: 5430, layer accuracy: 0.54296875, layer loss: 0.3249196410179138, 
ep: 10, global_step: 5440, layer accuracy: 0.6328125, layer loss: 0.33370670676231384, 
ep: 10, global_step: 5450, layer accuracy: 0.5546875, layer loss: 0.34423795342445374, 
ep: 10, global_step: 5460, layer accuracy: 0.609375, layer loss: 0.33182889223098755, 
ep: 10, global_step: 5470, layer accuracy: 0.5390625, layer loss: 0.3550567328929901, 
ep: 10, global_step: 5480, layer accuracy: 0.578125, layer loss: 0.2985627353191376, 
ep: 10, global_step: 5490, layer accuracy: 0.62890625, layer loss: 0.27662718296051025, 
ep: 10, global_step: 5500, layer accuracy: 0.5546875, layer loss: 0.341341108083725, 
ep: 10, global_step: 5510, layer accuracy: 0.63671875, layer loss: 0.269957572221756, 
ep: 10, global_step: 5520, layer accuracy: 0.55859375, layer loss: 0.33305275440216064, 
ep: 10, global_step: 5530, layer accuracy: 0.5390625, layer loss: 0.3746783137321472, 
ep: 10, global_step: 5540, layer accuracy: 0.59765625, layer loss: 0.2689078450202942, 
ep: 10, global_step: 5550, layer accuracy: 0.59375, layer loss: 0.2917558550834656, 
ep: 10, global_step: 5560, layer accuracy: 0.6171875, layer loss: 0.2974174916744232, 
ep: 10, global_step: 5570, layer accuracy: 0.60546875, layer loss: 0.3564290404319763, 
ep: 10, global_step: 5580, layer accuracy: 0.57421875, layer loss: 0.3250170052051544, 
ep: 10, global_step: 5590, layer accuracy: 0.59765625, layer loss: 0.3202804923057556, 
ep: 10, global_step: 5600, layer accuracy: 0.56640625, layer loss: 0.3280756175518036, 
save checkpoint -> step_5600
[2024-11-28 05:37:33,460] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-28 05:37:34,460] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_5600/pytorch_model/mp_rank_00_model_states.pt
[2024-11-28 05:37:34,460] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_5600/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-28 05:37:38,577] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_5600/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-28 05:37:38,645] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_5600/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-28 05:37:38,645] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_5600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-28 05:37:38,654] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_5600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-28 05:37:38,654] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_5600/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-28 05:37:38,654] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_5600/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-28 05:37:38,654] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-28 05:37:38,654] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_5600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-28 05:37:38,654] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_5600 saved!
ep: 10, global_step: 5610, layer accuracy: 0.59375, layer loss: 0.326992928981781, 
ep: 10, global_step: 5620, layer accuracy: 0.578125, layer loss: 0.3407739996910095, 
ep: 10, global_step: 5630, layer accuracy: 0.55859375, layer loss: 0.29361820220947266, 
ep: 10, global_step: 5640, layer accuracy: 0.578125, layer loss: 0.3189506232738495, 
ep: 10, global_step: 5650, layer accuracy: 0.6015625, layer loss: 0.31166744232177734, 
ep: 10, global_step: 5660, layer accuracy: 0.58203125, layer loss: 0.32211834192276, 
ep: 10, global_step: 5670, layer accuracy: 0.56640625, layer loss: 0.33403313159942627, 
ep: 10, global_step: 5680, layer accuracy: 0.59375, layer loss: 0.31967708468437195, 
ep: 10, global_step: 5690, layer accuracy: 0.54296875, layer loss: 0.3665276765823364, 
valid layer_batch_acc: 0.7588421942092466
ep: 10, time: 130343.34357118607
训练集的acc: 0.0
验证集的acc: 0.0
ep: 11, global_step: 5700, layer accuracy: 0.58984375, layer loss: 0.3214735984802246, 
ep: 11, global_step: 5710, layer accuracy: 0.625, layer loss: 0.29730844497680664, 
ep: 11, global_step: 5720, layer accuracy: 0.55859375, layer loss: 0.2934383749961853, 
ep: 11, global_step: 5730, layer accuracy: 0.58984375, layer loss: 0.3106163740158081, 
ep: 11, global_step: 5740, layer accuracy: 0.64453125, layer loss: 0.23654553294181824, 
ep: 11, global_step: 5750, layer accuracy: 0.58203125, layer loss: 0.3354523777961731, 
ep: 11, global_step: 5760, layer accuracy: 0.5234375, layer loss: 0.3477417826652527, 
ep: 11, global_step: 5770, layer accuracy: 0.63671875, layer loss: 0.3226972818374634, 
ep: 11, global_step: 5780, layer accuracy: 0.60546875, layer loss: 0.30105525255203247, 
ep: 11, global_step: 5790, layer accuracy: 0.58984375, layer loss: 0.33379021286964417, 
ep: 11, global_step: 5800, layer accuracy: 0.58984375, layer loss: 0.30156177282333374, 
ep: 11, global_step: 5810, layer accuracy: 0.6328125, layer loss: 0.28284597396850586, 
ep: 11, global_step: 5820, layer accuracy: 0.60546875, layer loss: 0.2711346745491028, 
ep: 11, global_step: 5830, layer accuracy: 0.609375, layer loss: 0.2994735836982727, 
ep: 11, global_step: 5840, layer accuracy: 0.5625, layer loss: 0.34968119859695435, 
ep: 11, global_step: 5850, layer accuracy: 0.625, layer loss: 0.3425326943397522, 
ep: 11, global_step: 5860, layer accuracy: 0.62109375, layer loss: 0.30364781618118286, 
ep: 11, global_step: 5870, layer accuracy: 0.609375, layer loss: 0.2635904550552368, 
ep: 11, global_step: 5880, layer accuracy: 0.5859375, layer loss: 0.2894909977912903, 
ep: 11, global_step: 5890, layer accuracy: 0.57421875, layer loss: 0.3158584237098694, 
ep: 11, global_step: 5900, layer accuracy: 0.5859375, layer loss: 0.28901931643486023, 
ep: 11, global_step: 5910, layer accuracy: 0.57421875, layer loss: 0.30152249336242676, 
ep: 11, global_step: 5920, layer accuracy: 0.61328125, layer loss: 0.3239794373512268, 
ep: 11, global_step: 5930, layer accuracy: 0.5546875, layer loss: 0.36307287216186523, 
ep: 11, global_step: 5940, layer accuracy: 0.5703125, layer loss: 0.31999313831329346, 
ep: 11, global_step: 5950, layer accuracy: 0.63671875, layer loss: 0.3010737895965576, 
ep: 11, global_step: 5960, layer accuracy: 0.578125, layer loss: 0.33317726850509644, 
ep: 11, global_step: 5970, layer accuracy: 0.609375, layer loss: 0.35312122106552124, 
ep: 11, global_step: 5980, layer accuracy: 0.5859375, layer loss: 0.3783942759037018, 
ep: 11, global_step: 5990, layer accuracy: 0.58203125, layer loss: 0.3116537630558014, 
ep: 11, global_step: 6000, layer accuracy: 0.66015625, layer loss: 0.30540522933006287, 
save checkpoint -> step_6000
[2024-11-28 08:22:55,465] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-28 08:22:56,468] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_6000/pytorch_model/mp_rank_00_model_states.pt
[2024-11-28 08:22:56,468] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_6000/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-28 08:23:00,678] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_6000/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-28 08:23:00,745] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_6000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-28 08:23:00,745] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_6000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-28 08:23:00,753] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_6000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-28 08:23:00,754] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_6000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-28 08:23:00,754] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_6000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-28 08:23:00,754] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-28 08:23:00,754] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_6000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-28 08:23:00,754] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_6000 saved!
ep: 11, global_step: 6010, layer accuracy: 0.60546875, layer loss: 0.27673885226249695, 
ep: 11, global_step: 6020, layer accuracy: 0.62109375, layer loss: 0.2858748435974121, 
ep: 11, global_step: 6030, layer accuracy: 0.5859375, layer loss: 0.2905164957046509, 
ep: 11, global_step: 6040, layer accuracy: 0.5703125, layer loss: 0.30768394470214844, 
ep: 11, global_step: 6050, layer accuracy: 0.58203125, layer loss: 0.30809682607650757, 
ep: 11, global_step: 6060, layer accuracy: 0.62890625, layer loss: 0.3226412534713745, 
ep: 11, global_step: 6070, layer accuracy: 0.59765625, layer loss: 0.30549585819244385, 
ep: 11, global_step: 6080, layer accuracy: 0.58203125, layer loss: 0.28893327713012695, 
ep: 11, global_step: 6090, layer accuracy: 0.61328125, layer loss: 0.3313721716403961, 
ep: 11, global_step: 6100, layer accuracy: 0.60546875, layer loss: 0.2870391607284546, 
ep: 11, global_step: 6110, layer accuracy: 0.640625, layer loss: 0.3066474199295044, 
ep: 11, global_step: 6120, layer accuracy: 0.57421875, layer loss: 0.2787500023841858, 
ep: 11, global_step: 6130, layer accuracy: 0.5390625, layer loss: 0.34198975563049316, 
ep: 11, global_step: 6140, layer accuracy: 0.6015625, layer loss: 0.29087603092193604, 
ep: 11, global_step: 6150, layer accuracy: 0.6171875, layer loss: 0.3231576085090637, 
ep: 11, global_step: 6160, layer accuracy: 0.58203125, layer loss: 0.3002611994743347, 
ep: 11, global_step: 6170, layer accuracy: 0.58984375, layer loss: 0.386826753616333, 
ep: 11, global_step: 6180, layer accuracy: 0.58984375, layer loss: 0.33693525195121765, 
ep: 11, global_step: 6190, layer accuracy: 0.63671875, layer loss: 0.298038512468338, 
ep: 11, global_step: 6200, layer accuracy: 0.6328125, layer loss: 0.2789580821990967, 
ep: 11, global_step: 6210, layer accuracy: 0.60546875, layer loss: 0.3708224892616272, 
valid layer_batch_acc: 0.7633602924692614
ep: 11, time: 142185.32645726204
训练集的acc: 0.0
验证集的acc: 0.0
ep: 12, global_step: 6220, layer accuracy: 0.5546875, layer loss: 0.337840735912323, 
ep: 12, global_step: 6230, layer accuracy: 0.62109375, layer loss: 0.2897988557815552, 
ep: 12, global_step: 6240, layer accuracy: 0.578125, layer loss: 0.27744412422180176, 
ep: 12, global_step: 6250, layer accuracy: 0.609375, layer loss: 0.3491549491882324, 
ep: 12, global_step: 6260, layer accuracy: 0.62890625, layer loss: 0.29871881008148193, 
ep: 12, global_step: 6270, layer accuracy: 0.59765625, layer loss: 0.35492420196533203, 
ep: 12, global_step: 6280, layer accuracy: 0.60546875, layer loss: 0.28377240896224976, 
ep: 12, global_step: 6290, layer accuracy: 0.58984375, layer loss: 0.2994191348552704, 
ep: 12, global_step: 6300, layer accuracy: 0.62890625, layer loss: 0.3455003499984741, 
ep: 12, global_step: 6310, layer accuracy: 0.5546875, layer loss: 0.3535754084587097, 
ep: 12, global_step: 6320, layer accuracy: 0.5625, layer loss: 0.29447805881500244, 
ep: 12, global_step: 6330, layer accuracy: 0.640625, layer loss: 0.28505855798721313, 
ep: 12, global_step: 6340, layer accuracy: 0.61328125, layer loss: 0.304796427488327, 
ep: 12, global_step: 6350, layer accuracy: 0.6171875, layer loss: 0.30679672956466675, 
ep: 12, global_step: 6360, layer accuracy: 0.55078125, layer loss: 0.338766485452652, 
ep: 12, global_step: 6370, layer accuracy: 0.57421875, layer loss: 0.3877735137939453, 
ep: 12, global_step: 6380, layer accuracy: 0.64453125, layer loss: 0.3160586357116699, 
ep: 12, global_step: 6390, layer accuracy: 0.5859375, layer loss: 0.33623433113098145, 
ep: 12, global_step: 6400, layer accuracy: 0.59765625, layer loss: 0.2855713367462158, 
save checkpoint -> step_6400
[2024-11-28 11:08:08,605] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-28 11:08:09,597] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_6400/pytorch_model/mp_rank_00_model_states.pt
[2024-11-28 11:08:09,598] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_6400/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-28 11:08:13,759] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_6400/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-28 11:08:13,836] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_6400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-28 11:08:13,836] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_6400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-28 11:08:13,844] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_6400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-28 11:08:13,844] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_6400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-28 11:08:13,844] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-28 11:08:13,844] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_6400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-28 11:08:13,844] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_6400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-28 11:08:13,844] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_6400 saved!
ep: 12, global_step: 6410, layer accuracy: 0.62890625, layer loss: 0.26947301626205444, 
ep: 12, global_step: 6420, layer accuracy: 0.59375, layer loss: 0.30706024169921875, 
ep: 12, global_step: 6430, layer accuracy: 0.609375, layer loss: 0.32941797375679016, 
ep: 12, global_step: 6440, layer accuracy: 0.58203125, layer loss: 0.30004173517227173, 
ep: 12, global_step: 6450, layer accuracy: 0.58984375, layer loss: 0.3036600947380066, 
ep: 12, global_step: 6460, layer accuracy: 0.5859375, layer loss: 0.3449317514896393, 
ep: 12, global_step: 6470, layer accuracy: 0.60546875, layer loss: 0.36503225564956665, 
ep: 12, global_step: 6480, layer accuracy: 0.6328125, layer loss: 0.2885795831680298, 
ep: 12, global_step: 6490, layer accuracy: 0.6484375, layer loss: 0.2943950295448303, 
ep: 12, global_step: 6500, layer accuracy: 0.578125, layer loss: 0.25865253806114197, 
ep: 12, global_step: 6510, layer accuracy: 0.57421875, layer loss: 0.31657397747039795, 
ep: 12, global_step: 6520, layer accuracy: 0.59375, layer loss: 0.3153512477874756, 
ep: 12, global_step: 6530, layer accuracy: 0.5625, layer loss: 0.3752586841583252, 
ep: 12, global_step: 6540, layer accuracy: 0.6640625, layer loss: 0.2740285098552704, 
ep: 12, global_step: 6550, layer accuracy: 0.62890625, layer loss: 0.31458964943885803, 
ep: 12, global_step: 6560, layer accuracy: 0.60546875, layer loss: 0.300300657749176, 
ep: 12, global_step: 6570, layer accuracy: 0.55078125, layer loss: 0.3529680669307709, 
ep: 12, global_step: 6580, layer accuracy: 0.609375, layer loss: 0.3990749418735504, 
ep: 12, global_step: 6590, layer accuracy: 0.625, layer loss: 0.2551889717578888, 
ep: 12, global_step: 6600, layer accuracy: 0.55859375, layer loss: 0.3522738814353943, 
ep: 12, global_step: 6610, layer accuracy: 0.60546875, layer loss: 0.2823847830295563, 
ep: 12, global_step: 6620, layer accuracy: 0.62109375, layer loss: 0.29282888770103455, 
ep: 12, global_step: 6630, layer accuracy: 0.6328125, layer loss: 0.29797273874282837, 
ep: 12, global_step: 6640, layer accuracy: 0.609375, layer loss: 0.25863155722618103, 
ep: 12, global_step: 6650, layer accuracy: 0.62890625, layer loss: 0.3136482238769531, 
ep: 12, global_step: 6660, layer accuracy: 0.6796875, layer loss: 0.2642231583595276, 
ep: 12, global_step: 6670, layer accuracy: 0.578125, layer loss: 0.30704811215400696, 
ep: 12, global_step: 6680, layer accuracy: 0.60546875, layer loss: 0.32777196168899536, 
ep: 12, global_step: 6690, layer accuracy: 0.5703125, layer loss: 0.38575005531311035, 
ep: 12, global_step: 6700, layer accuracy: 0.62109375, layer loss: 0.33394646644592285, 
ep: 12, global_step: 6710, layer accuracy: 0.6640625, layer loss: 0.2662379741668701, 
ep: 12, global_step: 6720, layer accuracy: 0.58984375, layer loss: 0.3007085621356964, 
ep: 12, global_step: 6730, layer accuracy: 0.5546875, layer loss: 0.3350255489349365, 
valid layer_batch_acc: 0.763093000396627
ep: 12, time: 154025.94122958183
训练集的acc: 0.0
验证集的acc: 0.0
ep: 13, global_step: 6740, layer accuracy: 0.59375, layer loss: 0.4031982421875, 
ep: 13, global_step: 6750, layer accuracy: 0.60546875, layer loss: 0.34628671407699585, 
ep: 13, global_step: 6760, layer accuracy: 0.5859375, layer loss: 0.313584566116333, 
ep: 13, global_step: 6770, layer accuracy: 0.69921875, layer loss: 0.2260380983352661, 
ep: 13, global_step: 6780, layer accuracy: 0.6015625, layer loss: 0.29710522294044495, 
ep: 13, global_step: 6790, layer accuracy: 0.6484375, layer loss: 0.3057602643966675, 
ep: 13, global_step: 6800, layer accuracy: 0.64453125, layer loss: 0.3159634470939636, 
save checkpoint -> step_6800
[2024-11-28 13:53:26,320] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-28 13:53:27,331] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_6800/pytorch_model/mp_rank_00_model_states.pt
[2024-11-28 13:53:27,332] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_6800/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-28 13:53:31,696] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_6800/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-28 13:53:31,780] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_6800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-28 13:53:31,780] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_6800/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-28 13:53:31,788] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_6800/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-28 13:53:31,789] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_6800/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-28 13:53:31,788] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_6800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-28 13:53:31,789] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-28 13:53:31,789] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_6800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-28 13:53:31,789] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_6800 saved!
ep: 13, global_step: 6810, layer accuracy: 0.5859375, layer loss: 0.2578551173210144, 
ep: 13, global_step: 6820, layer accuracy: 0.66015625, layer loss: 0.23994268476963043, 
ep: 13, global_step: 6830, layer accuracy: 0.66796875, layer loss: 0.278052419424057, 
ep: 13, global_step: 6840, layer accuracy: 0.625, layer loss: 0.2702566981315613, 
ep: 13, global_step: 6850, layer accuracy: 0.5859375, layer loss: 0.3082119822502136, 
ep: 13, global_step: 6860, layer accuracy: 0.609375, layer loss: 0.28717169165611267, 
ep: 13, global_step: 6870, layer accuracy: 0.6953125, layer loss: 0.25710904598236084, 
ep: 13, global_step: 6880, layer accuracy: 0.640625, layer loss: 0.3122422397136688, 
ep: 13, global_step: 6890, layer accuracy: 0.6171875, layer loss: 0.2590251863002777, 
ep: 13, global_step: 6900, layer accuracy: 0.59375, layer loss: 0.3145119845867157, 
ep: 13, global_step: 6910, layer accuracy: 0.60546875, layer loss: 0.287784218788147, 
ep: 13, global_step: 6920, layer accuracy: 0.640625, layer loss: 0.2532958984375, 
ep: 13, global_step: 6930, layer accuracy: 0.5546875, layer loss: 0.2883757948875427, 
ep: 13, global_step: 6940, layer accuracy: 0.640625, layer loss: 0.3239370584487915, 
ep: 13, global_step: 6950, layer accuracy: 0.56640625, layer loss: 0.2654949426651001, 
ep: 13, global_step: 6960, layer accuracy: 0.6171875, layer loss: 0.33854439854621887, 
ep: 13, global_step: 6970, layer accuracy: 0.60546875, layer loss: 0.2678907513618469, 
ep: 13, global_step: 6980, layer accuracy: 0.58203125, layer loss: 0.27061736583709717, 
ep: 13, global_step: 6990, layer accuracy: 0.60546875, layer loss: 0.31751590967178345, 
ep: 13, global_step: 7000, layer accuracy: 0.63671875, layer loss: 0.21881785988807678, 
ep: 13, global_step: 7010, layer accuracy: 0.60546875, layer loss: 0.33238649368286133, 
ep: 13, global_step: 7020, layer accuracy: 0.625, layer loss: 0.26787176728248596, 
ep: 13, global_step: 7030, layer accuracy: 0.5703125, layer loss: 0.32285574078559875, 
ep: 13, global_step: 7040, layer accuracy: 0.6171875, layer loss: 0.237629234790802, 
ep: 13, global_step: 7050, layer accuracy: 0.62109375, layer loss: 0.2822946012020111, 
ep: 13, global_step: 7060, layer accuracy: 0.59375, layer loss: 0.3290409743785858, 
ep: 13, global_step: 7070, layer accuracy: 0.6328125, layer loss: 0.3262934684753418, 
ep: 13, global_step: 7080, layer accuracy: 0.58984375, layer loss: 0.28768324851989746, 
ep: 13, global_step: 7090, layer accuracy: 0.61328125, layer loss: 0.30337879061698914, 
ep: 13, global_step: 7100, layer accuracy: 0.57421875, layer loss: 0.3804031312465668, 
ep: 13, global_step: 7110, layer accuracy: 0.64453125, layer loss: 0.31363245844841003, 
ep: 13, global_step: 7120, layer accuracy: 0.5625, layer loss: 0.3059757947921753, 
ep: 13, global_step: 7130, layer accuracy: 0.62109375, layer loss: 0.23435303568840027, 
ep: 13, global_step: 7140, layer accuracy: 0.58984375, layer loss: 0.33127766847610474, 
ep: 13, global_step: 7150, layer accuracy: 0.625, layer loss: 0.31370049715042114, 
ep: 13, global_step: 7160, layer accuracy: 0.59375, layer loss: 0.2761269807815552, 
ep: 13, global_step: 7170, layer accuracy: 0.609375, layer loss: 0.32390502095222473, 
ep: 13, global_step: 7180, layer accuracy: 0.62890625, layer loss: 0.30462464690208435, 
ep: 13, global_step: 7190, layer accuracy: 0.63671875, layer loss: 0.2675336003303528, 
ep: 13, global_step: 7200, layer accuracy: 0.609375, layer loss: 0.27714425325393677, 
save checkpoint -> step_7200
[2024-11-28 15:42:20,670] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-28 15:42:21,712] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_7200/pytorch_model/mp_rank_00_model_states.pt
[2024-11-28 15:42:21,712] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_7200/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-28 15:42:25,989] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_7200/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-28 15:42:26,065] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_7200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-28 15:42:26,065] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_7200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-28 15:42:26,074] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_7200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-28 15:42:26,074] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_7200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-28 15:42:26,074] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_7200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-28 15:42:26,074] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-28 15:42:26,074] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_7200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-28 15:42:26,074] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_7200 saved!
ep: 13, global_step: 7210, layer accuracy: 0.578125, layer loss: 0.3139318823814392, 
ep: 13, global_step: 7220, layer accuracy: 0.61328125, layer loss: 0.3970591723918915, 
ep: 13, global_step: 7230, layer accuracy: 0.61328125, layer loss: 0.28772610425949097, 
ep: 13, global_step: 7240, layer accuracy: 0.61328125, layer loss: 0.3338012993335724, 
ep: 13, global_step: 7250, layer accuracy: 0.63671875, layer loss: 0.26221561431884766, 
valid layer_batch_acc: 0.7685423097484005
ep: 13, time: 165888.50657391548
训练集的acc: 0.0
验证集的acc: 0.0
ep: 14, global_step: 7260, layer accuracy: 0.61328125, layer loss: 0.30129382014274597, 
ep: 14, global_step: 7270, layer accuracy: 0.5859375, layer loss: 0.2627389132976532, 
ep: 14, global_step: 7280, layer accuracy: 0.62109375, layer loss: 0.3013196587562561, 
ep: 14, global_step: 7290, layer accuracy: 0.59765625, layer loss: 0.27517563104629517, 
ep: 14, global_step: 7300, layer accuracy: 0.578125, layer loss: 0.31379589438438416, 
ep: 14, global_step: 7310, layer accuracy: 0.6171875, layer loss: 0.2956264913082123, 
ep: 14, global_step: 7320, layer accuracy: 0.609375, layer loss: 0.29221075773239136, 
ep: 14, global_step: 7330, layer accuracy: 0.59765625, layer loss: 0.3142037093639374, 
ep: 14, global_step: 7340, layer accuracy: 0.64453125, layer loss: 0.26734989881515503, 
ep: 14, global_step: 7350, layer accuracy: 0.62890625, layer loss: 0.29822105169296265, 
ep: 14, global_step: 7360, layer accuracy: 0.58984375, layer loss: 0.2877196669578552, 
ep: 14, global_step: 7370, layer accuracy: 0.58984375, layer loss: 0.2726525664329529, 
ep: 14, global_step: 7380, layer accuracy: 0.52734375, layer loss: 0.3327716588973999, 
ep: 14, global_step: 7390, layer accuracy: 0.64453125, layer loss: 0.2753527760505676, 
ep: 14, global_step: 7400, layer accuracy: 0.6171875, layer loss: 0.29559266567230225, 
ep: 14, global_step: 7410, layer accuracy: 0.62109375, layer loss: 0.2706870436668396, 
ep: 14, global_step: 7420, layer accuracy: 0.6328125, layer loss: 0.2874371409416199, 
ep: 14, global_step: 7430, layer accuracy: 0.58984375, layer loss: 0.3172324597835541, 
ep: 14, global_step: 7440, layer accuracy: 0.58984375, layer loss: 0.30350351333618164, 
ep: 14, global_step: 7450, layer accuracy: 0.6171875, layer loss: 0.2725822329521179, 
ep: 14, global_step: 7460, layer accuracy: 0.609375, layer loss: 0.2949039340019226, 
ep: 14, global_step: 7470, layer accuracy: 0.6171875, layer loss: 0.2743765711784363, 
ep: 14, global_step: 7480, layer accuracy: 0.5703125, layer loss: 0.2857450246810913, 
ep: 14, global_step: 7490, layer accuracy: 0.5, layer loss: 0.3829503655433655, 
ep: 14, global_step: 7500, layer accuracy: 0.60546875, layer loss: 0.30305150151252747, 
ep: 14, global_step: 7510, layer accuracy: 0.61328125, layer loss: 0.2827794551849365, 
ep: 14, global_step: 7520, layer accuracy: 0.58203125, layer loss: 0.38815099000930786, 
ep: 14, global_step: 7530, layer accuracy: 0.65234375, layer loss: 0.23731139302253723, 
ep: 14, global_step: 7540, layer accuracy: 0.671875, layer loss: 0.25729817152023315, 
ep: 14, global_step: 7550, layer accuracy: 0.625, layer loss: 0.3108115494251251, 
ep: 14, global_step: 7560, layer accuracy: 0.609375, layer loss: 0.29211926460266113, 
ep: 14, global_step: 7570, layer accuracy: 0.62890625, layer loss: 0.273455947637558, 
ep: 14, global_step: 7580, layer accuracy: 0.60546875, layer loss: 0.346153199672699, 
ep: 14, global_step: 7590, layer accuracy: 0.671875, layer loss: 0.25962206721305847, 
ep: 14, global_step: 7600, layer accuracy: 0.64453125, layer loss: 0.2925264835357666, 
save checkpoint -> step_7600
[2024-11-28 18:27:48,565] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-28 18:27:49,550] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_7600/pytorch_model/mp_rank_00_model_states.pt
[2024-11-28 18:27:49,550] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_7600/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-28 18:27:53,659] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_7600/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-28 18:27:53,728] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_7600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-28 18:27:53,728] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_7600/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-28 18:27:53,737] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_7600/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-28 18:27:53,737] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_7600/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-28 18:27:53,737] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-28 18:27:53,737] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_7600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-28 18:27:53,737] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_7600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-28 18:27:53,737] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_7600 saved!
ep: 14, global_step: 7610, layer accuracy: 0.578125, layer loss: 0.27707359194755554, 
ep: 14, global_step: 7620, layer accuracy: 0.625, layer loss: 0.3565916419029236, 
ep: 14, global_step: 7630, layer accuracy: 0.609375, layer loss: 0.26643890142440796, 
ep: 14, global_step: 7640, layer accuracy: 0.6640625, layer loss: 0.2525966763496399, 
ep: 14, global_step: 7650, layer accuracy: 0.64453125, layer loss: 0.26152998208999634, 
ep: 14, global_step: 7660, layer accuracy: 0.6875, layer loss: 0.291659414768219, 
ep: 14, global_step: 7670, layer accuracy: 0.6171875, layer loss: 0.28277885913848877, 
ep: 14, global_step: 7680, layer accuracy: 0.5703125, layer loss: 0.3634765148162842, 
ep: 14, global_step: 7690, layer accuracy: 0.6328125, layer loss: 0.28918254375457764, 
ep: 14, global_step: 7700, layer accuracy: 0.609375, layer loss: 0.3162376284599304, 
ep: 14, global_step: 7710, layer accuracy: 0.65234375, layer loss: 0.23128479719161987, 
ep: 14, global_step: 7720, layer accuracy: 0.61328125, layer loss: 0.31779158115386963, 
ep: 14, global_step: 7730, layer accuracy: 0.66015625, layer loss: 0.2781878113746643, 
ep: 14, global_step: 7740, layer accuracy: 0.6640625, layer loss: 0.26875609159469604, 
ep: 14, global_step: 7750, layer accuracy: 0.61328125, layer loss: 0.34109506011009216, 
ep: 14, global_step: 7760, layer accuracy: 0.62109375, layer loss: 0.3327485918998718, 
ep: 14, global_step: 7770, layer accuracy: 0.5802469135802469, layer loss: 0.2888435125350952, 
valid layer_batch_acc: 0.7689044473951956
ep: 14, time: 177734.37918543816
训练集的acc: 0.0
验证集的acc: 0.0
ep: 15, global_step: 7780, layer accuracy: 0.609375, layer loss: 0.24266675114631653, 
ep: 15, global_step: 7790, layer accuracy: 0.65625, layer loss: 0.2320757508277893, 
ep: 15, global_step: 7800, layer accuracy: 0.66015625, layer loss: 0.22223970293998718, 
ep: 15, global_step: 7810, layer accuracy: 0.61328125, layer loss: 0.29428014159202576, 
ep: 15, global_step: 7820, layer accuracy: 0.59375, layer loss: 0.30769258737564087, 
ep: 15, global_step: 7830, layer accuracy: 0.5546875, layer loss: 0.3176080286502838, 
ep: 15, global_step: 7840, layer accuracy: 0.609375, layer loss: 0.2650038003921509, 
ep: 15, global_step: 7850, layer accuracy: 0.62890625, layer loss: 0.2976004481315613, 
ep: 15, global_step: 7860, layer accuracy: 0.6328125, layer loss: 0.2896510362625122, 
ep: 15, global_step: 7870, layer accuracy: 0.640625, layer loss: 0.2733495235443115, 
ep: 15, global_step: 7880, layer accuracy: 0.56640625, layer loss: 0.33504486083984375, 
ep: 15, global_step: 7890, layer accuracy: 0.63671875, layer loss: 0.26762133836746216, 
ep: 15, global_step: 7900, layer accuracy: 0.59375, layer loss: 0.25463205575942993, 
ep: 15, global_step: 7910, layer accuracy: 0.6015625, layer loss: 0.25527846813201904, 
ep: 15, global_step: 7920, layer accuracy: 0.60546875, layer loss: 0.26950767636299133, 
ep: 15, global_step: 7930, layer accuracy: 0.6328125, layer loss: 0.27861288189888, 
ep: 15, global_step: 7940, layer accuracy: 0.55078125, layer loss: 0.30601173639297485, 
ep: 15, global_step: 7950, layer accuracy: 0.60546875, layer loss: 0.2644675374031067, 
ep: 15, global_step: 7960, layer accuracy: 0.62890625, layer loss: 0.295856773853302, 
ep: 15, global_step: 7970, layer accuracy: 0.65625, layer loss: 0.2528776526451111, 
ep: 15, global_step: 7980, layer accuracy: 0.61328125, layer loss: 0.3059197962284088, 
ep: 15, global_step: 7990, layer accuracy: 0.6015625, layer loss: 0.2752175033092499, 
ep: 15, global_step: 8000, layer accuracy: 0.61328125, layer loss: 0.35418570041656494, 
save checkpoint -> step_8000
[2024-11-28 21:13:13,186] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-28 21:13:14,243] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_8000/pytorch_model/mp_rank_00_model_states.pt
[2024-11-28 21:13:14,243] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_8000/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-28 21:13:18,481] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_8000/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-28 21:13:18,581] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_8000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-28 21:13:18,581] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_8000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-28 21:13:18,589] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_8000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-28 21:13:18,590] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_8000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-28 21:13:18,590] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-28 21:13:18,590] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_8000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-28 21:13:18,590] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_8000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-28 21:13:18,590] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_8000 saved!
ep: 15, global_step: 8010, layer accuracy: 0.65625, layer loss: 0.2597372233867645, 
ep: 15, global_step: 8020, layer accuracy: 0.640625, layer loss: 0.298416405916214, 
ep: 15, global_step: 8030, layer accuracy: 0.59765625, layer loss: 0.3540307879447937, 
ep: 15, global_step: 8040, layer accuracy: 0.65234375, layer loss: 0.28643202781677246, 
ep: 15, global_step: 8050, layer accuracy: 0.60546875, layer loss: 0.29526934027671814, 
ep: 15, global_step: 8060, layer accuracy: 0.6484375, layer loss: 0.29355379939079285, 
ep: 15, global_step: 8070, layer accuracy: 0.6484375, layer loss: 0.2882964611053467, 
ep: 15, global_step: 8080, layer accuracy: 0.6484375, layer loss: 0.2319234013557434, 
ep: 15, global_step: 8090, layer accuracy: 0.60546875, layer loss: 0.3247855305671692, 
ep: 15, global_step: 8100, layer accuracy: 0.5859375, layer loss: 0.317097008228302, 
ep: 15, global_step: 8110, layer accuracy: 0.6484375, layer loss: 0.27325451374053955, 
ep: 15, global_step: 8120, layer accuracy: 0.55859375, layer loss: 0.29073798656463623, 
ep: 15, global_step: 8130, layer accuracy: 0.65234375, layer loss: 0.2545062303543091, 
ep: 15, global_step: 8140, layer accuracy: 0.6171875, layer loss: 0.2879108786582947, 
ep: 15, global_step: 8150, layer accuracy: 0.63671875, layer loss: 0.24768328666687012, 
ep: 15, global_step: 8160, layer accuracy: 0.6875, layer loss: 0.2429233193397522, 
ep: 15, global_step: 8170, layer accuracy: 0.62890625, layer loss: 0.241623654961586, 
ep: 15, global_step: 8180, layer accuracy: 0.62109375, layer loss: 0.33053144812583923, 
ep: 15, global_step: 8190, layer accuracy: 0.6171875, layer loss: 0.2928391098976135, 
ep: 15, global_step: 8200, layer accuracy: 0.671875, layer loss: 0.24096450209617615, 
ep: 15, global_step: 8210, layer accuracy: 0.65234375, layer loss: 0.2664104998111725, 
ep: 15, global_step: 8220, layer accuracy: 0.65234375, layer loss: 0.3384290337562561, 
ep: 15, global_step: 8230, layer accuracy: 0.59375, layer loss: 0.3083834648132324, 
ep: 15, global_step: 8240, layer accuracy: 0.6015625, layer loss: 0.2650497853755951, 
ep: 15, global_step: 8250, layer accuracy: 0.6171875, layer loss: 0.2687121629714966, 
ep: 15, global_step: 8260, layer accuracy: 0.68359375, layer loss: 0.2963637113571167, 
ep: 15, global_step: 8270, layer accuracy: 0.66015625, layer loss: 0.22870400547981262, 
ep: 15, global_step: 8280, layer accuracy: 0.6328125, layer loss: 0.2686174511909485, 
valid layer_batch_acc: 0.7706892686544
ep: 15, time: 189594.91892766953
训练集的acc: 0.0
验证集的acc: 0.0
ep: 16, global_step: 8290, layer accuracy: 0.5703125, layer loss: 0.29859545826911926, 
ep: 16, global_step: 8300, layer accuracy: 0.625, layer loss: 0.2962714433670044, 
ep: 16, global_step: 8310, layer accuracy: 0.5546875, layer loss: 0.34677302837371826, 
ep: 16, global_step: 8320, layer accuracy: 0.6171875, layer loss: 0.3124508261680603, 
ep: 16, global_step: 8330, layer accuracy: 0.67578125, layer loss: 0.2562524378299713, 
ep: 16, global_step: 8340, layer accuracy: 0.640625, layer loss: 0.23990139365196228, 
ep: 16, global_step: 8350, layer accuracy: 0.57421875, layer loss: 0.36110395193099976, 
ep: 16, global_step: 8360, layer accuracy: 0.68359375, layer loss: 0.24506129324436188, 
ep: 16, global_step: 8370, layer accuracy: 0.5703125, layer loss: 0.35505837202072144, 
ep: 16, global_step: 8380, layer accuracy: 0.6484375, layer loss: 0.23050662875175476, 
ep: 16, global_step: 8390, layer accuracy: 0.62109375, layer loss: 0.2937470078468323, 
ep: 16, global_step: 8400, layer accuracy: 0.63671875, layer loss: 0.2929350733757019, 
save checkpoint -> step_8400
[2024-11-28 23:58:46,051] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-28 23:58:47,117] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_8400/pytorch_model/mp_rank_00_model_states.pt
[2024-11-28 23:58:47,117] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_8400/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-28 23:58:51,432] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_8400/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-28 23:58:51,510] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_8400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-28 23:58:51,510] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_8400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-28 23:58:51,519] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_8400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-28 23:58:51,519] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_8400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-28 23:58:51,519] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_8400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-28 23:58:51,519] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_8400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-28 23:58:51,519] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-28 23:58:51,519] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_8400 saved!
ep: 16, global_step: 8410, layer accuracy: 0.671875, layer loss: 0.24749816954135895, 
ep: 16, global_step: 8420, layer accuracy: 0.65234375, layer loss: 0.24044039845466614, 
ep: 16, global_step: 8430, layer accuracy: 0.625, layer loss: 0.26899638772010803, 
ep: 16, global_step: 8440, layer accuracy: 0.6328125, layer loss: 0.286781907081604, 
ep: 16, global_step: 8450, layer accuracy: 0.66015625, layer loss: 0.2962528467178345, 
ep: 16, global_step: 8460, layer accuracy: 0.60546875, layer loss: 0.30017662048339844, 
ep: 16, global_step: 8470, layer accuracy: 0.6328125, layer loss: 0.264777809381485, 
ep: 16, global_step: 8480, layer accuracy: 0.60546875, layer loss: 0.27856314182281494, 
ep: 16, global_step: 8490, layer accuracy: 0.6484375, layer loss: 0.21281972527503967, 
ep: 16, global_step: 8500, layer accuracy: 0.578125, layer loss: 0.31435590982437134, 
ep: 16, global_step: 8510, layer accuracy: 0.609375, layer loss: 0.32630181312561035, 
ep: 16, global_step: 8520, layer accuracy: 0.671875, layer loss: 0.2820192575454712, 
ep: 16, global_step: 8530, layer accuracy: 0.68359375, layer loss: 0.25716397166252136, 
ep: 16, global_step: 8540, layer accuracy: 0.6328125, layer loss: 0.24101004004478455, 
ep: 16, global_step: 8550, layer accuracy: 0.65625, layer loss: 0.22833594679832458, 
ep: 16, global_step: 8560, layer accuracy: 0.62109375, layer loss: 0.30801624059677124, 
ep: 16, global_step: 8570, layer accuracy: 0.6484375, layer loss: 0.22993195056915283, 
ep: 16, global_step: 8580, layer accuracy: 0.65234375, layer loss: 0.266978919506073, 
ep: 16, global_step: 8590, layer accuracy: 0.609375, layer loss: 0.2978566288948059, 
ep: 16, global_step: 8600, layer accuracy: 0.60546875, layer loss: 0.2735486924648285, 
ep: 16, global_step: 8610, layer accuracy: 0.58984375, layer loss: 0.3390982151031494, 
ep: 16, global_step: 8620, layer accuracy: 0.69921875, layer loss: 0.2782623767852783, 
ep: 16, global_step: 8630, layer accuracy: 0.625, layer loss: 0.28434014320373535, 
ep: 16, global_step: 8640, layer accuracy: 0.65234375, layer loss: 0.24063502252101898, 
ep: 16, global_step: 8650, layer accuracy: 0.62890625, layer loss: 0.2628825902938843, 
ep: 16, global_step: 8660, layer accuracy: 0.62890625, layer loss: 0.2882612943649292, 
ep: 16, global_step: 8670, layer accuracy: 0.60546875, layer loss: 0.2610135078430176, 
ep: 16, global_step: 8680, layer accuracy: 0.63671875, layer loss: 0.249128058552742, 
ep: 16, global_step: 8690, layer accuracy: 0.64453125, layer loss: 0.2654959261417389, 
ep: 16, global_step: 8700, layer accuracy: 0.65625, layer loss: 0.24137288331985474, 
ep: 16, global_step: 8710, layer accuracy: 0.640625, layer loss: 0.2674944996833801, 
ep: 16, global_step: 8720, layer accuracy: 0.6015625, layer loss: 0.3083750009536743, 
ep: 16, global_step: 8730, layer accuracy: 0.671875, layer loss: 0.23544804751873016, 
ep: 16, global_step: 8740, layer accuracy: 0.66015625, layer loss: 0.23730644583702087, 
ep: 16, global_step: 8750, layer accuracy: 0.609375, layer loss: 0.3044566512107849, 
ep: 16, global_step: 8760, layer accuracy: 0.62890625, layer loss: 0.24047471582889557, 
ep: 16, global_step: 8770, layer accuracy: 0.6484375, layer loss: 0.25440284609794617, 
ep: 16, global_step: 8780, layer accuracy: 0.61328125, layer loss: 0.2806011438369751, 
ep: 16, global_step: 8790, layer accuracy: 0.58984375, layer loss: 0.2910124957561493, 
ep: 16, global_step: 8800, layer accuracy: 0.62109375, layer loss: 0.29904085397720337, 
save checkpoint -> step_8800
[2024-11-29 01:47:35,795] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-29 01:47:36,837] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_8800/pytorch_model/mp_rank_00_model_states.pt
[2024-11-29 01:47:36,837] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_8800/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-29 01:47:41,092] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_8800/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-29 01:47:41,169] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_8800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-29 01:47:41,169] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_8800/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-29 01:47:41,177] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_8800/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-29 01:47:41,178] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_8800/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-29 01:47:41,178] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-29 01:47:41,178] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_8800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-29 01:47:41,178] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_8800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-29 01:47:41,178] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_8800 saved!
valid layer_batch_acc: 0.780527341392333
ep: 16, time: 201446.14150357246
训练集的acc: 0.0
验证集的acc: 0.0
ep: 17, global_step: 8810, layer accuracy: 0.5546875, layer loss: 0.3033433258533478, 
ep: 17, global_step: 8820, layer accuracy: 0.6640625, layer loss: 0.25300341844558716, 
ep: 17, global_step: 8830, layer accuracy: 0.66796875, layer loss: 0.251187801361084, 
ep: 17, global_step: 8840, layer accuracy: 0.609375, layer loss: 0.29519522190093994, 
ep: 17, global_step: 8850, layer accuracy: 0.65625, layer loss: 0.24928362667560577, 
ep: 17, global_step: 8860, layer accuracy: 0.671875, layer loss: 0.2554466426372528, 
ep: 17, global_step: 8870, layer accuracy: 0.64453125, layer loss: 0.23705458641052246, 
ep: 17, global_step: 8880, layer accuracy: 0.671875, layer loss: 0.2558165192604065, 
ep: 17, global_step: 8890, layer accuracy: 0.6484375, layer loss: 0.24860918521881104, 
ep: 17, global_step: 8900, layer accuracy: 0.6640625, layer loss: 0.2429760992527008, 
ep: 17, global_step: 8910, layer accuracy: 0.6640625, layer loss: 0.22304236888885498, 
ep: 17, global_step: 8920, layer accuracy: 0.62890625, layer loss: 0.2614944875240326, 
ep: 17, global_step: 8930, layer accuracy: 0.6796875, layer loss: 0.2315463125705719, 
ep: 17, global_step: 8940, layer accuracy: 0.6015625, layer loss: 0.324636846780777, 
ep: 17, global_step: 8950, layer accuracy: 0.60546875, layer loss: 0.28502827882766724, 
ep: 17, global_step: 8960, layer accuracy: 0.6171875, layer loss: 0.27108925580978394, 
ep: 17, global_step: 8970, layer accuracy: 0.6171875, layer loss: 0.2929939925670624, 
ep: 17, global_step: 8980, layer accuracy: 0.64453125, layer loss: 0.28928083181381226, 
ep: 17, global_step: 8990, layer accuracy: 0.62890625, layer loss: 0.27255022525787354, 
ep: 17, global_step: 9000, layer accuracy: 0.60546875, layer loss: 0.28066855669021606, 
ep: 17, global_step: 9010, layer accuracy: 0.63671875, layer loss: 0.26189756393432617, 
ep: 17, global_step: 9020, layer accuracy: 0.59765625, layer loss: 0.2601974904537201, 
ep: 17, global_step: 9030, layer accuracy: 0.59375, layer loss: 0.3172776699066162, 
ep: 17, global_step: 9040, layer accuracy: 0.63671875, layer loss: 0.24623790383338928, 
ep: 17, global_step: 9050, layer accuracy: 0.66015625, layer loss: 0.2683962285518646, 
ep: 17, global_step: 9060, layer accuracy: 0.65625, layer loss: 0.2495325654745102, 
ep: 17, global_step: 9070, layer accuracy: 0.6171875, layer loss: 0.3074944317340851, 
ep: 17, global_step: 9080, layer accuracy: 0.62109375, layer loss: 0.3128153085708618, 
ep: 17, global_step: 9090, layer accuracy: 0.6171875, layer loss: 0.28528597950935364, 
ep: 17, global_step: 9100, layer accuracy: 0.6875, layer loss: 0.2573951780796051, 
ep: 17, global_step: 9110, layer accuracy: 0.64453125, layer loss: 0.2500479221343994, 
ep: 17, global_step: 9120, layer accuracy: 0.6640625, layer loss: 0.2510907053947449, 
ep: 17, global_step: 9130, layer accuracy: 0.6484375, layer loss: 0.3192889094352722, 
ep: 17, global_step: 9140, layer accuracy: 0.63671875, layer loss: 0.28970763087272644, 
ep: 17, global_step: 9150, layer accuracy: 0.63671875, layer loss: 0.23769918084144592, 
ep: 17, global_step: 9160, layer accuracy: 0.625, layer loss: 0.3328414559364319, 
ep: 17, global_step: 9170, layer accuracy: 0.62890625, layer loss: 0.29952728748321533, 
ep: 17, global_step: 9180, layer accuracy: 0.625, layer loss: 0.2909936010837555, 
ep: 17, global_step: 9190, layer accuracy: 0.65625, layer loss: 0.23831528425216675, 
ep: 17, global_step: 9200, layer accuracy: 0.62109375, layer loss: 0.28291192650794983, 
save checkpoint -> step_9200
[2024-11-29 04:32:57,964] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-29 04:32:58,983] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_9200/pytorch_model/mp_rank_00_model_states.pt
[2024-11-29 04:32:58,983] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_9200/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-29 04:33:03,138] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_9200/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-29 04:33:03,198] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_9200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-29 04:33:03,198] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_9200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-29 04:33:03,206] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_9200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-29 04:33:03,206] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_9200/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-29 04:33:03,206] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-29 04:33:03,206] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_9200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-29 04:33:03,207] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_9200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-29 04:33:03,207] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_9200 saved!
ep: 17, global_step: 9210, layer accuracy: 0.65625, layer loss: 0.24904875457286835, 
ep: 17, global_step: 9220, layer accuracy: 0.6328125, layer loss: 0.2988653779029846, 
ep: 17, global_step: 9230, layer accuracy: 0.58984375, layer loss: 0.3293854296207428, 
ep: 17, global_step: 9240, layer accuracy: 0.62109375, layer loss: 0.2641039788722992, 
ep: 17, global_step: 9250, layer accuracy: 0.65234375, layer loss: 0.224823459982872, 
ep: 17, global_step: 9260, layer accuracy: 0.62109375, layer loss: 0.32549840211868286, 
ep: 17, global_step: 9270, layer accuracy: 0.578125, layer loss: 0.33176660537719727, 
ep: 17, global_step: 9280, layer accuracy: 0.6015625, layer loss: 0.30390632152557373, 
ep: 17, global_step: 9290, layer accuracy: 0.65625, layer loss: 0.2779434621334076, 
ep: 17, global_step: 9300, layer accuracy: 0.66796875, layer loss: 0.23789584636688232, 
ep: 17, global_step: 9310, layer accuracy: 0.6640625, layer loss: 0.2386709749698639, 
ep: 17, global_step: 9320, layer accuracy: 0.6015625, layer loss: 0.29631003737449646, 
valid layer_batch_acc: 0.7812343720360758
ep: 17, time: 213296.90771317482
训练集的acc: 0.0
验证集的acc: 0.0
ep: 18, global_step: 9330, layer accuracy: 0.671875, layer loss: 0.2341446876525879, 
ep: 18, global_step: 9340, layer accuracy: 0.6796875, layer loss: 0.2733575701713562, 
ep: 18, global_step: 9350, layer accuracy: 0.609375, layer loss: 0.30320703983306885, 
ep: 18, global_step: 9360, layer accuracy: 0.6328125, layer loss: 0.30382993817329407, 
ep: 18, global_step: 9370, layer accuracy: 0.6796875, layer loss: 0.22436442971229553, 
ep: 18, global_step: 9380, layer accuracy: 0.63671875, layer loss: 0.2753034830093384, 
ep: 18, global_step: 9390, layer accuracy: 0.63671875, layer loss: 0.27034151554107666, 
ep: 18, global_step: 9400, layer accuracy: 0.67578125, layer loss: 0.2314300686120987, 
ep: 18, global_step: 9410, layer accuracy: 0.6484375, layer loss: 0.26893725991249084, 
ep: 18, global_step: 9420, layer accuracy: 0.640625, layer loss: 0.30601057410240173, 
ep: 18, global_step: 9430, layer accuracy: 0.65625, layer loss: 0.24402955174446106, 
ep: 18, global_step: 9440, layer accuracy: 0.64453125, layer loss: 0.23206040263175964, 
ep: 18, global_step: 9450, layer accuracy: 0.5859375, layer loss: 0.3116738200187683, 
ep: 18, global_step: 9460, layer accuracy: 0.65234375, layer loss: 0.26478153467178345, 
ep: 18, global_step: 9470, layer accuracy: 0.61328125, layer loss: 0.2720258831977844, 
ep: 18, global_step: 9480, layer accuracy: 0.640625, layer loss: 0.24355635046958923, 
ep: 18, global_step: 9490, layer accuracy: 0.65625, layer loss: 0.2958439290523529, 
ep: 18, global_step: 9500, layer accuracy: 0.66796875, layer loss: 0.23195868730545044, 
ep: 18, global_step: 9510, layer accuracy: 0.64453125, layer loss: 0.2819860279560089, 
ep: 18, global_step: 9520, layer accuracy: 0.59765625, layer loss: 0.3007464110851288, 
ep: 18, global_step: 9530, layer accuracy: 0.66015625, layer loss: 0.23106001317501068, 
ep: 18, global_step: 9540, layer accuracy: 0.62890625, layer loss: 0.26573288440704346, 
ep: 18, global_step: 9550, layer accuracy: 0.6171875, layer loss: 0.24376583099365234, 
ep: 18, global_step: 9560, layer accuracy: 0.625, layer loss: 0.30659717321395874, 
ep: 18, global_step: 9570, layer accuracy: 0.6640625, layer loss: 0.3364189565181732, 
ep: 18, global_step: 9580, layer accuracy: 0.65234375, layer loss: 0.2521982192993164, 
ep: 18, global_step: 9590, layer accuracy: 0.625, layer loss: 0.3032785654067993, 
ep: 18, global_step: 9600, layer accuracy: 0.640625, layer loss: 0.29064756631851196, 
save checkpoint -> step_9600
[2024-11-29 07:18:24,604] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-29 07:18:25,613] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_9600/pytorch_model/mp_rank_00_model_states.pt
[2024-11-29 07:18:25,614] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_9600/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-29 07:18:29,743] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_9600/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-29 07:18:30,002] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_9600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-29 07:18:30,002] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_9600/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-29 07:18:30,010] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_9600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-29 07:18:30,010] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_9600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-29 07:18:30,010] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-29 07:18:30,010] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_9600/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-29 07:18:30,010] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_9600/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-29 07:18:30,010] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_9600 saved!
ep: 18, global_step: 9610, layer accuracy: 0.6328125, layer loss: 0.2438209354877472, 
ep: 18, global_step: 9620, layer accuracy: 0.62890625, layer loss: 0.2636244297027588, 
ep: 18, global_step: 9630, layer accuracy: 0.671875, layer loss: 0.1968551129102707, 
ep: 18, global_step: 9640, layer accuracy: 0.65625, layer loss: 0.2654682397842407, 
ep: 18, global_step: 9650, layer accuracy: 0.6015625, layer loss: 0.3161852955818176, 
ep: 18, global_step: 9660, layer accuracy: 0.6640625, layer loss: 0.23746654391288757, 
ep: 18, global_step: 9670, layer accuracy: 0.6171875, layer loss: 0.26464954018592834, 
ep: 18, global_step: 9680, layer accuracy: 0.67578125, layer loss: 0.19278877973556519, 
ep: 18, global_step: 9690, layer accuracy: 0.671875, layer loss: 0.21592283248901367, 
ep: 18, global_step: 9700, layer accuracy: 0.62890625, layer loss: 0.2912988066673279, 
ep: 18, global_step: 9710, layer accuracy: 0.60546875, layer loss: 0.3052402138710022, 
ep: 18, global_step: 9720, layer accuracy: 0.66015625, layer loss: 0.28549984097480774, 
ep: 18, global_step: 9730, layer accuracy: 0.66015625, layer loss: 0.23590019345283508, 
ep: 18, global_step: 9740, layer accuracy: 0.63671875, layer loss: 0.2783270478248596, 
ep: 18, global_step: 9750, layer accuracy: 0.609375, layer loss: 0.28943923115730286, 
ep: 18, global_step: 9760, layer accuracy: 0.62109375, layer loss: 0.24602052569389343, 
ep: 18, global_step: 9770, layer accuracy: 0.6484375, layer loss: 0.23524382710456848, 
ep: 18, global_step: 9780, layer accuracy: 0.609375, layer loss: 0.2585141956806183, 
ep: 18, global_step: 9790, layer accuracy: 0.6328125, layer loss: 0.22145143151283264, 
ep: 18, global_step: 9800, layer accuracy: 0.66015625, layer loss: 0.2901144325733185, 
ep: 18, global_step: 9810, layer accuracy: 0.62890625, layer loss: 0.24027353525161743, 
ep: 18, global_step: 9820, layer accuracy: 0.6171875, layer loss: 0.24676813185214996, 
ep: 18, global_step: 9830, layer accuracy: 0.55078125, layer loss: 0.32687950134277344, 
ep: 18, global_step: 9840, layer accuracy: 0.640625, layer loss: 0.2426624298095703, 
valid layer_batch_acc: 0.78621807584197
ep: 18, time: 225141.35905885696
训练集的acc: 0.0
验证集的acc: 0.0
ep: 19, global_step: 9850, layer accuracy: 0.625, layer loss: 0.24905148148536682, 
ep: 19, global_step: 9860, layer accuracy: 0.64453125, layer loss: 0.25219476222991943, 
ep: 19, global_step: 9870, layer accuracy: 0.6328125, layer loss: 0.27941083908081055, 
ep: 19, global_step: 9880, layer accuracy: 0.65234375, layer loss: 0.2643951177597046, 
ep: 19, global_step: 9890, layer accuracy: 0.60546875, layer loss: 0.3097362518310547, 
ep: 19, global_step: 9900, layer accuracy: 0.64453125, layer loss: 0.29761403799057007, 
ep: 19, global_step: 9910, layer accuracy: 0.59375, layer loss: 0.3327598571777344, 
ep: 19, global_step: 9920, layer accuracy: 0.69140625, layer loss: 0.25658851861953735, 
ep: 19, global_step: 9930, layer accuracy: 0.609375, layer loss: 0.32050150632858276, 
ep: 19, global_step: 9940, layer accuracy: 0.6484375, layer loss: 0.26015815138816833, 
ep: 19, global_step: 9950, layer accuracy: 0.6640625, layer loss: 0.2134270966053009, 
ep: 19, global_step: 9960, layer accuracy: 0.58984375, layer loss: 0.33192533254623413, 
ep: 19, global_step: 9970, layer accuracy: 0.64453125, layer loss: 0.2749410569667816, 
ep: 19, global_step: 9980, layer accuracy: 0.62890625, layer loss: 0.2737399935722351, 
ep: 19, global_step: 9990, layer accuracy: 0.64453125, layer loss: 0.22719255089759827, 
ep: 19, global_step: 10000, layer accuracy: 0.6875, layer loss: 0.24403716623783112, 
save checkpoint -> step_10000
[2024-11-29 10:03:41,791] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-29 10:03:42,817] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_10000/pytorch_model/mp_rank_00_model_states.pt
[2024-11-29 10:03:42,817] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_10000/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-29 10:03:46,950] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_10000/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-29 10:03:47,167] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_10000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-29 10:03:47,167] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_10000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-29 10:03:47,175] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_10000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-29 10:03:47,175] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_10000/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-29 10:03:47,175] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-29 10:03:47,175] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_10000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-29 10:03:47,176] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_10000/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-29 10:03:47,176] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_10000 saved!
ep: 19, global_step: 10010, layer accuracy: 0.59765625, layer loss: 0.2582896649837494, 
ep: 19, global_step: 10020, layer accuracy: 0.609375, layer loss: 0.2768539488315582, 
ep: 19, global_step: 10030, layer accuracy: 0.6875, layer loss: 0.23022235929965973, 
ep: 19, global_step: 10040, layer accuracy: 0.65625, layer loss: 0.25041958689689636, 
ep: 19, global_step: 10050, layer accuracy: 0.609375, layer loss: 0.2790779173374176, 
ep: 19, global_step: 10060, layer accuracy: 0.65625, layer loss: 0.2560213804244995, 
ep: 19, global_step: 10070, layer accuracy: 0.65234375, layer loss: 0.2456236034631729, 
ep: 19, global_step: 10080, layer accuracy: 0.671875, layer loss: 0.2876824140548706, 
ep: 19, global_step: 10090, layer accuracy: 0.69140625, layer loss: 0.22130510210990906, 
ep: 19, global_step: 10100, layer accuracy: 0.66796875, layer loss: 0.25392287969589233, 
ep: 19, global_step: 10110, layer accuracy: 0.64453125, layer loss: 0.2910502552986145, 
ep: 19, global_step: 10120, layer accuracy: 0.640625, layer loss: 0.26915574073791504, 
ep: 19, global_step: 10130, layer accuracy: 0.63671875, layer loss: 0.26701346039772034, 
ep: 19, global_step: 10140, layer accuracy: 0.58984375, layer loss: 0.23747442662715912, 
ep: 19, global_step: 10150, layer accuracy: 0.6328125, layer loss: 0.278143048286438, 
ep: 19, global_step: 10160, layer accuracy: 0.6484375, layer loss: 0.2376275360584259, 
ep: 19, global_step: 10170, layer accuracy: 0.65625, layer loss: 0.20602095127105713, 
ep: 19, global_step: 10180, layer accuracy: 0.70703125, layer loss: 0.21792446076869965, 
ep: 19, global_step: 10190, layer accuracy: 0.62109375, layer loss: 0.2860545516014099, 
ep: 19, global_step: 10200, layer accuracy: 0.66015625, layer loss: 0.2401912361383438, 
ep: 19, global_step: 10210, layer accuracy: 0.65625, layer loss: 0.2728472948074341, 
ep: 19, global_step: 10220, layer accuracy: 0.6015625, layer loss: 0.2652176320552826, 
ep: 19, global_step: 10230, layer accuracy: 0.64453125, layer loss: 0.23624858260154724, 
ep: 19, global_step: 10240, layer accuracy: 0.68359375, layer loss: 0.1927952617406845, 
ep: 19, global_step: 10250, layer accuracy: 0.62890625, layer loss: 0.25585561990737915, 
ep: 19, global_step: 10260, layer accuracy: 0.671875, layer loss: 0.26862332224845886, 
ep: 19, global_step: 10270, layer accuracy: 0.62890625, layer loss: 0.2687491774559021, 
ep: 19, global_step: 10280, layer accuracy: 0.58203125, layer loss: 0.3179965615272522, 
ep: 19, global_step: 10290, layer accuracy: 0.64453125, layer loss: 0.24357721209526062, 
ep: 19, global_step: 10300, layer accuracy: 0.64453125, layer loss: 0.2318938672542572, 
ep: 19, global_step: 10310, layer accuracy: 0.703125, layer loss: 0.2395370751619339, 
ep: 19, global_step: 10320, layer accuracy: 0.65625, layer loss: 0.23419299721717834, 
ep: 19, global_step: 10330, layer accuracy: 0.6328125, layer loss: 0.3456738591194153, 
ep: 19, global_step: 10340, layer accuracy: 0.71484375, layer loss: 0.24125882983207703, 
ep: 19, global_step: 10350, layer accuracy: 0.6328125, layer loss: 0.25658881664276123, 
ep: 19, global_step: 10360, layer accuracy: 0.654320987654321, layer loss: 0.3088528513908386, 
valid layer_batch_acc: 0.786330166065978
ep: 19, time: 236980.16077780724
训练集的acc: 0.0
验证集的acc: 0.0
ep: 20, global_step: 10370, layer accuracy: 0.63671875, layer loss: 0.2805306315422058, 
ep: 20, global_step: 10380, layer accuracy: 0.69921875, layer loss: 0.2090749740600586, 
ep: 20, global_step: 10390, layer accuracy: 0.66796875, layer loss: 0.24959924817085266, 
ep: 20, global_step: 10400, layer accuracy: 0.65234375, layer loss: 0.24712975323200226, 
save checkpoint -> step_10400
[2024-11-29 12:48:55,779] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-11-29 12:48:56,784] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_10400/pytorch_model/mp_rank_00_model_states.pt
[2024-11-29 12:48:56,785] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_10400/pytorch_model/mp_rank_00_model_states.pt...
[2024-11-29 12:49:01,002] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_10400/pytorch_model/mp_rank_00_model_states.pt.
[2024-11-29 12:49:01,071] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_10400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-11-29 12:49:01,071] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_10400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt...
[2024-11-29 12:49:01,080] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_10400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt.
[2024-11-29 12:49:01,080] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_10400/pytorch_model/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt
[2024-11-29 12:49:01,080] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_10400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-11-29 12:49:01,080] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
[2024-11-29 12:49:01,080] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_10400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-11-29 12:49:01,080] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_10400 saved!

name:  shared.weight param num:  131072
name:  encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight param num:  8192
name:  encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight param num:  32768
name:  encoder.block.23.layer.0.SelfAttention.k.lora_A.default.weight param num:  8192
name:  encoder.block.23.layer.0.SelfAttention.k.lora_B.default.weight param num:  32768
name:  encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight param num:  8192
name:  encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight param num:  32768
name:  encoder.block.23.layer.0.SelfAttention.o.lora_A.default.weight param num:  32768
name:  encoder.block.23.layer.0.SelfAttention.o.lora_B.default.weight param num:  8192
name:  encoder.block.23.layer.1.DenseReluDense.wi.lora_A.default.weight param num:  8192
name:  encoder.block.23.layer.1.DenseReluDense.wi.lora_B.default.weight param num:  131072
name:  encoder.block.23.layer.1.DenseReluDense.wo.lora_A.default.weight param num:  131072
name:  encoder.block.23.layer.1.DenseReluDense.wo.lora_B.default.weight param num:  8192
name:  layer_classifier.local_layers.0.0.weight param num:  65536
name:  layer_classifier.local_layers.0.0.bias param num:  256
name:  layer_classifier.local_layers.0.2.weight param num:  256
name:  layer_classifier.local_layers.0.2.bias param num:  256
name:  layer_classifier.local_layers.0.3.weight param num:  4096
name:  layer_classifier.local_layers.0.3.bias param num:  16
name:  layer_classifier.local_layers.1.0.weight param num:  131072
name:  layer_classifier.local_layers.1.0.bias param num:  512
name:  layer_classifier.local_layers.1.2.weight param num:  512
name:  layer_classifier.local_layers.1.2.bias param num:  512
name:  layer_classifier.local_layers.1.3.weight param num:  75264
name:  layer_classifier.local_layers.1.3.bias param num:  147
name:  layer_classifier.global_layers.0.0.weight param num:  262144
name:  layer_classifier.global_layers.0.0.bias param num:  256
name:  layer_classifier.global_layers.0.2.weight param num:  256
name:  layer_classifier.global_layers.0.2.bias param num:  256
name:  layer_classifier.global_layers.1.0.weight param num:  327680
name:  layer_classifier.global_layers.1.0.bias param num:  256
name:  layer_classifier.global_layers.1.2.weight param num:  256
name:  layer_classifier.global_layers.1.2.bias param num:  256
name:  layer_classifier.linear.weight param num:  41728
name:  layer_classifier.linear.bias param num:  163
name:  node_classifier.layer_score.weight param num:  83456
name:  node_classifier.layer_score.bias param num:  512
name:  node_classifier.hidden_score.weight param num:  524288
name:  node_classifier.hidden_score.bias param num:  512
name:  node_classifier.batch_norm1.weight param num:  1024
name:  node_classifier.batch_norm1.bias param num:  1024
name:  node_classifier.out_proj.weight param num:  1593344
name:  node_classifier.out_proj.bias param num:  1556
trainable paras number: 3690842
layer param: shared.weight
layer param: encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight
layer param: encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight
layer param: encoder.block.23.layer.0.SelfAttention.k.lora_A.default.weight
layer param: encoder.block.23.layer.0.SelfAttention.k.lora_B.default.weight
layer param: encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight
layer param: encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight
layer param: encoder.block.23.layer.0.SelfAttention.o.lora_A.default.weight
layer param: encoder.block.23.layer.0.SelfAttention.o.lora_B.default.weight
layer param: encoder.block.23.layer.1.DenseReluDense.wi.lora_A.default.weight
layer param: encoder.block.23.layer.1.DenseReluDense.wi.lora_B.default.weight
layer param: encoder.block.23.layer.1.DenseReluDense.wo.lora_A.default.weight
layer param: encoder.block.23.layer.1.DenseReluDense.wo.lora_B.default.weight
layer param: layer_classifier.local_layers.0.0.weight
layer param: layer_classifier.local_layers.0.0.bias
layer param: layer_classifier.local_layers.0.2.weight
layer param: layer_classifier.local_layers.0.2.bias
layer param: layer_classifier.local_layers.0.3.weight
layer param: layer_classifier.local_layers.0.3.bias
layer param: layer_classifier.local_layers.1.0.weight
layer param: layer_classifier.local_layers.1.0.bias
layer param: layer_classifier.local_layers.1.2.weight
layer param: layer_classifier.local_layers.1.2.bias
layer param: layer_classifier.local_layers.1.3.weight
layer param: layer_classifier.local_layers.1.3.bias
layer param: layer_classifier.global_layers.0.0.weight
layer param: layer_classifier.global_layers.0.0.bias
layer param: layer_classifier.global_layers.0.2.weight
layer param: layer_classifier.global_layers.0.2.bias
layer param: layer_classifier.global_layers.1.0.weight
layer param: layer_classifier.global_layers.1.0.bias
layer param: layer_classifier.global_layers.1.2.weight
layer param: layer_classifier.global_layers.1.2.bias
layer param: layer_classifier.linear.weight
layer param: layer_classifier.linear.bias
node param: node_classifier.layer_score.weight
node param: node_classifier.layer_score.bias
node param: node_classifier.hidden_score.weight
node param: node_classifier.hidden_score.bias
node param: node_classifier.batch_norm1.weight
node param: node_classifier.batch_norm1.bias
node param: node_classifier.out_proj.weight
node param: node_classifier.out_proj.bias
[2024-12-02 16:25:51,236] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.15.1, git-hash=unknown, git-branch=unknown
[2024-12-02 16:25:51,236] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 1
[2024-12-02 16:25:51,383] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-12-02 16:25:51,384] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-12-02 16:25:51,384] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-12-02 16:25:51,385] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-12-02 16:25:51,385] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-12-02 16:25:51,386] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-12-02 16:25:51,386] [INFO] [stage_1_and_2.py:148:__init__] Reduce bucket size 500000000
[2024-12-02 16:25:51,386] [INFO] [stage_1_and_2.py:149:__init__] Allgather bucket size 500000000
[2024-12-02 16:25:51,386] [INFO] [stage_1_and_2.py:150:__init__] CPU Offload: False
[2024-12-02 16:25:51,386] [INFO] [stage_1_and_2.py:151:__init__] Round robin gradient partitioning: False
[2024-12-02 16:25:51,533] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2024-12-02 16:25:51,533] [INFO] [utils.py:782:see_memory_usage] MA 2.27 GB         Max_MA 2.28 GB         CA 2.31 GB         Max_CA 2 GB 
[2024-12-02 16:25:51,533] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 22.63 GB, percent = 18.0%
[2024-12-02 16:25:51,626] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2024-12-02 16:25:51,627] [INFO] [utils.py:782:see_memory_usage] MA 2.27 GB         Max_MA 2.29 GB         CA 2.31 GB         Max_CA 2 GB 
[2024-12-02 16:25:51,627] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 22.63 GB, percent = 18.0%
[2024-12-02 16:25:51,627] [INFO] [stage_1_and_2.py:543:__init__] optimizer state initialized
[2024-12-02 16:25:51,719] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2024-12-02 16:25:51,720] [INFO] [utils.py:782:see_memory_usage] MA 2.27 GB         Max_MA 2.27 GB         CA 2.31 GB         Max_CA 2 GB 
[2024-12-02 16:25:51,720] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 22.63 GB, percent = 18.0%
[2024-12-02 16:25:51,721] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[2024-12-02 16:25:51,721] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None
[2024-12-02 16:25:51,721] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-12-02 16:25:51,721] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0001], mom=[(0.9, 0.999)]
[2024-12-02 16:25:51,722] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[2024-12-02 16:25:51,722] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-12-02 16:25:51,722] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2024-12-02 16:25:51,722] [INFO] [config.py:1003:print]   amp_enabled .................. False
[2024-12-02 16:25:51,722] [INFO] [config.py:1003:print]   amp_params ................... False
[2024-12-02 16:25:51,722] [INFO] [config.py:1003:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-12-02 16:25:51,722] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[2024-12-02 16:25:51,722] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[2024-12-02 16:25:51,722] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[2024-12-02 16:25:51,722] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[2024-12-02 16:25:51,722] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[2024-12-02 16:25:51,722] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fcf03d01d60>
[2024-12-02 16:25:51,722] [INFO] [config.py:1003:print]   communication_data_type ...... None
[2024-12-02 16:25:51,722] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   disable_allgather ............ False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   dump_state ................... False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   global_rank .................. 0
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 8
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   optimizer_name ............... None
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   optimizer_params ............. None
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   pld_enabled .................. False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   pld_params ................... False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   scheduler_name ............... None
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   scheduler_params ............. None
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   sparse_attention ............. None
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   steps_per_print .............. inf
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   train_batch_size ............. 512
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  64
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[2024-12-02 16:25:51,723] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[2024-12-02 16:25:51,724] [INFO] [config.py:1003:print]   world_size ................... 1
[2024-12-02 16:25:51,724] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  True
[2024-12-02 16:25:51,724] [INFO] [config.py:1003:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100000000, max_in_cpu=1000000000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-12-02 16:25:51,724] [INFO] [config.py:1003:print]   zero_enabled ................. True
[2024-12-02 16:25:51,724] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[2024-12-02 16:25:51,724] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 2
[2024-12-02 16:25:51,724] [INFO] [config.py:989:print_user_config]   json = {
    "train_batch_size": 512, 
    "train_micro_batch_size_per_gpu": 64, 
    "gradient_accumulation_steps": 8, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": false
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
ep: 0, global_step: 10, layer accuracy: 0.0, total loss: 8.05652904510498, layer loss: 1.9001795053482056, bottom loss: 3.086050271987915, node loss: 3.070298910140991
ep: 0, global_step: 20, layer accuracy: 0.0, total loss: 7.853265762329102, layer loss: 1.8488041162490845, bottom loss: 3.020740270614624, node loss: 2.9837210178375244
node contra_loss: 0.0
ep: 0, global_step: 30, layer accuracy: 0.0, total loss: 7.697074890136719, layer loss: 1.828757882118225, bottom loss: 2.9532811641693115, node loss: 2.9150359630584717
node contra_loss: 0.0
ep: 0, global_step: 40, layer accuracy: 0.0, total loss: 7.593113899230957, layer loss: 1.7434985637664795, bottom loss: 2.811807870864868, node loss: 2.7487449645996094
node contra_loss: 0.2890625
ep: 0, global_step: 50, layer accuracy: 0.0, total loss: 7.401185989379883, layer loss: 1.69119393825531, bottom loss: 2.791454553604126, node loss: 2.7251780033111572
node contra_loss: 0.193359375
ep: 0, global_step: 60, layer accuracy: 0.0, total loss: 7.097838401794434, layer loss: 1.6640725135803223, bottom loss: 2.7429842948913574, node loss: 2.690781831741333
node contra_loss: 0.0
ep: 0, global_step: 70, layer accuracy: 0.0, total loss: 7.031123161315918, layer loss: 1.6439170837402344, bottom loss: 2.7279860973358154, node loss: 2.65921950340271
node contra_loss: 0.0
ep: 0, global_step: 80, layer accuracy: 0.0, total loss: 6.713864803314209, layer loss: 1.5967395305633545, bottom loss: 2.5891406536102295, node loss: 2.527984619140625
node contra_loss: 0.0
ep: 0, global_step: 90, layer accuracy: 0.0, total loss: 6.703110218048096, layer loss: 1.6128339767456055, bottom loss: 2.5751700401306152, node loss: 2.515106201171875
node contra_loss: 0.0
ep: 0, global_step: 100, layer accuracy: 0.0, total loss: 6.791996955871582, layer loss: 1.6420942544937134, bottom loss: 2.5905189514160156, node loss: 2.5349700450897217
node contra_loss: 0.0244140625
ep: 0, global_step: 110, layer accuracy: 0.0, total loss: 6.498830318450928, layer loss: 1.5777833461761475, bottom loss: 2.5023059844970703, node loss: 2.418740749359131
node contra_loss: 0.0
ep: 0, global_step: 120, layer accuracy: 0.0, total loss: 6.122129440307617, layer loss: 1.4806511402130127, bottom loss: 2.362881898880005, node loss: 2.2785964012145996
node contra_loss: 0.0
ep: 0, global_step: 130, layer accuracy: 0.0, total loss: 6.606225490570068, layer loss: 1.4837877750396729, bottom loss: 2.333272695541382, node loss: 2.2657275199890137
node contra_loss: 0.5234375
ep: 0, global_step: 140, layer accuracy: 0.0, total loss: 6.022239685058594, layer loss: 1.4572834968566895, bottom loss: 2.2920708656311035, node loss: 2.21941876411438
node contra_loss: 0.053466796875
ep: 0, global_step: 150, layer accuracy: 0.0, total loss: 5.807525634765625, layer loss: 1.396530270576477, bottom loss: 2.2345147132873535, node loss: 2.176480770111084
node contra_loss: 0.0
ep: 0, global_step: 160, layer accuracy: 0.0, total loss: 5.584536075592041, layer loss: 1.3679383993148804, bottom loss: 2.153102397918701, node loss: 2.06349515914917
node contra_loss: 0.0
ep: 0, global_step: 170, layer accuracy: 0.0, total loss: 5.594632148742676, layer loss: 1.4044175148010254, bottom loss: 2.129671335220337, node loss: 2.0605432987213135
ep: 0, global_step: 180, layer accuracy: 0.0, total loss: 5.458970069885254, layer loss: 1.3488867282867432, bottom loss: 2.059455394744873, node loss: 1.9808037281036377
node contra_loss: 0.06982421875
ep: 0, global_step: 190, layer accuracy: 0.0, total loss: 5.325395584106445, layer loss: 1.358338475227356, bottom loss: 2.020063877105713, node loss: 1.9469932317733765
ep: 0, global_step: 200, layer accuracy: 0.0, total loss: 5.160408973693848, layer loss: 1.273205280303955, bottom loss: 1.9338631629943848, node loss: 1.8581254482269287
node contra_loss: 0.09521484375
ep: 0, global_step: 210, layer accuracy: 0.0, total loss: 5.096893310546875, layer loss: 1.3247501850128174, bottom loss: 1.922666311264038, node loss: 1.849476933479309
node contra_loss: 0.0
ep: 0, global_step: 220, layer accuracy: 0.0, total loss: 4.849059104919434, layer loss: 1.2614638805389404, bottom loss: 1.8268909454345703, node loss: 1.760704517364502
node contra_loss: 2.759043127298355e-08
ep: 0, global_step: 230, layer accuracy: 0.0, total loss: 4.710776329040527, layer loss: 1.2312943935394287, bottom loss: 1.7860581874847412, node loss: 1.6933728456497192
node contra_loss: 5.078315734863281e-05
ep: 0, global_step: 240, layer accuracy: 0.0, total loss: 4.603213310241699, layer loss: 1.2389295101165771, bottom loss: 1.7210668325424194, node loss: 1.6422784328460693
node contra_loss: 0.00093841552734375
ep: 0, global_step: 250, layer accuracy: 0.0, total loss: 4.62623405456543, layer loss: 1.2395594120025635, bottom loss: 1.7210896015167236, node loss: 1.6655844449996948
node contra_loss: 2.421438694000244e-07
ep: 0, global_step: 260, layer accuracy: 0.0, total loss: 4.548313617706299, layer loss: 1.2600126266479492, bottom loss: 1.6745548248291016, node loss: 1.6137460470199585
ep: 0, global_step: 270, layer accuracy: 0.0, total loss: 4.399026870727539, layer loss: 1.2007927894592285, bottom loss: 1.6344610452651978, node loss: 1.5637729167938232
node contra_loss: 0.0
ep: 0, global_step: 280, layer accuracy: 0.0, total loss: 4.3265862464904785, layer loss: 1.1912305355072021, bottom loss: 1.5640919208526611, node loss: 1.5048575401306152
node contra_loss: 0.06640625
ep: 0, global_step: 290, layer accuracy: 0.0, total loss: 4.378448486328125, layer loss: 1.2196136713027954, bottom loss: 1.606775164604187, node loss: 1.5520594120025635
node contra_loss: 6.664777174592018e-09
ep: 0, global_step: 300, layer accuracy: 0.0, total loss: 4.040406703948975, layer loss: 1.1103193759918213, bottom loss: 1.5040199756622314, node loss: 1.4260674715042114
node contra_loss: 0.0
ep: 0, global_step: 310, layer accuracy: 0.0, total loss: 4.1200408935546875, layer loss: 1.1625945568084717, bottom loss: 1.513140082359314, node loss: 1.4443061351776123
node contra_loss: 0.0
ep: 0, global_step: 320, layer accuracy: 0.0, total loss: 3.9527339935302734, layer loss: 1.1220797300338745, bottom loss: 1.420607566833496, node loss: 1.3658570051193237
node contra_loss: 0.044189453125
ep: 0, global_step: 330, layer accuracy: 0.0, total loss: 3.7539188861846924, layer loss: 1.0403661727905273, bottom loss: 1.3894243240356445, node loss: 1.3239405155181885
node contra_loss: 0.00018787384033203125
ep: 0, global_step: 340, layer accuracy: 0.0, total loss: 3.8600592613220215, layer loss: 1.1057482957839966, bottom loss: 1.4134465456008911, node loss: 1.3408643007278442
node contra_loss: 0.0
ep: 0, global_step: 350, layer accuracy: 0.0, total loss: 3.6897811889648438, layer loss: 1.0665404796600342, bottom loss: 1.3369874954223633, node loss: 1.2799664735794067
node contra_loss: 0.00628662109375
ep: 0, global_step: 360, layer accuracy: 0.0, total loss: 3.4697365760803223, layer loss: 1.0007567405700684, bottom loss: 1.2660725116729736, node loss: 1.2029072046279907
node contra_loss: 0.0
ep: 0, global_step: 370, layer accuracy: 0.0, total loss: 3.7405202388763428, layer loss: 1.0336410999298096, bottom loss: 1.3076788187026978, node loss: 1.268340826034546
node contra_loss: 0.130859375
ep: 0, global_step: 380, layer accuracy: 0.0, total loss: 3.68696928024292, layer loss: 1.104590892791748, bottom loss: 1.3146532773971558, node loss: 1.2677251100540161
ep: 0, global_step: 390, layer accuracy: 0.0, total loss: 3.427140235900879, layer loss: 1.0335181951522827, bottom loss: 1.2241179943084717, node loss: 1.1695040464401245
node contra_loss: 7.962808012962341e-08
ep: 0, global_step: 400, layer accuracy: 0.0, total loss: 3.3489623069763184, layer loss: 0.9787932634353638, bottom loss: 1.2141649723052979, node loss: 1.1560040712356567
node contra_loss: 0.0
save checkpoint -> step_400
[2024-12-02 21:27:58,135] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-12-02 21:27:59,889] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_400/pytorch_model/mp_rank_00_model_states.pt
[2024-12-02 21:27:59,889] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_400/pytorch_model/mp_rank_00_model_states.pt...
[2024-12-02 21:28:04,335] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_400/pytorch_model/mp_rank_00_model_states.pt.
[2024-12-02 21:28:04,391] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-12-02 21:28:04,428] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-12-02 21:28:04,429] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_400/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-12-02 21:28:04,429] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_400 saved!
ep: 0, global_step: 410, layer accuracy: 0.0, total loss: 3.3822243213653564, layer loss: 1.002626657485962, bottom loss: 1.1999331712722778, node loss: 1.1403577327728271
node contra_loss: 0.039306640625
ep: 0, global_step: 420, layer accuracy: 0.0, total loss: 3.306122303009033, layer loss: 0.9925914406776428, bottom loss: 1.1803364753723145, node loss: 1.1331945657730103
node contra_loss: 0.0
ep: 0, global_step: 430, layer accuracy: 0.0, total loss: 3.1379809379577637, layer loss: 0.9366767406463623, bottom loss: 1.1268880367279053, node loss: 1.0744141340255737
node contra_loss: 1.8104910850524902e-06
ep: 0, global_step: 440, layer accuracy: 0.0, total loss: 3.234300136566162, layer loss: 0.9623715877532959, bottom loss: 1.1160469055175781, node loss: 1.074826955795288
node contra_loss: 0.0810546875
ep: 0, global_step: 450, layer accuracy: 0.0, total loss: 3.0889620780944824, layer loss: 0.9202789068222046, bottom loss: 1.0919206142425537, node loss: 1.0483202934265137
node contra_loss: 0.0284423828125
ep: 0, global_step: 460, layer accuracy: 0.0, total loss: 3.149704933166504, layer loss: 0.9481313228607178, bottom loss: 1.1205931901931763, node loss: 1.0743885040283203
node contra_loss: 0.006591796875
ep: 0, global_step: 470, layer accuracy: 0.0, total loss: 3.091179609298706, layer loss: 0.9025739431381226, bottom loss: 1.0725111961364746, node loss: 1.0311335325241089
node contra_loss: 0.0849609375
ep: 0, global_step: 480, layer accuracy: 0.0, total loss: 2.9817352294921875, layer loss: 0.9409898519515991, bottom loss: 1.035461664199829, node loss: 1.0052835941314697
node contra_loss: 0.0
ep: 0, global_step: 490, layer accuracy: 0.0, total loss: 3.026761531829834, layer loss: 0.9041465520858765, bottom loss: 1.050248146057129, node loss: 1.0196325778961182
node contra_loss: 0.052734375
ep: 0, global_step: 500, layer accuracy: 0.0, total loss: 3.1407206058502197, layer loss: 0.9682491421699524, bottom loss: 1.0945841073989868, node loss: 1.0778872966766357
node contra_loss: 0.0
ep: 0, global_step: 510, layer accuracy: 0.0, total loss: 2.848268985748291, layer loss: 0.9022548198699951, bottom loss: 0.9958834052085876, node loss: 0.9501307606697083
node contra_loss: 4.540197551250458e-08
valid layer_batch_acc: 0.0
ep: 0, time: 30266.241085529327
训练集的acc: 0.019608361500840304
验证集的acc: 0.4481625825587611
ep: 1, global_step: 520, layer accuracy: 0.0, total loss: 2.6721577644348145, layer loss: 0.832500696182251, bottom loss: 0.941174328327179, node loss: 0.8984828591346741
node contra_loss: 0.0
ep: 1, global_step: 530, layer accuracy: 0.0, total loss: 2.6686558723449707, layer loss: 0.8359427452087402, bottom loss: 0.931113600730896, node loss: 0.9015995860099792
node contra_loss: 0.0
ep: 1, global_step: 540, layer accuracy: 0.0, total loss: 3.1369590759277344, layer loss: 0.9659556746482849, bottom loss: 1.097716212272644, node loss: 1.0532678365707397
node contra_loss: 0.02001953125
ep: 1, global_step: 550, layer accuracy: 0.0, total loss: 2.627474308013916, layer loss: 0.8052605986595154, bottom loss: 0.9097656011581421, node loss: 0.8870574831962585
node contra_loss: 0.025390625
ep: 1, global_step: 560, layer accuracy: 0.0, total loss: 2.658407688140869, layer loss: 0.7881860733032227, bottom loss: 0.8895733952522278, node loss: 0.8629723787307739
node contra_loss: 0.11767578125
ep: 1, global_step: 570, layer accuracy: 0.0, total loss: 2.4838528633117676, layer loss: 0.7896997928619385, bottom loss: 0.860740602016449, node loss: 0.8334122896194458
ep: 1, global_step: 580, layer accuracy: 0.0, total loss: 2.686551570892334, layer loss: 0.7973387241363525, bottom loss: 0.889909565448761, node loss: 0.8625845909118652
node contra_loss: 0.13671875
ep: 1, global_step: 590, layer accuracy: 0.0, total loss: 2.308505058288574, layer loss: 0.7220735549926758, bottom loss: 0.8113347291946411, node loss: 0.7750967144966125
node contra_loss: 0.0
ep: 1, global_step: 600, layer accuracy: 0.0, total loss: 2.486191987991333, layer loss: 0.7781678438186646, bottom loss: 0.8662530183792114, node loss: 0.8417710661888123
node contra_loss: 0.0
ep: 1, global_step: 610, layer accuracy: 0.0, total loss: 2.4094138145446777, layer loss: 0.7543129920959473, bottom loss: 0.809364378452301, node loss: 0.7873868346214294
node contra_loss: 0.058349609375
ep: 1, global_step: 620, layer accuracy: 0.0, total loss: 2.1775383949279785, layer loss: 0.6918361783027649, bottom loss: 0.7521315217018127, node loss: 0.7335705757141113
node contra_loss: 0.0
ep: 1, global_step: 630, layer accuracy: 0.0, total loss: 2.3051974773406982, layer loss: 0.6977905035018921, bottom loss: 0.7591681480407715, node loss: 0.7359340786933899
node contra_loss: 0.1123046875
ep: 1, global_step: 640, layer accuracy: 0.0, total loss: 2.311843156814575, layer loss: 0.6948626041412354, bottom loss: 0.7454790472984314, node loss: 0.7220873832702637
node contra_loss: 0.1494140625
ep: 1, global_step: 650, layer accuracy: 0.0, total loss: 2.197599411010742, layer loss: 0.7085504531860352, bottom loss: 0.7527205348014832, node loss: 0.7363283038139343
node contra_loss: 0.0
ep: 1, global_step: 660, layer accuracy: 0.0, total loss: 2.1258151531219482, layer loss: 0.6868329048156738, bottom loss: 0.7326845526695251, node loss: 0.7062975764274597
node contra_loss: 0.0
ep: 1, global_step: 670, layer accuracy: 0.0, total loss: 2.0258946418762207, layer loss: 0.6380079388618469, bottom loss: 0.7112564444541931, node loss: 0.6766303777694702
node contra_loss: 0.0
ep: 1, global_step: 680, layer accuracy: 0.0, total loss: 1.887326955795288, layer loss: 0.6187763214111328, bottom loss: 0.6448166370391846, node loss: 0.6237339377403259
node contra_loss: 0.0
ep: 1, global_step: 690, layer accuracy: 0.0, total loss: 2.1533725261688232, layer loss: 0.6572437286376953, bottom loss: 0.7128084301948547, node loss: 0.7066603302955627
node contra_loss: 0.07666015625
ep: 1, global_step: 700, layer accuracy: 0.0, total loss: 1.94307541847229, layer loss: 0.6176190376281738, bottom loss: 0.6658011078834534, node loss: 0.6469599604606628
node contra_loss: 0.0126953125
ep: 1, global_step: 710, layer accuracy: 0.0, total loss: 1.9915874004364014, layer loss: 0.6603374481201172, bottom loss: 0.6697208881378174, node loss: 0.6615290641784668
node contra_loss: 0.0
ep: 1, global_step: 720, layer accuracy: 0.0, total loss: 2.02142596244812, layer loss: 0.6551192402839661, bottom loss: 0.6879622340202332, node loss: 0.6783445477485657
node contra_loss: 0.0
ep: 1, global_step: 730, layer accuracy: 0.0, total loss: 1.8687970638275146, layer loss: 0.5695309638977051, bottom loss: 0.6079323291778564, node loss: 0.5956307053565979
node contra_loss: 0.095703125
ep: 1, global_step: 740, layer accuracy: 0.0, total loss: 1.7603363990783691, layer loss: 0.5815019607543945, bottom loss: 0.5982910990715027, node loss: 0.5805433392524719
node contra_loss: 0.0
ep: 1, global_step: 750, layer accuracy: 0.0, total loss: 1.8502106666564941, layer loss: 0.5924814343452454, bottom loss: 0.635433554649353, node loss: 0.6222956776618958
node contra_loss: 0.0
ep: 1, global_step: 760, layer accuracy: 0.0, total loss: 1.7882535457611084, layer loss: 0.5967757701873779, bottom loss: 0.59815514087677, node loss: 0.5933225750923157
ep: 1, global_step: 770, layer accuracy: 0.0, total loss: 2.210826873779297, layer loss: 0.599048376083374, bottom loss: 0.6354551315307617, node loss: 0.6169482469558716
node contra_loss: 0.359375
ep: 1, global_step: 780, layer accuracy: 0.0, total loss: 1.8032902479171753, layer loss: 0.5837650299072266, bottom loss: 0.6154218912124634, node loss: 0.6041033267974854
node contra_loss: 0.0
ep: 1, global_step: 790, layer accuracy: 0.0, total loss: 1.6952849626541138, layer loss: 0.5432690978050232, bottom loss: 0.5800625681877136, node loss: 0.571953296661377
node contra_loss: 0.0
ep: 1, global_step: 800, layer accuracy: 0.0, total loss: 1.6436067819595337, layer loss: 0.5113160610198975, bottom loss: 0.545866847038269, node loss: 0.5371074676513672
node contra_loss: 0.04931640625
save checkpoint -> step_800
[2024-12-03 04:25:32,907] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-12-03 04:25:34,083] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_800/pytorch_model/mp_rank_00_model_states.pt
[2024-12-03 04:25:34,084] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_800/pytorch_model/mp_rank_00_model_states.pt...
[2024-12-03 04:25:38,515] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_800/pytorch_model/mp_rank_00_model_states.pt.
[2024-12-03 04:25:38,581] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-12-03 04:25:38,621] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-12-03 04:25:38,621] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_800/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-12-03 04:25:38,621] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_800 saved!
ep: 1, global_step: 810, layer accuracy: 0.0, total loss: 1.5907344818115234, layer loss: 0.5284421443939209, bottom loss: 0.534217119216919, node loss: 0.5280752182006836
ep: 1, global_step: 820, layer accuracy: 0.0, total loss: 1.590566873550415, layer loss: 0.5106328725814819, bottom loss: 0.5426942706108093, node loss: 0.5372397303581238
node contra_loss: 0.0
ep: 1, global_step: 830, layer accuracy: 0.0, total loss: 1.530509352684021, layer loss: 0.4951556324958801, bottom loss: 0.5217602849006653, node loss: 0.5135934352874756
node contra_loss: 0.0
ep: 1, global_step: 840, layer accuracy: 0.0, total loss: 1.6958808898925781, layer loss: 0.5570738911628723, bottom loss: 0.570429265499115, node loss: 0.5683777928352356
ep: 1, global_step: 850, layer accuracy: 0.0, total loss: 1.5478860139846802, layer loss: 0.49732354283332825, bottom loss: 0.5284338593482971, node loss: 0.5221285820007324
node contra_loss: 0.0
ep: 1, global_step: 860, layer accuracy: 0.0, total loss: 1.4470274448394775, layer loss: 0.4711972773075104, bottom loss: 0.49333876371383667, node loss: 0.4824913740158081
node contra_loss: 0.0
ep: 1, global_step: 870, layer accuracy: 0.0, total loss: 1.5189049243927002, layer loss: 0.4843847155570984, bottom loss: 0.5219792723655701, node loss: 0.512540876865387
node contra_loss: 0.0
ep: 1, global_step: 880, layer accuracy: 0.0, total loss: 1.8168847560882568, layer loss: 0.5173296928405762, bottom loss: 0.5283901691436768, node loss: 0.5231179594993591
node contra_loss: 0.248046875
ep: 1, global_step: 890, layer accuracy: 0.0, total loss: 1.5364006757736206, layer loss: 0.4961422383785248, bottom loss: 0.5226538181304932, node loss: 0.5176045894622803
node contra_loss: 0.0
ep: 1, global_step: 900, layer accuracy: 0.0, total loss: 1.3448232412338257, layer loss: 0.44450145959854126, bottom loss: 0.4541409909725189, node loss: 0.4461807906627655
node contra_loss: 0.0
ep: 1, global_step: 910, layer accuracy: 0.0, total loss: 1.802228331565857, layer loss: 0.5488399863243103, bottom loss: 0.5715081691741943, node loss: 0.5725051164627075
node contra_loss: 0.109375
ep: 1, global_step: 920, layer accuracy: 0.0, total loss: 1.4399064779281616, layer loss: 0.4499324560165405, bottom loss: 0.4813009202480316, node loss: 0.4786437749862671
node contra_loss: 0.030029296875
ep: 1, global_step: 930, layer accuracy: 0.0, total loss: 1.4836217164993286, layer loss: 0.49277743697166443, bottom loss: 0.497283935546875, node loss: 0.4935603439807892
node contra_loss: 0.0
ep: 1, global_step: 940, layer accuracy: 0.0, total loss: 1.7065465450286865, layer loss: 0.48015114665031433, bottom loss: 0.48694729804992676, node loss: 0.4796825051307678
node contra_loss: 0.259765625
ep: 1, global_step: 950, layer accuracy: 0.0, total loss: 1.5447790622711182, layer loss: 0.49189627170562744, bottom loss: 0.4984591603279114, node loss: 0.49582985043525696
node contra_loss: 0.05859375
ep: 1, global_step: 960, layer accuracy: 0.0, total loss: 1.582598090171814, layer loss: 0.47368940711021423, bottom loss: 0.4910236597061157, node loss: 0.489955335855484
node contra_loss: 0.1279296875
ep: 1, global_step: 970, layer accuracy: 0.0, total loss: 1.3910000324249268, layer loss: 0.4635367691516876, bottom loss: 0.46598777174949646, node loss: 0.46147552132606506
node contra_loss: 0.0
ep: 1, global_step: 980, layer accuracy: 0.0, total loss: 1.4322640895843506, layer loss: 0.4657406210899353, bottom loss: 0.48141178488731384, node loss: 0.48511165380477905
node contra_loss: 0.0
ep: 1, global_step: 990, layer accuracy: 0.0, total loss: 1.2594518661499023, layer loss: 0.40236204862594604, bottom loss: 0.4291936755180359, node loss: 0.427896112203598
node contra_loss: 0.0
ep: 1, global_step: 1000, layer accuracy: 0.0, total loss: 1.1552594900131226, layer loss: 0.3810324966907501, bottom loss: 0.39161545038223267, node loss: 0.3826115131378174
node contra_loss: 0.0
ep: 1, global_step: 1010, layer accuracy: 0.0, total loss: 1.3832213878631592, layer loss: 0.4623485207557678, bottom loss: 0.46301528811454773, node loss: 0.45785754919052124
node contra_loss: 0.0
ep: 1, global_step: 1020, layer accuracy: 0.0, total loss: 1.4082691669464111, layer loss: 0.4640204906463623, bottom loss: 0.47054004669189453, node loss: 0.4737085700035095
ep: 1, global_step: 1030, layer accuracy: 0.015625, total loss: 1.3576551675796509, layer loss: 0.4170960783958435, bottom loss: 0.4345717430114746, node loss: 0.4400693476200104
node contra_loss: 0.06591796875
valid layer_batch_acc: 0.0
ep: 1, time: 60798.97537779808
训练集的acc: 0.044598447797269486
验证集的acc: 0.5962510131231785
ep: 2, global_step: 1040, layer accuracy: 0.0, total loss: 1.2822858095169067, layer loss: 0.42520153522491455, bottom loss: 0.4319040775299072, node loss: 0.42518022656440735
node contra_loss: 0.0
ep: 2, global_step: 1050, layer accuracy: 0.0, total loss: 1.373679518699646, layer loss: 0.45258426666259766, bottom loss: 0.45770466327667236, node loss: 0.46339061856269836
node contra_loss: 0.0
ep: 2, global_step: 1060, layer accuracy: 0.0, total loss: 1.2300426959991455, layer loss: 0.4127214848995209, bottom loss: 0.41072770953178406, node loss: 0.4065934717655182
node contra_loss: 0.0
ep: 2, global_step: 1070, layer accuracy: 0.0, total loss: 1.6467162370681763, layer loss: 0.43733617663383484, bottom loss: 0.46882063150405884, node loss: 0.47298136353492737
node contra_loss: 0.267578125
ep: 2, global_step: 1080, layer accuracy: 0.0, total loss: 1.2640252113342285, layer loss: 0.4236550033092499, bottom loss: 0.41983672976493835, node loss: 0.4205334782600403
node contra_loss: 0.0
ep: 2, global_step: 1090, layer accuracy: 0.0, total loss: 1.4170465469360352, layer loss: 0.42693227529525757, bottom loss: 0.45392337441444397, node loss: 0.4536713659763336
node contra_loss: 0.08251953125
ep: 2, global_step: 1100, layer accuracy: 0.0, total loss: 1.1683571338653564, layer loss: 0.38712942600250244, bottom loss: 0.39426425099372864, node loss: 0.386963427066803
node contra_loss: 0.0
ep: 2, global_step: 1110, layer accuracy: 0.0, total loss: 1.3043196201324463, layer loss: 0.40784716606140137, bottom loss: 0.43716949224472046, node loss: 0.43598753213882446
node contra_loss: 0.0233154296875
ep: 2, global_step: 1120, layer accuracy: 0.0, total loss: 1.6930932998657227, layer loss: 0.48670560121536255, bottom loss: 0.4969981610774994, node loss: 0.49942857027053833
node contra_loss: 0.2099609375
ep: 2, global_step: 1130, layer accuracy: 0.0, total loss: 1.360140323638916, layer loss: 0.4222518503665924, bottom loss: 0.46592995524406433, node loss: 0.47195857763290405
node contra_loss: 0.0
ep: 2, global_step: 1140, layer accuracy: 0.0, total loss: 1.2176320552825928, layer loss: 0.39966464042663574, bottom loss: 0.407842218875885, node loss: 0.4101252555847168
node contra_loss: 0.0
ep: 2, global_step: 1150, layer accuracy: 0.015625, total loss: 1.3416643142700195, layer loss: 0.4477938413619995, bottom loss: 0.44704389572143555, node loss: 0.44682660698890686
node contra_loss: 0.0
ep: 2, global_step: 1160, layer accuracy: 0.0, total loss: 1.1945972442626953, layer loss: 0.3844873309135437, bottom loss: 0.4063982367515564, node loss: 0.4037116765975952
node contra_loss: 0.0
ep: 2, global_step: 1170, layer accuracy: 0.0, total loss: 1.146285891532898, layer loss: 0.3802187442779541, bottom loss: 0.38335102796554565, node loss: 0.3827160894870758
node contra_loss: 0.0
ep: 2, global_step: 1180, layer accuracy: 0.0, total loss: 1.322449803352356, layer loss: 0.45816370844841003, bottom loss: 0.43356841802597046, node loss: 0.43071773648262024
node contra_loss: 0.0
ep: 2, global_step: 1190, layer accuracy: 0.0, total loss: 1.1039206981658936, layer loss: 0.3625642657279968, bottom loss: 0.3684142529964447, node loss: 0.3729422092437744
node contra_loss: 0.0
ep: 2, global_step: 1200, layer accuracy: 0.0, total loss: 1.0958211421966553, layer loss: 0.3542005121707916, bottom loss: 0.3723689019680023, node loss: 0.36925169825553894
node contra_loss: 0.0
save checkpoint -> step_1200
[2024-12-03 11:23:34,208] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-12-03 11:23:35,207] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_1200/pytorch_model/mp_rank_00_model_states.pt
[2024-12-03 11:23:35,207] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_1200/pytorch_model/mp_rank_00_model_states.pt...
[2024-12-03 11:23:39,845] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_1200/pytorch_model/mp_rank_00_model_states.pt.
[2024-12-03 11:23:39,891] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_1200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-12-03 11:23:39,928] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_1200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-12-03 11:23:39,928] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_1200/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-12-03 11:23:39,928] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_1200 saved!
ep: 2, global_step: 1210, layer accuracy: 0.0, total loss: 1.2630926370620728, layer loss: 0.40074995160102844, bottom loss: 0.4281338155269623, node loss: 0.4300585091114044
node contra_loss: 0.004150390625
ep: 2, global_step: 1220, layer accuracy: 0.0, total loss: 1.1202597618103027, layer loss: 0.37108832597732544, bottom loss: 0.37734347581863403, node loss: 0.37182801961898804
node contra_loss: 0.0
ep: 2, global_step: 1230, layer accuracy: 0.0, total loss: 0.917475700378418, layer loss: 0.31549936532974243, bottom loss: 0.30364990234375, node loss: 0.29832640290260315
ep: 2, global_step: 1240, layer accuracy: 0.0, total loss: 1.6246492862701416, layer loss: 0.5119056701660156, bottom loss: 0.5229786038398743, node loss: 0.5392279028892517
node contra_loss: 0.050537109375
ep: 2, global_step: 1250, layer accuracy: 0.0, total loss: 1.2213819026947021, layer loss: 0.39089980721473694, bottom loss: 0.40864667296409607, node loss: 0.40688183903694153
node contra_loss: 0.01495361328125
ep: 2, global_step: 1260, layer accuracy: 0.0, total loss: 1.333172082901001, layer loss: 0.3375857174396515, bottom loss: 0.3587913513183594, node loss: 0.3594512939453125
node contra_loss: 0.27734375
ep: 2, global_step: 1270, layer accuracy: 0.0, total loss: 1.2503063678741455, layer loss: 0.374462753534317, bottom loss: 0.4117482900619507, node loss: 0.4208824336528778
node contra_loss: 0.043212890625
ep: 2, global_step: 1280, layer accuracy: 0.0, total loss: 1.0942407846450806, layer loss: 0.35208839178085327, bottom loss: 0.36753159761428833, node loss: 0.3746207654476166
node contra_loss: 0.0
ep: 2, global_step: 1290, layer accuracy: 0.0, total loss: 1.0751421451568604, layer loss: 0.35576704144477844, bottom loss: 0.35968664288520813, node loss: 0.35968849062919617
node contra_loss: 0.0
ep: 2, global_step: 1300, layer accuracy: 0.0, total loss: 1.0166807174682617, layer loss: 0.32414665818214417, bottom loss: 0.34145084023475647, node loss: 0.3510831892490387
node contra_loss: 0.0
ep: 2, global_step: 1310, layer accuracy: 0.0, total loss: 1.2296969890594482, layer loss: 0.39290928840637207, bottom loss: 0.40068119764328003, node loss: 0.39704403281211853
node contra_loss: 0.0390625
ep: 2, global_step: 1320, layer accuracy: 0.0, total loss: 1.0169979333877563, layer loss: 0.3241986632347107, bottom loss: 0.3465002775192261, node loss: 0.3462989926338196
node contra_loss: 0.0
ep: 2, global_step: 1330, layer accuracy: 0.0, total loss: 0.9760143756866455, layer loss: 0.32559531927108765, bottom loss: 0.3224303126335144, node loss: 0.32798877358436584
node contra_loss: 0.0
ep: 2, global_step: 1340, layer accuracy: 0.0, total loss: 1.0905704498291016, layer loss: 0.3468444049358368, bottom loss: 0.3709648847579956, node loss: 0.372761070728302
ep: 2, global_step: 1350, layer accuracy: 0.0, total loss: 0.9287588596343994, layer loss: 0.30468305945396423, bottom loss: 0.30974623560905457, node loss: 0.314329594373703
node contra_loss: 0.0
ep: 2, global_step: 1360, layer accuracy: 0.0, total loss: 1.0429266691207886, layer loss: 0.33914506435394287, bottom loss: 0.3532220721244812, node loss: 0.3505595028400421
node contra_loss: 0.0
ep: 2, global_step: 1370, layer accuracy: 0.0, total loss: 0.9178906083106995, layer loss: 0.3215493857860565, bottom loss: 0.2993272542953491, node loss: 0.29701393842697144
node contra_loss: 0.0
ep: 2, global_step: 1380, layer accuracy: 0.0, total loss: 1.1157429218292236, layer loss: 0.3456265330314636, bottom loss: 0.3869268596172333, node loss: 0.38318952918052673
node contra_loss: 0.0
ep: 2, global_step: 1390, layer accuracy: 0.0, total loss: 0.9705835580825806, layer loss: 0.32641687989234924, bottom loss: 0.3219197988510132, node loss: 0.32224687933921814
node contra_loss: 0.0
ep: 2, global_step: 1400, layer accuracy: 0.0, total loss: 0.8436388969421387, layer loss: 0.2776034474372864, bottom loss: 0.2824515998363495, node loss: 0.2835839092731476
node contra_loss: 0.0
ep: 2, global_step: 1410, layer accuracy: 0.0, total loss: 1.0734409093856812, layer loss: 0.3379884362220764, bottom loss: 0.36605432629585266, node loss: 0.3693980872631073
node contra_loss: 0.0
ep: 2, global_step: 1420, layer accuracy: 0.0, total loss: 1.194313645362854, layer loss: 0.35582002997398376, bottom loss: 0.37927088141441345, node loss: 0.3830508291721344
node contra_loss: 0.076171875
ep: 2, global_step: 1430, layer accuracy: 0.0, total loss: 1.1099666357040405, layer loss: 0.3656364977359772, bottom loss: 0.3714585304260254, node loss: 0.37287160754203796
node contra_loss: 0.0
ep: 2, global_step: 1440, layer accuracy: 0.0, total loss: 1.065919041633606, layer loss: 0.3359207212924957, bottom loss: 0.36143040657043457, node loss: 0.36856794357299805
node contra_loss: 0.0
ep: 2, global_step: 1450, layer accuracy: 0.0, total loss: 0.8749511241912842, layer loss: 0.291060209274292, bottom loss: 0.29332759976387024, node loss: 0.29056334495544434
node contra_loss: 0.0
ep: 2, global_step: 1460, layer accuracy: 0.0, total loss: 1.3996074199676514, layer loss: 0.36541032791137695, bottom loss: 0.39601001143455505, node loss: 0.40283554792404175
node contra_loss: 0.2353515625
ep: 2, global_step: 1470, layer accuracy: 0.0, total loss: 1.2068507671356201, layer loss: 0.38912466168403625, bottom loss: 0.4089180529117584, node loss: 0.40880805253982544
node contra_loss: 0.0
ep: 2, global_step: 1480, layer accuracy: 0.0, total loss: 1.1019270420074463, layer loss: 0.36274245381355286, bottom loss: 0.3663742244243622, node loss: 0.37281039357185364
node contra_loss: 0.0
ep: 2, global_step: 1490, layer accuracy: 0.0, total loss: 1.3684264421463013, layer loss: 0.44485747814178467, bottom loss: 0.4569476246833801, node loss: 0.46662136912345886
node contra_loss: 0.0
ep: 2, global_step: 1500, layer accuracy: 0.0, total loss: 1.0276992321014404, layer loss: 0.327653169631958, bottom loss: 0.34806615114212036, node loss: 0.35197994112968445
node contra_loss: 0.0
ep: 2, global_step: 1510, layer accuracy: 0.0, total loss: 0.9234645366668701, layer loss: 0.296895831823349, bottom loss: 0.31236475706100464, node loss: 0.31420400738716125
node contra_loss: 0.0
ep: 2, global_step: 1520, layer accuracy: 0.0, total loss: 1.029617190361023, layer loss: 0.33953094482421875, bottom loss: 0.34477928280830383, node loss: 0.34530699253082275
node contra_loss: 0.0
ep: 2, global_step: 1530, layer accuracy: 0.0, total loss: 1.1191747188568115, layer loss: 0.3432435095310211, bottom loss: 0.38507726788520813, node loss: 0.3908538818359375
node contra_loss: 0.0
ep: 2, global_step: 1540, layer accuracy: 0.0, total loss: 0.9663453102111816, layer loss: 0.29679664969444275, bottom loss: 0.3348640203475952, node loss: 0.3346845805644989
node contra_loss: 0.0
ep: 2, global_step: 1550, layer accuracy: 0.0, total loss: 1.0593929290771484, layer loss: 0.3429378569126129, bottom loss: 0.35578101873397827, node loss: 0.36067402362823486
node contra_loss: 0.0
valid layer_batch_acc: 0.002353894704168032
ep: 2, time: 91184.92621970177
训练集的acc: 0.051891156976414825
验证集的acc: 0.6149183465829726
ep: 3, global_step: 1560, layer accuracy: 0.0, total loss: 0.8927195072174072, layer loss: 0.2858740985393524, bottom loss: 0.3012668788433075, node loss: 0.3055785000324249
ep: 3, global_step: 1570, layer accuracy: 0.0, total loss: 0.8221597671508789, layer loss: 0.2681485712528229, bottom loss: 0.2758801579475403, node loss: 0.27813103795051575
node contra_loss: 0.0
ep: 3, global_step: 1580, layer accuracy: 0.0, total loss: 2.265895128250122, layer loss: 0.28939059376716614, bottom loss: 0.301908403635025, node loss: 0.3074086010456085
node contra_loss: 1.3671875
ep: 3, global_step: 1590, layer accuracy: 0.0, total loss: 0.7921271324157715, layer loss: 0.2537737488746643, bottom loss: 0.2665668725967407, node loss: 0.27178648114204407
node contra_loss: 0.0
ep: 3, global_step: 1600, layer accuracy: 0.0, total loss: 0.9884523153305054, layer loss: 0.3071078360080719, bottom loss: 0.3397398293018341, node loss: 0.34160467982292175
node contra_loss: 0.0
save checkpoint -> step_1600
[2024-12-03 18:20:20,186] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!
[2024-12-03 18:20:21,172] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: ckpts6/step_1600/pytorch_model/mp_rank_00_model_states.pt
[2024-12-03 18:20:21,172] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_1600/pytorch_model/mp_rank_00_model_states.pt...
[2024-12-03 18:20:25,470] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_1600/pytorch_model/mp_rank_00_model_states.pt.
[2024-12-03 18:20:25,523] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving ckpts6/step_1600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-12-03 18:20:25,560] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved ckpts6/step_1600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-12-03 18:20:25,561] [INFO] [engine.py:3536:_save_zero_checkpoint] zero checkpoint saved ckpts6/step_1600/pytorch_model/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-12-03 18:20:25,561] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint pytorch_model is ready now!
step_1600 saved!
ep: 3, global_step: 1610, layer accuracy: 0.0, total loss: 0.9344974756240845, layer loss: 0.304271936416626, bottom loss: 0.3135765790939331, node loss: 0.3166489899158478
node contra_loss: 0.0
ep: 3, global_step: 1620, layer accuracy: 0.015625, total loss: 1.066770315170288, layer loss: 0.35176989436149597, bottom loss: 0.35738056898117065, node loss: 0.35761988162994385
node contra_loss: 0.0
ep: 3, global_step: 1630, layer accuracy: 0.0, total loss: 0.9111241102218628, layer loss: 0.2879405617713928, bottom loss: 0.31371814012527466, node loss: 0.3094654083251953
node contra_loss: 0.0
ep: 3, global_step: 1640, layer accuracy: 0.0, total loss: 0.9611239433288574, layer loss: 0.31568774580955505, bottom loss: 0.32158738374710083, node loss: 0.32384881377220154
node contra_loss: 0.0
ep: 3, global_step: 1650, layer accuracy: 0.0, total loss: 0.8517919182777405, layer loss: 0.27114957571029663, bottom loss: 0.2872803807258606, node loss: 0.29336196184158325
node contra_loss: 0.0
ep: 3, global_step: 1660, layer accuracy: 0.0, total loss: 0.786365270614624, layer loss: 0.2549527883529663, bottom loss: 0.2667192816734314, node loss: 0.26469317078590393
node contra_loss: 0.0
ep: 3, global_step: 1670, layer accuracy: 0.0, total loss: 0.791692852973938, layer loss: 0.2597048878669739, bottom loss: 0.2690495550632477, node loss: 0.26293835043907166
node contra_loss: 0.0
ep: 3, global_step: 1680, layer accuracy: 0.015625, total loss: 1.1442906856536865, layer loss: 0.36715081334114075, bottom loss: 0.386615514755249, node loss: 0.39052438735961914
node contra_loss: 0.0
ep: 3, global_step: 1690, layer accuracy: 0.0, total loss: 1.0256543159484863, layer loss: 0.3191746771335602, bottom loss: 0.3474630117416382, node loss: 0.35901662707328796
node contra_loss: 0.0
ep: 3, global_step: 1700, layer accuracy: 0.0, total loss: 1.028841257095337, layer loss: 0.3171353340148926, bottom loss: 0.3523605763912201, node loss: 0.35934531688690186
node contra_loss: 0.0
ep: 3, global_step: 1710, layer accuracy: 0.0, total loss: 1.1375083923339844, layer loss: 0.3317069709300995, bottom loss: 0.3709976077079773, node loss: 0.37791910767555237
node contra_loss: 0.056884765625
ep: 3, global_step: 1720, layer accuracy: 0.0, total loss: 0.7404661178588867, layer loss: 0.25256597995758057, bottom loss: 0.247248113155365, node loss: 0.24065200984477997
node contra_loss: 0.0
ep: 3, global_step: 1730, layer accuracy: 0.0, total loss: 0.9130979776382446, layer loss: 0.29306647181510925, bottom loss: 0.307088702917099, node loss: 0.3129428029060364
node contra_loss: 0.0
ep: 3, global_step: 1740, layer accuracy: 0.046875, total loss: 1.1383368968963623, layer loss: 0.3596557080745697, bottom loss: 0.38238954544067383, node loss: 0.3962915539741516
node contra_loss: 0.0

[2024-12-10 11:35:30,648] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-12-10 11:35:35,171] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-12-10 11:35:35,181] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-12-10 11:35:37,566] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-12-10 11:35:37,566] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-12-10 11:35:37,605] [INFO] [comm.py:652:init_distributed] cdb=None
name:  shared.weight param num:  131072
name:  encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight param num:  8192
name:  encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight param num:  32768
name:  encoder.block.23.layer.0.SelfAttention.k.lora_A.default.weight param num:  8192
name:  encoder.block.23.layer.0.SelfAttention.k.lora_B.default.weight param num:  32768
name:  encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight param num:  8192
name:  encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight param num:  32768
name:  encoder.block.23.layer.0.SelfAttention.o.lora_A.default.weight param num:  32768
name:  encoder.block.23.layer.0.SelfAttention.o.lora_B.default.weight param num:  8192
name:  encoder.block.23.layer.1.DenseReluDense.wi.lora_A.default.weight param num:  8192
name:  encoder.block.23.layer.1.DenseReluDense.wi.lora_B.default.weight param num:  131072
name:  encoder.block.23.layer.1.DenseReluDense.wo.lora_A.default.weight param num:  131072
name:  encoder.block.23.layer.1.DenseReluDense.wo.lora_B.default.weight param num:  8192
name:  layer_classifier.local_layers.0.0.weight param num:  65536
name:  layer_classifier.local_layers.0.0.bias param num:  256
name:  layer_classifier.local_layers.0.2.weight param num:  256
name:  layer_classifier.local_layers.0.2.bias param num:  256
name:  layer_classifier.local_layers.0.3.weight param num:  4096
name:  layer_classifier.local_layers.0.3.bias param num:  16
name:  layer_classifier.local_layers.1.0.weight param num:  131072
name:  layer_classifier.local_layers.1.0.bias param num:  512
name:  layer_classifier.local_layers.1.2.weight param num:  512
name:  layer_classifier.local_layers.1.2.bias param num:  512
name:  layer_classifier.local_layers.1.3.weight param num:  75264
name:  layer_classifier.local_layers.1.3.bias param num:  147
name:  layer_classifier.global_layers.0.0.weight param num:  262144
name:  layer_classifier.global_layers.0.0.bias param num:  256
name:  layer_classifier.global_layers.0.2.weight param num:  256
name:  layer_classifier.global_layers.0.2.bias param num:  256
name:  layer_classifier.global_layers.1.0.weight param num:  327680
name:  layer_classifier.global_layers.1.0.bias param num:  256
name:  layer_classifier.global_layers.1.2.weight param num:  256
name:  layer_classifier.global_layers.1.2.bias param num:  256
name:  layer_classifier.linear.weight param num:  41728
name:  layer_classifier.linear.bias param num:  163
name:  node_classifier.layer_score.weight param num:  83456
name:  node_classifier.layer_score.bias param num:  512
name:  node_classifier.hidden_score.weight param num:  524288
name:  node_classifier.hidden_score.bias param num:  512
name:  node_classifier.batch_norm1.weight param num:  1024
name:  node_classifier.batch_norm1.bias param num:  1024
name:  node_classifier.out_proj.weight param num:  1593344
name:  node_classifier.out_proj.bias param num:  1556
trainable paras number: 3690842
layer param: shared.weight
layer param: encoder.block.23.layer.0.SelfAttention.q.lora_A.default.weight
layer param: encoder.block.23.layer.0.SelfAttention.q.lora_B.default.weight
layer param: encoder.block.23.layer.0.SelfAttention.k.lora_A.default.weight
layer param: encoder.block.23.layer.0.SelfAttention.k.lora_B.default.weight
layer param: encoder.block.23.layer.0.SelfAttention.v.lora_A.default.weight
layer param: encoder.block.23.layer.0.SelfAttention.v.lora_B.default.weight
layer param: encoder.block.23.layer.0.SelfAttention.o.lora_A.default.weight
layer param: encoder.block.23.layer.0.SelfAttention.o.lora_B.default.weight
layer param: encoder.block.23.layer.1.DenseReluDense.wi.lora_A.default.weight
layer param: encoder.block.23.layer.1.DenseReluDense.wi.lora_B.default.weight
layer param: encoder.block.23.layer.1.DenseReluDense.wo.lora_A.default.weight
layer param: encoder.block.23.layer.1.DenseReluDense.wo.lora_B.default.weight
layer param: layer_classifier.local_layers.0.0.weight
layer param: layer_classifier.local_layers.0.0.bias
layer param: layer_classifier.local_layers.0.2.weight
layer param: layer_classifier.local_layers.0.2.bias
layer param: layer_classifier.local_layers.0.3.weight
layer param: layer_classifier.local_layers.0.3.bias
layer param: layer_classifier.local_layers.1.0.weight
layer param: layer_classifier.local_layers.1.0.bias
layer param: layer_classifier.local_layers.1.2.weight
layer param: layer_classifier.local_layers.1.2.bias
layer param: layer_classifier.local_layers.1.3.weight
layer param: layer_classifier.local_layers.1.3.bias
layer param: layer_classifier.global_layers.0.0.weight
layer param: layer_classifier.global_layers.0.0.bias
layer param: layer_classifier.global_layers.0.2.weight
layer param: layer_classifier.global_layers.0.2.bias
layer param: layer_classifier.global_layers.1.0.weight
layer param: layer_classifier.global_layers.1.0.bias
layer param: layer_classifier.global_layers.1.2.weight
layer param: layer_classifier.global_layers.1.2.bias
layer param: layer_classifier.linear.weight
layer param: layer_classifier.linear.bias
node param: node_classifier.layer_score.weight
node param: node_classifier.layer_score.bias
node param: node_classifier.hidden_score.weight
node param: node_classifier.hidden_score.bias
node param: node_classifier.batch_norm1.weight
node param: node_classifier.batch_norm1.bias
node param: node_classifier.out_proj.weight
node param: node_classifier.out_proj.bias
