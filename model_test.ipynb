{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csy/miniconda3/envs/deepspeed/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csy/miniconda3/envs/deepspeed/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/csy/miniconda3/envs/deepspeed/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from accelerate import Accelerator\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, Sampler\n",
    "from transformers import T5EncoderModel, T5Tokenizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, multilabel_confusion_matrix\n",
    "from ProtTransModel2 import ClassConfig, T5EncoderCLSModel, Contrastive_loss, LayerLoss, NodeLoss\n",
    "from accelerate.logging import get_logger\n",
    "from sklearn.metrics import roc_curve, auc, matthews_corrcoef\n",
    "import json\n",
    "import math\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "from MySampler2 import MyDistributedSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dirname = '/step_Focalloss6_'\n",
    "model_path = '/data/csyData/prot_t5_xl_half_uniref50-enc'\n",
    "\n",
    "with open('/data/csyData/uniprot_test/data/XML_testdata/go_temp/GO_data/cco/label_freq_list.json') as f:\n",
    "    label_freq_list = json.load(f)\n",
    "\n",
    "path = '/data/csyData/uniprot_test/data/XML_testdata/go_temp/GO_data/cco/withlayer2/'\n",
    "datatype = 'stride/'\n",
    "train_data_dir1 = path + datatype + 'traindata.csv'\n",
    "train_data_dir2 = path + datatype + 'trainNolabel.csv'\n",
    "# train_data_dir3 = path + 'traindata2.csv'\n",
    "train_filelist = [train_data_dir1, train_data_dir2]\n",
    "\n",
    "\n",
    "test_data_dir1 = path + datatype + 'testdata.csv'\n",
    "test_data_dir2 = path + datatype + 'testNolabel.csv'\n",
    "# test_data_dir3 = path + 'testdata2.csv'\n",
    "test_filelist = [test_data_dir1, test_data_dir2]\n",
    "\n",
    "# 得到 根 -> 叶子 字典\n",
    "with open('/data/csyData/uniprot_test/data/XML_testdata/go_temp/GO_data/cco/GO_cco_withlayerDepthDict3.json') as f:\n",
    "    temp_hierar_relations = json.load(f)\n",
    "    for go in temp_hierar_relations:\n",
    "        temp_hierar_relations[go] = temp_hierar_relations[go]['leaf']\n",
    "\n",
    "# 得到 分层聚类字典\n",
    "with open('/data/csyData/pygosemsim-master/pygosemsim-master/cco_Kmeans_cluster2.json') as f:\n",
    "    temp_cluster_nodes = json.load(f)\n",
    "\n",
    "# 得到 聚类的父子关系字典\n",
    "# with open('/data/csyData/uniprot_test/code/GOcode/cco_version2/cco_cluster_relations.json') as f:\n",
    "with open('/data/csyData/pygosemsim-master/pygosemsim-master/cco_KMeanscluster_relations.json') as f:\n",
    "    cluster_relations = json.load(f)\n",
    "\n",
    "# 得到标签频率按照阈值分成四份的字典\n",
    "# with open('/data/csyData/uniprot_test/data/XML_testdata/go_temp/GO_data/cco/label_freq_list.json') as f:\n",
    "#     label_freq_list = json.load(f)\n",
    "\n",
    "# 得到标签频率按照字典\n",
    "# with open('/data/csyData/uniprot_test/data/XML_testdata/go_temp/GO_data/cco/sta_count3.json') as f:\n",
    "#     sta_count3 = json.load(f)\n",
    "\n",
    "# 得到alpha\n",
    "with open('/data/csyData/uniprot_test/code/GOcode/cco_version2/freq.json') as f:\n",
    "    freq = json.load(f)\n",
    "\n",
    "node_nums = len(temp_hierar_relations.keys()) - 1\n",
    "layer_nums = len(temp_cluster_nodes.keys())\n",
    "labels_num = node_nums + layer_nums\n",
    "\n",
    "epoch = 200    # 可能修改\n",
    "max_length = 512\n",
    "train_batch_size = 64\n",
    "valid_batch_size = 64\n",
    "# lr = 3e-4\n",
    "# lr = 1e-3\n",
    "only_layer_metrics = False\n",
    "# load_model = True\n",
    "# saved_ep = 50   # 重新训练时，记得改成最新的模型参数\n",
    "saved_ep = 0\n",
    "\n",
    "temp_go = list(pd.read_csv(test_data_dir2, nrows=0).columns)[2:]\n",
    "\n",
    "high_freq = {}\n",
    "low_freq = {}\n",
    "hierar_relations = {}\n",
    "\n",
    "def go2index(target_go):\n",
    "    go = temp_go\n",
    "    if isinstance(target_go, list):\n",
    "        return [go.index(i) for i in target_go]\n",
    "    elif isinstance(target_go, str):\n",
    "        if target_go in go:\n",
    "            return go.index(target_go)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "for node,value in temp_hierar_relations.items():\n",
    "    if go2index(node):\n",
    "        hierar_relations[str(go2index(node))] = go2index(value)\n",
    "\n",
    "main_numbers, sub_numbers = [], []\n",
    "for label in list(temp_cluster_nodes.keys()):\n",
    "    if '_' not in label:\n",
    "        main_numbers.append(label)\n",
    "    else:\n",
    "        sub_numbers.append(label)\n",
    "\n",
    "main_numbers.sort(key=lambda x: int(x))\n",
    "sub_numbers.sort(key=lambda x: (int(x.split('_')[0]), int(x.split('_')[1])) if '_' in x else (int(x), -1))\n",
    "cluster_nodes = main_numbers + sub_numbers\n",
    "\n",
    "\n",
    "cluster_nodes_relations = {}\n",
    "for index,value in enumerate(cluster_nodes):\n",
    "    cluster_nodes_relations[str(index)] = go2index(temp_cluster_nodes[value])\n",
    "\n",
    "alpha = [0] * node_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csy/miniconda3/envs/deepspeed/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = T5EncoderModel.from_pretrained(model_path)\n",
    "model.config.d_model = 1024\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "\n",
    "lora_target_modules = []\n",
    "for name, _ in model.named_modules():\n",
    "    for layer in [23]:\n",
    "        if (str(layer) in name) & (('.wi' in name) or ('.wo' in name) or ('.q' in name) or ('.k' in name) or ('.v' in name) or ('.o' in name)):\n",
    "            lora_target_modules.append(name)\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "                lora_alpha=16,\n",
    "                lora_dropout=0.1,\n",
    "                r=8,\n",
    "                bias=\"none\",\n",
    "                task_type=\"SEQ_2_SEQ_LM\",\n",
    "                target_modules=lora_target_modules\n",
    "                )\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "class_config = ClassConfig(node_nums=node_nums, layer_nums=layer_nums, batch_size=train_batch_size)\n",
    "\n",
    "class_model = T5EncoderCLSModel(model.config,\n",
    "                                class_config,\n",
    "                                cluster_relations,\n",
    "                                hierar_relations,\n",
    "                                cluster_nodes_relations,\n",
    "                                alpha)\n",
    "class_model.encoder = model.encoder\n",
    "\n",
    "model = class_model\n",
    "del class_model\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from safetensors.torch import load_file\n",
    "\n",
    "saved_path = './ckpts6/step_1600/model/model.safetensors'\n",
    "\n",
    "\n",
    "weights = load_file(saved_path)\n",
    "\n",
    "# 现在 weights 是一个字典，其中包含了模型的所有权重\n",
    "# 你可以将这些权重加载到你的模型中\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5EncoderCLSModel(\n",
       "  (shared): Embedding(128, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(128, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 32)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-22): 22 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=16384, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (wo): lora.Linear(\n",
       "                (base_layer): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=16384, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (layer_loss_fn): ClassificationLoss(\n",
       "    (criterion): BCEWithLogitsLoss()\n",
       "  )\n",
       "  (nodes_loss_fn): ClassificationLoss(\n",
       "    (criterion): FocalLoss()\n",
       "  )\n",
       "  (layer_classifier): HMCNClassificationHead(\n",
       "    (local_layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Linear(in_features=256, out_features=16, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Linear(in_features=512, out_features=147, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (global_layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=1280, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=256, out_features=163, bias=True)\n",
       "  )\n",
       "  (node_classifier): ClassificationHead(\n",
       "    (layer_score): Linear(in_features=163, out_features=512, bias=True)\n",
       "    (hidden_score): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (batch_norm1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0.15, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=1556, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_func(batch):\n",
    "    sequence, layers, nodes = [], [], []\n",
    "    for item in batch:\n",
    "        sequence.append(item[0])\n",
    "        layers.append(item[1])\n",
    "        nodes.append(item[2])\n",
    "    inputs = tokenizer(sequence, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    # del inputs[\"token_type_ids\"]\n",
    "    if not only_layer_metrics:\n",
    "        inputs[\"nodes\"] = torch.FloatTensor(np.stack(nodes)).to('cuda:1')\n",
    "    inputs[\"layers\"] = torch.FloatTensor(np.stack(layers)).to('cuda:1')\n",
    "    return inputs\n",
    "\n",
    "class MyDataLoader(DataLoader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyDataLoader, self).__init__(*args, **kwargs)\n",
    "        self.go = self.dataset.go\n",
    "\n",
    "    def go2index(self,target_go):\n",
    "        if isinstance(target_go, list):\n",
    "            return [self.go.index(i) for i in target_go]\n",
    "        elif isinstance(target_go, str):\n",
    "            if target_go in self.go:\n",
    "                return self.go.index(target_go)\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self,data_dirlist) -> None:\n",
    "        super().__init__()\n",
    "        self.data = pd.concat(data_dirlist,axis=0).reset_index(drop=True)\n",
    "        self.go = list(self.data.columns)[2:]\n",
    "        \n",
    "        # low_freq_label_indices = self.data[self.data[list(low_freq.keys())].eq(1).any(axis=1)].index.tolist()\n",
    "        # temp = self.data.loc[low_freq_label_indices]\n",
    "        # temp['sequence'] = temp['sequence'].apply(lambda x: x[::-1])\n",
    "        # self.data = pd.concat([self.data] + [temp]).reset_index(drop=True)\n",
    "\n",
    "        # self.high_freq_label_indices = self.data[self.data[list(high_freq.keys())].eq(1).any(axis=1) & self.data[list(low_freq.keys())].eq(0).all(axis=1)].index.tolist()\n",
    "        # self.low_freq_label_indices = self.data[self.data[list(low_freq.keys())].eq(1).any(axis=1)].index.tolist()\n",
    "\n",
    "        # self.other_indices = self.data.index.difference(self.low_freq_label_indices).difference(self.high_freq_label_indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        temp_nodelabel = np.array(self.data.iloc[index,2:].tolist())\n",
    "        temp_layerlabel = np.array([])\n",
    "        \n",
    "        for cluster_name in cluster_nodes:\n",
    "            golist = temp_cluster_nodes[cluster_name]\n",
    "            temp_layerlabel = np.append(temp_layerlabel, \n",
    "                                        np.sum(temp_nodelabel[np.array(self.go2index(golist))]) > 0)\n",
    "        return self.data[\"sequence\"].iloc[index], temp_layerlabel, temp_nodelabel\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "validdata_list = []\n",
    "for i in test_filelist:\n",
    "    validdata_list.append(pd.read_csv(i))\n",
    "validset = MyDataset(validdata_list)\n",
    "\n",
    "valid_sampler = MyDistributedSampler(validset, \\\n",
    "                                    num_replicas=1, \\\n",
    "                                    rank=0, \\\n",
    "                                    shuffle=True, \\\n",
    "                                    initial_ratio=0.5, \\\n",
    "                                    drop_last=False)\n",
    "\n",
    "\n",
    "validloader = MyDataLoader(validset, batch_size=valid_batch_size, collate_fn=collate_func, sampler=valid_sampler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepspeed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
